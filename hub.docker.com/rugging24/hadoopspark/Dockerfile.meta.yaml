MetaArgs: null
Stages:
- BaseName: debian:stretch
  Commands:
  - Key: RSYNC_PASSWORD
    Name: arg
    Value: '''root'''
  - CmdLine:
    - apt-get update && apt-get install -y apt-utils build-essential     checkinstall
      default-jdk default-jre wget sudo vim openssh-server     libreadline-gplv2-dev
      libncursesw5-dev libssl-dev tar sshpass     libsqlite3-dev tk-dev libgdbm-dev
      libc6-dev libbz2-dev libffi-dev zlib1g-dev     rsync
    Name: run
    PrependShell: true
  - CmdLine:
    - wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz && tar xzf /Python-3.7.4.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /Python-3.7.4 && ./configure --prefix=/usr/local/python-37 --enable-optimizations     &&
      make altinstall && cd && rm -rf /Python-3.7.4 && rm /Python-3.7.4.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /usr/local/python-37/bin/python3.7 /usr/bin/python &&     ln -s /usr/local/python-37/bin/pip3.7
      /usr/bin/pip
    Name: run
    PrependShell: true
  - CmdLine:
    - groupadd -g 1020 hadoop && useradd -g 1020 -u 1020 -d /home/hadoop -s /bin/bash  -m
      -p hadoop hadoop
    Name: run
    PrependShell: true
  - CmdLine:
    - adduser hadoop sudo
    Name: run
    PrependShell: true
  - CmdLine:
    - su hadoop -c 'ssh-keygen -t rsa -N "" -f /home/hadoop/.ssh/id_rsa -q'
    Name: run
    PrependShell: true
  - CmdLine:
    - cat /home/hadoop/.ssh/id_rsa.pub >> /home/hadoop/.ssh/authorized_keys
    Name: run
    PrependShell: true
  - CmdLine:
    - chown -R hadoop:hadoop /home/hadoop/.ssh && chmod 600 /home/hadoop/.ssh/*
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://apache.lauf-forum.at/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xzf /hadoop-3.1.2.tar.gz && rm /hadoop-3.1.2.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv /hadoop-3.1.2 /home/hadoop/hadoop
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://apache.lauf-forum.at/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xzf /spark-2.4.3-bin-hadoop2.7.tgz && rm /spark-2.4.3-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv /spark-2.4.3-bin-hadoop2.7 /home/hadoop/spark
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-8-openjdk-amd64/jre
    Name: env
  - CmdLine:
    - touch /home/hadoop/.profile
    Name: run
    PrependShell: true
  - CmdLine:
    - echo PATH=/home/hadoop/hadoop/bin:/home/hadoop/hadoop/sbin:/home/hadoop/spark/bin:${PATH}
      > /home/hadoop/.profile
    Name: run
    PrependShell: true
  - CmdLine:
    - echo JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre >> /home/hadoop/.profile
    Name: run
    PrependShell: true
  - CmdLine:
    - chown hadoop:hadoop /home/hadoop/.profile
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "export JAVA_HOME=${JAVA_HOME}" >> /home/hadoop/hadoop/etc/hadoop/hadoop-env.sh
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - '*.xml'
    - /home/hadoop/hadoop/etc/hadoop/
  - CmdLine:
    - chown -R hadoop:hadoop /home/hadoop/hadoop
    Name: run
    PrependShell: true
  - CmdLine:
    - chown -R hadoop:hadoop /home/hadoop/hadoop/*
    Name: run
    PrependShell: true
  - CmdLine:
    - chown -R hadoop:hadoop /home/hadoop/spark
    Name: run
    PrependShell: true
  - CmdLine:
    - chown -R hadoop:hadoop /home/hadoop/spark/*
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /root/.ssh
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "PermitRootLogin   yes" >> /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "PasswordAuthentication  no" >> /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "StrictModes  no" >> /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "PubkeyAuthentication yes" >> /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "net.ipv6.conf.all.disable_ipv6 = 1" >> /etc/sysctl.conf
    Name: run
    PrependShell: true
  - Env:
    - Key: HDFS_NAMENODE_USER
      Value: '"hadoop"'
    Name: env
  - Env:
    - Key: HDFS_DATANODE_USER
      Value: '"hadoop"'
    Name: env
  - Env:
    - Key: HDFS_SECONDARYNAMENODE_USER
      Value: '"hadoop"'
    Name: env
  - Env:
    - Key: YARN_RESOURCEMANAGER_USER
      Value: '"hadoop"'
    Name: env
  - Env:
    - Key: YARN_NODEMANAGER_USER
      Value: '"hadoop"'
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: '"/home/hadoop/hadoop/etc/hadoop"'
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: '"/home/hadoop/spark"'
    Name: env
  - Env:
    - Key: LD_LIBRARY_PATH
      Value: '"/home/hadoop/hadoop/lib/native:${LD_LIBRARY_PATH}"'
    Name: env
  - CmdLine:
    - mv "${SPARK_HOME}"/conf/spark-defaults.conf.template "${SPARK_HOME}"/conf/spark-defaults.conf
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "spark.master    yarn" >> "${SPARK_HOME}"/conf/spark-defaults.conf
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "spark.driver.memory    512m" >> "${SPARK_HOME}"/conf/spark-defaults.conf
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "spark.executor.memory      512m" >> "${SPARK_HOME}"/conf/spark-defaults.conf
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - run_master.sh
    - /run_master.sh
  - CmdLine:
    - chmod a+x /run_master.sh
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "22"
    - "50070"
    - "50075"
    - "50470"
    - "8020"
    - "9000"
    - "9870"
  - CmdLine:
    - /run_master.sh
    Name: entrypoint
    PrependShell: false
  From:
    Image: debian:stretch
  Name: ""
  Platform: ""
  SourceCode: FROM debian:stretch
