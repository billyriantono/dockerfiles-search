{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "cithub/hadoop",
      "SourceCode": "FROM cithub/hadoop",
      "Platform": "",
      "From": {
        "Image": "cithub/hadoop"
      },
      "Commands": [
        {
          "Maintainer": "Channel IT Services, LLC",
          "Name": "maintainer"
        },
        {
          "Env": [
            {
              "Key": "SPARK_FILE_VER",
              "Value": "2.3.2-bin-hadoop2.7"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_VER",
              "Value": "2.3.2"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/home/hadoop/spark/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_OPTS",
              "Value": "-\"--packages graphframes:graphframes:0.6.0-spark2.3-s_2.11,com.databricks:spark-csv_2.11:1.2.0\""
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "YARN_CONF_DIR",
              "Value": "/home/hadoop/hadoop/etc/hadoop"
            }
          ],
          "Name": "env"
        },
        {
          "Name": "volume",
          "Volumes": [
            "/data"
          ]
        },
        {
          "CmdLine": [
            "apt-get update \u0026\u0026\tmkdir -p /home/hadoop/spark \u0026\u0026\twget https://www.apache.org/dyn/closer.lua/spark/spark-$SPARK_VER/spark-$SPARK_FILE_VER.tgz \u0026\u0026\ttar xzvf spark-$SPARK_FILE_VER.tgz \u0026\u0026\tmv spark-$SPARK_FILE_VER $SPARK_HOME \u0026\u0026\trm spark-$SPARK_FILE_VER.tgz"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get update \u0026\u0026\tapt-get install -y python3-pip python3-numpy python3-scipy python3-matplotlib python3-pandas python3-sympy python3-nose \u0026\u0026\tapt-get install -y python3-dev python3-pip g++ libopenblas-dev git \u0026\u0026\tapt-get clean \u0026\u0026\tpip3 install jupyter \u0026\u0026\tln -sf /usr/bin/python3 /usr/bin/python \u0026\u0026\tpip3 install --upgrade pip \u0026\u0026\tpip3 install spaCy \u0026\u0026\tpip3 install pyLDAvis scipy gensim nltk bokeh py4j \u0026\u0026\tpip3 install -U scikit-learn \u0026\u0026\tpip3 install https://dist.apache.org/repos/dist/dev/incubator/toree/0.2.0/snapshots/dev1/toree-pip/toree-0.2.0.dev1.tar.gz \u0026\u0026\tpip3 install toree \u0026\u0026\tpip3 install tensorflow \u0026\u0026\tpip3 install keras \u0026\u0026\tjupyter toree install --replace --interpreters=Scala,PySpark --spark_home=$SPARK_HOME --spark_opts=$SPARK_OPTS"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "wget -q https://raw.githubusercontent.com/channelit/docker-images/master/spark-yarn/firststart.sh -O /firststart.sh \u0026\u0026\tchmod 755 firststart.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "touch /home/hadoop/spark/spark/conf/spark-env.sh \u0026\u0026\techo \"#!/bin/sh\" \u003e\u003e /home/hadoop/spark/spark/conf/spark-env.sh \u0026\u0026\techo \"export PYSPARK_PYTHON=python\" \u003e\u003e /home/hadoop/spark/spark/conf/spark-env.sh \u0026\u0026\techo \"export PYTHONPATH=$PYTHONPATH:/home/hadoop/spark/spark/graphframes.jar:.\" \u003e\u003e /home/hadoop/spark/spark/conf/spark-env.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "expose",
          "Ports": [
            "4040",
            "7077",
            "8031",
            "8032",
            "8033",
            "8080",
            "8081",
            "8888",
            "9000"
          ]
        }
      ]
    }
  ]
}