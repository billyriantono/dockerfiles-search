MetaArgs: null
Stages:
- BaseName: cithub/hadoop
  Commands:
  - Maintainer: Channel IT Services, LLC
    Name: maintainer
  - Env:
    - Key: SPARK_FILE_VER
      Value: 2.3.2-bin-hadoop2.7
    Name: env
  - Env:
    - Key: SPARK_VER
      Value: 2.3.2
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /home/hadoop/spark/spark
    Name: env
  - Env:
    - Key: SPARK_OPTS
      Value: -"--packages graphframes:graphframes:0.6.0-spark2.3-s_2.11,com.databricks:spark-csv_2.11:1.2.0"
    Name: env
  - Env:
    - Key: YARN_CONF_DIR
      Value: /home/hadoop/hadoop/etc/hadoop
    Name: env
  - Name: volume
    Volumes:
    - /data
  - CmdLine:
    - "apt-get update &&\tmkdir -p /home/hadoop/spark &&\twget https://www.apache.org/dyn/closer.lua/spark/spark-$SPARK_VER/spark-$SPARK_FILE_VER.tgz
      &&\ttar xzvf spark-$SPARK_FILE_VER.tgz &&\tmv spark-$SPARK_FILE_VER $SPARK_HOME
      &&\trm spark-$SPARK_FILE_VER.tgz"
    Name: run
    PrependShell: true
  - CmdLine:
    - "apt-get update &&\tapt-get install -y python3-pip python3-numpy python3-scipy
      python3-matplotlib python3-pandas python3-sympy python3-nose &&\tapt-get install
      -y python3-dev python3-pip g++ libopenblas-dev git &&\tapt-get clean &&\tpip3
      install jupyter &&\tln -sf /usr/bin/python3 /usr/bin/python &&\tpip3 install
      --upgrade pip &&\tpip3 install spaCy &&\tpip3 install pyLDAvis scipy gensim
      nltk bokeh py4j &&\tpip3 install -U scikit-learn &&\tpip3 install https://dist.apache.org/repos/dist/dev/incubator/toree/0.2.0/snapshots/dev1/toree-pip/toree-0.2.0.dev1.tar.gz
      &&\tpip3 install toree &&\tpip3 install tensorflow &&\tpip3 install keras &&\tjupyter
      toree install --replace --interpreters=Scala,PySpark --spark_home=$SPARK_HOME
      --spark_opts=$SPARK_OPTS"
    Name: run
    PrependShell: true
  - CmdLine:
    - "wget -q https://raw.githubusercontent.com/channelit/docker-images/master/spark-yarn/firststart.sh
      -O /firststart.sh &&\tchmod 755 firststart.sh"
    Name: run
    PrependShell: true
  - CmdLine:
    - "touch /home/hadoop/spark/spark/conf/spark-env.sh &&\techo \"#!/bin/sh\" >>
      /home/hadoop/spark/spark/conf/spark-env.sh &&\techo \"export PYSPARK_PYTHON=python\"
      >> /home/hadoop/spark/spark/conf/spark-env.sh &&\techo \"export PYTHONPATH=$PYTHONPATH:/home/hadoop/spark/spark/graphframes.jar:.\"
      >> /home/hadoop/spark/spark/conf/spark-env.sh"
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "4040"
    - "7077"
    - "8031"
    - "8032"
    - "8033"
    - "8080"
    - "8081"
    - "8888"
    - "9000"
  From:
    Image: cithub/hadoop
  Name: ""
  Platform: ""
  SourceCode: FROM cithub/hadoop
