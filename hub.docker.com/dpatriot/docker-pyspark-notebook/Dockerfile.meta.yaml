MetaArgs: null
Stages:
- BaseName: dpatriot/docker-spark:1.5
  Commands:
  - Maintainer: Shago Vyacheslav <v.shago@corpwebgames.com>
    Name: maintainer
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python/:$PYTHONPATH
    Name: env
  - CmdLine:
    - apt-get update     && apt-get install -y build-essential     python     python-dev     python-pip     python-zmq     &&
      rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install py4j     ipython[notebook]==3.2     jsonschema     jinja2     terminado     tornado
    Name: run
    PrependShell: true
  - CmdLine:
    - ipython profile create pyspark
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - pyspark-notebook.py
    - /root/.ipython/profile_pyspark/startup/pyspark-notebook.py
  - Name: volume
    Volumes:
    - /notebook
  - Name: workdir
    Path: /notebook
  - Name: expose
    Ports:
    - "8888"
  - CmdLine: null
    Name: entrypoint
    PrependShell: false
  - Chown: ""
    Name: add
    SourcesAndDest:
    - requirements.txt
    - /opt/
  - Env:
    - Key: DEBIAN_FRONTEND
      Value: noninteractive
    Name: env
  - CmdLine:
    - sed -i 's/^#\s*\(deb.*universe\)$/\1/g' /etc/apt/sources.list
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get -y update && apt-get install -y     mysql-client     gfortran     libopenblas-dev     liblapack-dev     libmysqlclient*     libtiff5-dev     libjpeg8-dev     zlib1g-dev     libfreetype6-dev     libpq-dev     libxft-dev     pkg-config     python2.7     python-dev     python-pip     tmux     curl     nano     vim     git     htop     man     software-properties-common     unzip     wget     libncurses5-dev     readline-common
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get build-dep -y python-matplotlib
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install -r /opt/requirements.txt &&     pip install --pre xgboost &&     pip
      install certifi==2015.04.28
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_CLASSPATH
      Value: /usr/local/spark/jars/mysql-connector-java.jar:/usr/local/spark/jars/spark-avro.jar:/usr/local/spark/jars/spark-redshift.jar:/usr/local/spark/jars/RedshiftJDBC41-1.1.10.1010.jar:/usr/local/spark/jars/minimal-json.jar
    Name: env
  - CmdLine:
    - aws s3 cp s3://$S3_BUCKET_CONF/hive/config/core-site.xml /usr/local/spark/conf/core-site.xml;aws
      s3 cp s3://$S3_BUCKET_CONF/hive/config/hive-site.xml /usr/local/spark/conf/hive-site.xml;ipython
      notebook --no-browser --profile=pyspark --ip=*
    Name: cmd
    PrependShell: true
  From:
    Image: dpatriot/docker-spark:1.5
  Name: ""
  Platform: ""
  SourceCode: FROM dpatriot/docker-spark:1.5
