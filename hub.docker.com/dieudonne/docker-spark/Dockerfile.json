{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "centos:7",
      "SourceCode": "FROM centos:7",
      "Platform": "",
      "From": {
        "Image": "centos:7"
      },
      "Commands": [
        {
          "Maintainer": "Dieudonne lx \u003clx.simon@yahoo.com\u003e",
          "Name": "maintainer"
        },
        {
          "Env": [
            {
              "Key": "TZ",
              "Value": "Asia/Shanghai"
            },
            {
              "Key": "LANG",
              "Value": "en_US.UTF-8"
            },
            {
              "Key": "LC_ALL",
              "Value": "en_US.UTF-8"
            },
            {
              "Key": "TERM",
              "Value": "xterm"
            },
            {
              "Key": "SLUGIFY_USES_TEXT_UNIDECODE",
              "Value": "yes"
            },
            {
              "Key": "HADOOP_VERSION",
              "Value": "2.7.2"
            },
            {
              "Key": "SPARK_VERSION",
              "Value": "2.3.2"
            },
            {
              "Key": "SPARK_HADOOP_VERSION",
              "Value": "2.7"
            },
            {
              "Key": "USER_PATH",
              "Value": "/usr/local"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "JAVA_HOME",
              "Value": "${USER_PATH}/jdk1.8.0"
            },
            {
              "Key": "HADOOP_HOME",
              "Value": "${USER_PATH}/hadoop"
            },
            {
              "Key": "SPARK_HOME",
              "Value": "${USER_PATH}/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "HADOOP_CONF_DIR",
              "Value": "${HADOOP_HOME}/etc/hadoop"
            },
            {
              "Key": "PATH",
              "Value": "${USER_PATH}/python3/bin:$JAVA_HOME/bin:${HADOOP_HOME}/bin:$SPARK_HOME/bin:$PATH"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "yum -y update     \u0026\u0026 yum install -y which openssh openssh-clients openssh-server bzip2 vim sudo unzip     \u0026\u0026 yum clean all -y     \u0026\u0026 rm -rf /var/cache/yum"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "ln -sf /usr/share/zoneinfo/$TZ /etc/localtime"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "localedef -i en_US -f UTF-8 en_US.UTF-8"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "sed -i -e '/Defaults    requiretty/{ s/.*/# Defaults    requiretty/ }' /etc/sudoers"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "curl -o /opt/jdk8.tar.gz -v -j -k -L -H \"Cookie: oraclelicense=accept-securebackup-cookie\" https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk-8u201-linux-x64.tar.gz     \u0026\u0026 tar -xzf /opt/jdk8.tar.gz -C /opt     \u0026\u0026 rm -f /opt/jdk8.tar.gz     \u0026\u0026 mv /opt/jdk1.8.0* ${JAVA_HOME}     \u0026\u0026 tar -C ${USER_PATH} -czf /opt/jdk8.tar.gz jdk1.8.0"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "curl -o conda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \u0026\u0026     bash conda.sh -b -f -p /usr/local/python3 \u0026\u0026     rm -f conda.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "conda update -y --all     \u0026\u0026 conda install -y python=3.6 requests     \u0026\u0026 conda clean --all -y"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "curl -L https://archive.apache.org/dist/hadoop/core/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz | tar -xzf - -C /opt     \u0026\u0026 mv /opt/hadoop-* ${HADOOP_HOME}     \u0026\u0026 chmod -x ${HADOOP_HOME}/bin/*.cmd ${HADOOP_HOME}/sbin/*.cmd"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "curl -L https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}.tgz | tar -xzf - -C /opt     \u0026\u0026 mv /opt/spark-* ${SPARK_HOME}     \u0026\u0026 chmod -x ${SPARK_HOME}/bin/*.cmd"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "conf/spark/*",
            "${SPARK_HOME}/conf/"
          ]
        },
        {
          "CmdLine": [
            "useradd elasticsearch     \u0026\u0026 useradd gdata     \u0026\u0026 useradd baitu"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "workdir",
          "Path": "/opt/baitu"
        },
        {
          "Name": "volume",
          "Volumes": [
            "${HADOOP_CONF_DIR}",
            "/opt/baitu",
            "/usr/lib/transwarp/scripts",
            "/etc/transwarp/conf"
          ]
        },
        {
          "Name": "expose",
          "Ports": [
            "19090"
          ]
        },
        {
          "CmdLine": [
            "/bin/bash"
          ],
          "Name": "cmd",
          "PrependShell": false
        }
      ]
    }
  ]
}