{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "openjdk:8u111-jdk",
      "SourceCode": "FROM openjdk:8u111-jdk",
      "Platform": "",
      "From": {
        "Image": "openjdk:8u111-jdk"
      },
      "Commands": [
        {
          "Maintainer": "Francesco Lescai lescai@biomed.au.dk",
          "Name": "maintainer"
        },
        {
          "CmdLine": [
            "apt-get update --fix-missing \u0026\u0026 apt-get install -y     ca-certificates     cmake     g++     git     libc6-dev     wget"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/spark/spark-2.1.0-bin-hadoop2.7"
            },
            {
              "Key": "HAIL_HOME",
              "Value": "/usr/hail"
            },
            {
              "Key": "PATH",
              "Value": "/opt/conda/bin:$PATH:/usr/spark/spark-2.1.0-bin-hadoop2.7/bin:/usr/hail/build/install/hail/bin/"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "echo 'export PATH=/opt/conda/bin:$PATH' \u003e /etc/profile.d/conda.sh \u0026\u0026     wget --quiet https://repo.continuum.io/miniconda/Miniconda2-4.1.11-Linux-x86_64.sh -O ~/miniconda.sh \u0026\u0026     /bin/bash ~/miniconda.sh -b -p /opt/conda \u0026\u0026     rm ~/miniconda.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /usr/spark \u0026\u0026     curl -sL --retry 3     \"https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz\"     | gzip -d     | tar x -C /usr/spark \u0026\u0026     chown -R root:root $SPARK_HOME"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install decorator \u0026\u0026 \tpip install --upgrade pip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr \u0026\u0026 \tcurl --retry 3 -O \t\"https://storage.googleapis.com/hail-common/distributions/0.1/Hail-0.1-20613ed50c74-Spark-2.1.0.zip\" \u0026\u0026 \tunzip Hail-0.1-20613ed50c74-Spark-2.1.0.zip \u0026\u0026     cd ${HAIL_HOME} \u0026\u0026     pip install py4j \u0026\u0026     echo 'alias pyhail=\"PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.3-src.zip:$HAIL_HOME/python SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar python\"' \u003e\u003e ~/.bashrc"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.3-src.zip:$HAIL_HOME/python"
            },
            {
              "Key": "SPARK_CLASSPATH",
              "Value": "$HAIL_HOME/build/libs/hail-all-spark.jar"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "python"
          ],
          "Name": "entrypoint",
          "PrependShell": false
        }
      ]
    }
  ]
}