{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "rocker/tidyverse:3.4",
      "SourceCode": "FROM rocker/tidyverse:3.4",
      "Platform": "",
      "From": {
        "Image": "rocker/tidyverse:3.4"
      },
      "Commands": [
        {
          "Maintainer": "Jaehyeon Kim \u003cdottami@gmail.com\u003e",
          "Name": "maintainer"
        },
        {
          "Key": "HADOOP_VERSION",
          "Name": "arg",
          "Value": null
        },
        {
          "Key": "HADOOP_ARCHIVE",
          "Name": "arg",
          "Value": null
        },
        {
          "Key": "SPARK_VERSION",
          "Name": "arg",
          "Value": null
        },
        {
          "Key": "SPARK_ARCHIVE",
          "Name": "arg",
          "Value": null
        },
        {
          "Key": "DOWNLOAD_URL",
          "Name": "arg",
          "Value": null
        },
        {
          "Env": [
            {
              "Key": "HADOOP_VERSION",
              "Value": "${HADOOP_VERSION:-2.8.3}"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "HADOOP_ARCHIVE",
              "Value": "hadoop-${HADOOP_VERSION}.tar.gz"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_VERSION",
              "Value": "${SPARK_VERSION:-2.2.1}"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_ARCHIVE",
              "Value": "spark-${SPARK_VERSION}-bin-without-hadoop.tgz"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "DOWNLOAD_URL",
              "Value": "${DOWNLOAD_URL:-https://mirrors.ocf.berkeley.edu}"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "JAVA_HOME",
              "Value": "/usr/lib/jvm/java-8-openjdk-amd64"
            },
            {
              "Key": "PATH",
              "Value": "$PATH:$JAVA_HOME/bin"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "apt-get update     \u0026\u0026 apt-get install -y curl procps netcat openjdk-8-jdk"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "HADOOP_HOME",
              "Value": "/usr/local/hadoop-$HADOOP_VERSION"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "mkdir -p \"${HADOOP_HOME}\"     \u0026\u0026 export DOWNLOAD_PATH=apache/hadoop/common/hadoop-${HADOOP_VERSION}/${HADOOP_ARCHIVE}     \u0026\u0026 curl -sSL ${DOWNLOAD_URL}/${DOWNLOAD_PATH} |         tar -xz -C ${HADOOP_HOME} --strip-components 1     \u0026\u0026 rm -rf ${HADOOP_ARCHIVE}"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "HADOOP_CONF_DIR",
              "Value": "${HADOOP_HOME}/etc/hadoop"
            },
            {
              "Key": "HADOOP_LIBEXEC_DIR",
              "Value": "${HADOOP_HOME}/libexec"
            },
            {
              "Key": "PATH",
              "Value": "$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin"
            }
          ],
          "Name": "env"
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "./hadoop-conf/*.xml",
            "$HADOOP_CONF_DIR/"
          ]
        },
        {
          "CmdLine": [
            "sed -i.bak 's/hadoop-daemons.sh/hadoop-daemon.sh/g'         $HADOOP_HOME/sbin/start-dfs.sh     \u0026\u0026 rm -f $HADOOP_HOME/sbin/start-dfs.sh.bak     \u0026\u0026 sed -i.bak 's/hadoop-daemons.sh/hadoop-daemon.sh/g'         $HADOOP_HOME/sbin/stop-dfs.sh     \u0026\u0026 rm -f $HADOOP_HOME/sbin/stop-dfs.sh.bak"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "./hadoop-conf/start*",
            "/opt/util/bin/"
          ]
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:/opt/util/bin"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "echo 'export HADOOP_HOME=$HADOOP_HOME' \u003e /etc/bash.bashrc.tmp     \u0026\u0026 echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:/opt/util/bin' \u003e\u003e /etc/bash.bashrc.tmp     \u0026\u0026 cat /etc/bash.bashrc \u003e\u003e /etc/bash.bashrc.tmp     \u0026\u0026 mv -f /etc/bash.bashrc.tmp /etc/bash.bashrc"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "volume",
          "Volumes": [
            "/opt/hdfs"
          ]
        },
        {
          "Name": "expose",
          "Ports": [
            "14000",
            "50070",
            "50470",
            "8020"
          ]
        },
        {
          "Name": "expose",
          "Ports": [
            "10020",
            "13562",
            "19888"
          ]
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark-$SPARK_VERSION"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "mkdir -p \"${SPARK_HOME}\"     \u0026\u0026 export DOWNLOAD_PATH=apache/spark/spark-${SPARK_VERSION}/${SPARK_ARCHIVE}     \u0026\u0026 curl -sSL ${DOWNLOAD_URL}/${DOWNLOAD_PATH} |         tar -xz -C ${SPARK_HOME} --strip-components 1     \u0026\u0026 rm -rf ${SPARK_ARCHIVE}"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "./spark-conf/spark-env.sh",
            "$SPARK_HOME/conf/spark-env.sh"
          ]
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "./spark-conf/log4j.properties",
            "$SPARK_HOME/conf/log4j.properties"
          ]
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$SPARK_HOME/bin"
            }
          ],
          "Name": "env"
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "./spark-conf/start-spark",
            "/opt/util/bin/start-spark"
          ]
        },
        {
          "CmdLine": [
            "echo 'export SPARK_HOME=$SPARK_HOME' \u003e\u003e /etc/bash.bashrc     \u0026\u0026 echo 'export PATH=$PATH:$SPARK_HOME/bin'\u003e\u003e /etc/bash.bashrc"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "expose",
          "Ports": [
            "6066",
            "7077",
            "8080",
            "8081"
          ]
        }
      ]
    }
  ]
}