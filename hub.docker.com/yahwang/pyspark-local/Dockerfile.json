{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "python:3.7-slim-stretch",
      "SourceCode": "FROM python:3.7-slim-stretch",
      "Platform": "",
      "From": {
        "Image": "python:3.7-slim-stretch"
      },
      "Commands": [
        {
          "Key": "SPARK_VERSION",
          "Name": "arg",
          "Value": "2.4.4"
        },
        {
          "Key": "HADOOP_VERSION",
          "Name": "arg",
          "Value": "2.7"
        },
        {
          "Key": "PYTHON_DEPS",
          "Name": "arg",
          "Value": "\"         jupyterlab==1.2.3         pandas==0.25.3         numpy==1.17.4         pyarrow==0.14.1         \""
        },
        {
          "Env": [
            {
              "Key": "LANG",
              "Value": "en_US.UTF-8"
            },
            {
              "Key": "JAVA_HOME",
              "Value": "/usr/lib/jvm/java-8-openjdk-amd64"
            },
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark"
            },
            {
              "Key": "PATH",
              "Value": "\"/usr/local/spark/bin:$PATH\""
            },
            {
              "Key": "PYTHONHASHSEED",
              "Value": "0"
            },
            {
              "Key": "PYTHONPATH",
              "Value": "\"/usr/local/spark/python:/usr/local/spark/python/lib/py4j-0.10.7-src.zip\""
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "apt-get update  \u0026\u0026 apt-get install -y locales  \u0026\u0026 localedef -f UTF-8 -i en_US en_US.UTF-8  \u0026\u0026 mkdir -p /usr/share/man/man1  \u0026\u0026 apt-get update  \u0026\u0026 apt-get install -y --no-install-recommends         wget         ca-certificates         gnupg         openjdk-8-jre-headless  \u0026\u0026 apt-get remove -yqq     gnupg  \u0026\u0026 apt-get autoremove -yqq --purge  \u0026\u0026 apt-get clean  \u0026\u0026 rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "wget -q http://apache.mirror.cdnetworks.com/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz  \u0026\u0026 tar xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz -C /usr/local  \u0026\u0026 mv /usr/local/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /usr/local/spark  \u0026\u0026 rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz  \u0026\u0026 wget -q http://central.maven.org/maven2/com/amazonaws/aws-java-sdk/1.7.4/aws-java-sdk-1.7.4.jar -P $SPARK_HOME/jars/  \u0026\u0026 wget -q http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.7.7/hadoop-aws-2.7.7.jar -P $SPARK_HOME/jars/  \u0026\u0026 cp $SPARK_HOME/conf/spark-defaults.conf.template $SPARK_HOME/conf/spark-defaults.conf  \u0026\u0026 echo \"spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem\" \u003e\u003e $SPARK_HOME/conf/spark-defaults.conf  \u0026\u0026 echo \"spark.sql.execution.arrow.enabled=true\" \u003e\u003e $SPARK_HOME/conf/spark-defaults.conf"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install --no-cache-dir     ${PYTHON_DEPS}"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "expose",
          "Ports": [
            "4040-4042",
            "8888"
          ]
        },
        {
          "Name": "workdir",
          "Path": "/home/notebooks"
        },
        {
          "CmdLine": [
            "jupyter",
            "lab",
            "--ip=0.0.0.0",
            "--NotebookApp.token=''",
            "--allow-root",
            "--no-browser"
          ],
          "Name": "cmd",
          "PrependShell": false
        }
      ]
    }
  ]
}