MetaArgs: null
Stages:
- BaseName: jingyuan4ever/java:latest
  Commands:
  - Maintainer: jingyuan
    Name: maintainer
  - CmdLine:
    - "apt-get update && \tapt-get install -y --no-install-recommends ssh rsync curl"
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_VERSION
      Value: 2.8.1
    Name: env
  - Env:
    - Key: HADOOP_URL
      Value: https://www.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz
    Name: env
  - CmdLine:
    - "set -x \t&& curl -fSL \"$HADOOP_URL\" -o /tmp/hadoop.tar.gz \t&& curl -fSL
      \"$HADOOP_URL.asc\" -o /tmp/hadoop.tar.gz.asc \t&& curl -fSL \"https://dist.apache.org/repos/dist/release/hadoop/common/KEYS\"
      -o /tmp/HADOOP_KEYS \t&& gpg --import /tmp/HADOOP_KEYS \t&& gpg --verify /tmp/hadoop.tar.gz.asc
      \t&& tar -xvf /tmp/hadoop.tar.gz -C /opt/ \t&& rm /tmp/hadoop.tar.gz*"
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_VERSION
      Value: 2.2.0
    Name: env
  - Env:
    - Key: SPARK_URL
      Value: http://www.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop2.7.tgz
    Name: env
  - CmdLine:
    - "set -x \t&& curl -fSL \"$SPARK_URL\" -o /tmp/spark.tar.gz \t&& curl -fSL \"$SPARK_URL.asc\"
      -o /tmp/spark.tar.gz.asc \t&& curl -fSL \"https://www.apache.org/dist/spark/KEYS\"
      -o /tmp/SPARK_KEYS \t&& gpg --import /tmp/SPARK_KEYS \t&& gpg --verify /tmp/spark.tar.gz.asc
      \t&& tar -xvf /tmp/spark.tar.gz -C /opt/ \t&& rm /tmp/spark.tar.gz*"
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/hadoop-$HADOOP_VERSION/etc/hadoop /etc/hadoop
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_HOME
      Value: /opt/hadoop-$HADOOP_VERSION
    Name: env
  - Env:
    - Key: PATH
      Value: $HADOOP_HOME/bin/:$PATH
    Name: env
  - Env:
    - Key: LD_LIBRARY_PATH
      Value: $HADOOP_HOME/lib/native
    Name: env
  - CmdLine:
    - ln -s /opt/spark-$SPARK_VERSION-bin-hadoop2.7 /etc/spark
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark-$SPARK_VERSION-bin-hadoop2.7
    Name: env
  - Env:
    - Key: PATH
      Value: $SPARK_HOME/bin/:$PATH
    Name: env
  - CmdLine:
    - apt-get install -y --no-install-recommends python3 python3-pip
    Name: run
    PrependShell: true
  - CmdLine:
    - "ln -s /usr/bin/python3 /usr/bin/python \t&& ln -s /usr/bin/pip3 /usr/bin/pip"
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install requests
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /root
  - Chown: ""
    Name: add
    SourcesAndDest:
    - entrypoint.sh
    - /entrypoint.sh
  - CmdLine:
    - chmod a+x /entrypoint.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - /entrypoint.sh
    Name: entrypoint
    PrependShell: false
  From:
    Image: jingyuan4ever/java:latest
  Name: ""
  Platform: ""
  SourceCode: FROM jingyuan4ever/java:latest
