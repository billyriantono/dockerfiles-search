MetaArgs: null
Stages:
- BaseName: benchflow/base-images:dns-envconsul-java8_dev
  Commands:
  - Maintainer: Vincenzo FERME <info@vincenzoferme.it>
    Name: maintainer
  - Env:
    - Key: SPARK_HOME
      Value: /usr/spark
    Name: env
  - Env:
    - Key: SPARK_VERSION
      Value: 1.6.2
    Name: env
  - Env:
    - Key: PYSPARK_PYTHON
      Value: python2.7
    Name: env
  - Env:
    - Key: PYSPARK_CASSANDRA_VERSION
      Value: 0.3.5
    Name: env
  - Env:
    - Key: HADOOP_VERSION
      Value: "2.6"
    Name: env
  - Env:
    - Key: GLIBC_VERSION
      Value: 2.23-r3
    Name: env
  - Env:
    - Key: LANG
      Value: C.UTF-8
    Name: env
  - Env:
    - Key: MINICONDA_PYTHON_VERSION
      Value: "2"
    Name: env
  - Env:
    - Key: MINICONDA_VERSION
      Value: 4.0.5
    Name: env
  - Env:
    - Key: DATA_ANALYSES_SCHEDULER_VERSION
      Value: v-dev
    Name: env
  - Env:
    - Key: DATA_TRANSFORMERS_VERSION
      Value: v-dev
    Name: env
  - Env:
    - Key: ANALYSERS_VERSION
      Value: v-dev
    Name: env
  - Env:
    - Key: PLUGINS_VERSION
      Value: v-dev
    Name: env
  - Env:
    - Key: REGULAR_PYTHON
      Value: /usr/bin/python2.7
    Name: env
  - Env:
    - Key: CONDA_PYTHON
      Value: /opt/conda/bin/python2.7
    Name: env
  - Env:
    - Key: CONDA_DIR
      Value: /opt/conda
    Name: env
  - Env:
    - Key: PATH
      Value: $CONDA_DIR/bin:$PATH
    Name: env
  - CmdLine:
    - "apk --update add curl wget tar python &&     wget -q --no-check-certificate
      -O /app/data-analyses-scheduler https://github.com/benchflow/data-analyses-scheduler/releases/download/$DATA_ANALYSES_SCHEDULER_VERSION/data-analyses-scheduler
      &&     chmod +x /app/data-analyses-scheduler &&     curl \t--location \t--retry
      10 \thttp://d3kbcqa49mib13.cloudfront.net/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz
      \t| gunzip \t| tar x -C /usr/ &&     ln -s /usr/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION
      /usr/spark &&     mkdir -p /app/configuration &&     mkdir -p /app/data-transformers
      &&     wget -q --no-check-certificate -O - https://github.com/benchflow/data-transformers/archive/$DATA_TRANSFORMERS_VERSION.tar.gz
      \    | tar xz --strip-components=2 -C /app/data-transformers data-transformers-$DATA_TRANSFORMERS_VERSION/data-transformers
      &&     wget -q --no-check-certificate -O - https://github.com/benchflow/data-transformers/archive/$DATA_TRANSFORMERS_VERSION.tar.gz
      \    | tar xz --strip-components=1 --wildcards --no-anchored '*.scheduler.configuration.yml'
      &&     for f in *.scheduler.configuration.yml; do mv -i \"$f\" \"app/configuration/$f\";
      done  &&     mkdir -p /app/analysers &&     wget -q --no-check-certificate -O
      - https://github.com/benchflow/analysers/archive/$ANALYSERS_VERSION.tar.gz     |
      tar xz --strip-components=2 -C /app/analysers analysers-$ANALYSERS_VERSION/analysers
      &&     wget -q --no-check-certificate -O - https://github.com/benchflow/analysers/archive/$ANALYSERS_VERSION.tar.gz
      \    | tar xz --strip-components=1 --wildcards --no-anchored '*.scheduler.configuration.yml'
      &&     for f in *.scheduler.configuration.yml; do mv -i \"$f\" \"app/configuration/$f\";
      done  &&     mkdir -p /app/data-transformers/suts &&     wget -q --no-check-certificate
      -O - https://github.com/benchflow/sut-plugins/archive/$PLUGINS_VERSION.tar.gz
      \    | tar xz --strip-components=1 -C /app/data-transformers/suts --wildcards
      --no-anchored 'data-transformers.configuration.yml' &&     apk del --purge curl
      wget tar &&     rm -rf /var/cache/apk/*"
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./configuration.yml
    - /app/configuration.yml
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./dependencies/pyspark-cassandra-assembly-$PYSPARK_CASSANDRA_VERSION.jar
    - $SPARK_HOME/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./configuration/spark/log4j.properties
    - $SPARK_HOME/conf/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./services/envcp/config.tpl
    - /app/config.tpl
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./services/300-data-analyses-scheduler.conf
    - /apps/chaperone.d/300-data-analyses-scheduler.conf
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./services/400-clean-tmp-folder.conf
    - /apps/chaperone.d/400-clean-tmp-folder.conf
  - CmdLine:
    - cp $SPARK_HOME/conf/spark-defaults.conf.template $SPARK_HOME/conf/spark-defaults.conf     &&
      sed -i -e '$aspark.ui.enabled false' $SPARK_HOME/conf/spark-defaults.conf
    Name: run
    PrependShell: true
  - CmdLine:
    - apk upgrade --update &&     apk add --update curl ca-certificates bash git bzip2
      unzip sudo libstdc++ glib libxext libxrender &&     for pkg in glibc-${GLIBC_VERSION}
      glibc-bin-${GLIBC_VERSION} glibc-i18n-${GLIBC_VERSION}; do curl -sSL https://github.com/andyshinn/alpine-pkg-glibc/releases/download/${GLIBC_VERSION}/${pkg}.apk
      -o /tmp/${pkg}.apk; done &&     apk add --allow-untrusted /tmp/*.apk &&     rm
      -v /tmp/*.apk &&     ( /usr/glibc-compat/bin/localedef --force --inputfile POSIX
      --charmap UTF-8 C.UTF-8 || true ) &&     echo "export LANG=C.UTF-8" > /etc/profile.d/locale.sh
      &&     /usr/glibc-compat/sbin/ldconfig /lib /usr/glibc-compat/lib &&     mkdir
      -p $CONDA_DIR &&     echo export PATH=$CONDA_DIR/bin:'$PATH' > /etc/profile.d/conda.sh
      &&     curl https://repo.continuum.io/miniconda/Miniconda${MINICONDA_PYTHON_VERSION}-${MINICONDA_VERSION}-Linux-x86_64.sh  -o
      mconda.sh &&     /bin/bash mconda.sh -f -b -p $CONDA_DIR &&     rm mconda.sh
      &&     $CONDA_DIR/bin/conda install --yes conda==${MINICONDA_VERSION} &&     conda
      install scipy &&     conda install pytz &&     conda install -c anaconda dateutil=2.4.1
      &&     apk del glibc-i18n
    Name: run
    PrependShell: true
  - CmdLine:
    - sed -i -e '$a@testing http://dl-4.alpinelinux.org/alpine/edge/testing' /etc/apk/repositories     &&
      apk --update add py-yaml py-dateutil
    Name: run
    PrependShell: true
  - CmdLine:
    - apk --update add py-pip     && pip install --upgrade pip     && ${REGULAR_PYTHON}
      /usr/bin/pip install future     && ${REGULAR_PYTHON} /usr/bin/pip install minio     &&
      apk del --purge py-pip     && rm -rf /var/cache/apk/*
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "8080"
  From:
    Image: benchflow/base-images:dns-envconsul-java8_dev
  Name: ""
  Platform: ""
  SourceCode: FROM benchflow/base-images:dns-envconsul-java8_dev
