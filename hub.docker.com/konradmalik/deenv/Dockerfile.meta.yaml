MetaArgs: null
Stages:
- BaseName: ubuntu:18.04
  Commands:
  - Env:
    - Key: LANG
      Value: C.UTF-8
    Name: env
  - Env:
    - Key: DEBIAN_FRONTEND
      Value: noninteractive
    Name: env
  - Env:
    - Key: APT_INSTALL
      Value: '"apt-get update && apt-get install -y --no-install-recommends --fix-missing"'
    Name: env
  - Env:
    - Key: PIP_INSTALL
      Value: '"python -m pip --no-cache-dir install --upgrade"'
    Name: env
  - Env:
    - Key: GIT_CLONE
      Value: '"git clone --depth 10"'
    Name: env
  - CmdLine:
    - rm -rf /var/lib/apt/lists/*            /etc/apt/sources.list.d/cuda.list            /etc/apt/sources.list.d/nvidia-ml.list
      &&     apt-get update
    Name: run
    PrependShell: true
  - CmdLine:
    - "eval $APT_INSTALL         build-essential         apt-utils         ca-certificates
      \        sudo         wget         git         vim         curl         unzip
      \        unrar         cmake \t\ttmux"
    Name: run
    PrependShell: true
  - Env:
    - Key: PYTHON_COMPAT_VERSION
      Value: "3.7"
    Name: env
  - CmdLine:
    - "eval $APT_INSTALL         software-properties-common && \tadd-apt-repository
      ppa:deadsnakes/ppa &&     apt-get update && \teval $APT_INSTALL         python${PYTHON_COMPAT_VERSION}
      \        python${PYTHON_COMPAT_VERSION}-dev         python3-distutils-extra
      \t\tlibblas-dev liblapack-dev libatlas-base-dev gfortran         &&     wget
      -O ~/get-pip.py         https://bootstrap.pypa.io/get-pip.py &&     python${PYTHON_COMPAT_VERSION}
      ~/get-pip.py &&     ln -s /usr/bin/python${PYTHON_COMPAT_VERSION} /usr/local/bin/python3
      &&     ln -s /usr/bin/python${PYTHON_COMPAT_VERSION} /usr/local/bin/python &&
      \    $PIP_INSTALL         setuptools         numpy         scipy         pandas
      \        cloudpickle \t\tjoblib"
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_VERSION
      Value: "8"
    Name: env
  - Env:
    - Key: SCALA_VERSION
      Value: 2.11.12
    Name: env
  - CmdLine:
    - "eval $APT_INSTALL         openjdk-$JAVA_VERSION-jdk \t\tscala         &&     $PIP_INSTALL
      \        koalas"
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-$JAVA_VERSION-openjdk-amd64
    Name: env
  - CmdLine:
    - eval $APT_INSTALL     npm  nodejs &&     npm install -g configurable-http-proxy
      &&     $PIP_INSTALL         jupyterhub jupyterlab &&         jupyterhub --generate-config
    Name: run
    PrependShell: true
  - CmdLine:
    - "$PIP_INSTALL \t\tmlflow && \t\tsed -i 's/127.0.0.1/0.0.0.0/g' /usr/local/lib/python${PYTHON_COMPAT_VERSION}/dist-packages/mlflow/cli.py
      &&         curl -LO http://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
      &&         bash Miniconda3-latest-Linux-x86_64.sh -p /miniconda -b &&         rm
      Miniconda3-latest-Linux-x86_64.sh"
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: ${PATH}:/miniconda/bin
    Name: env
  - CmdLine:
    - conda init &&         conda config --set auto_activate_base false
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_VERSION
      Value: 2.10.0
    Name: env
  - Env:
    - Key: HADOOP_ARCHIVE
      Value: https://www-eu.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz
    Name: env
  - Env:
    - Key: HADOOP_HOME
      Value: /usr/local/hadoop-$HADOOP_VERSION
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: $HADOOP_HOME/etc/hadoop
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$HADOOP_HOME/bin
    Name: env
  - CmdLine:
    - curl -s $HADOOP_ARCHIVE | tar -xz -C /usr/local/
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_VERSION
      Value: 2.4.4
    Name: env
  - Env:
    - Key: SPARK_ARCHIVE
      Value: https://www-eu.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-without-hadoop.tgz
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /usr/local/spark-${SPARK_VERSION}-bin-without-hadoop
    Name: env
  - Env:
    - Key: SPARK_LOG
      Value: /tmp
    Name: env
  - Env:
    - Key: SPARK_HOST
      Value: ""
    Name: env
  - Env:
    - Key: SPARK_MASTER
      Value: ""
    Name: env
  - Env:
    - Key: SPARK_WORKER_CORES
      Value: ""
    Name: env
  - Env:
    - Key: SPARK_WORKER_MEMORY
      Value: ""
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:${SPARK_HOME}/bin
    Name: env
  - CmdLine:
    - curl -s $SPARK_ARCHIVE | tar -zx -C /usr/local/
    Name: run
    PrependShell: true
  - Env:
    - Key: AWS_HADOOP_ARCHIVE
      Value: https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/$HADOOP_VERSION/hadoop-aws-$HADOOP_VERSION.jar
    Name: env
  - Env:
    - Key: AWS_VERSION
      Value: 1.11.271
    Name: env
  - Env:
    - Key: AWS_ARCHIVE
      Value: https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/$AWS_VERSION/aws-java-sdk-$AWS_VERSION.jar
    Name: env
  - Env:
    - Key: AZURE_HADOOP_ARCHIVE
      Value: https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/$HADOOP_VERSION/hadoop-azure-$HADOOP_VERSION.jar
    Name: env
  - Env:
    - Key: AZURE_VERSION
      Value: 7.0.0
    Name: env
  - Env:
    - Key: AZURE_ARCHIVE
      Value: https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/$AZURE_VERSION/azure-storage-$AZURE_VERSION.jar
    Name: env
  - Env:
    - Key: SPARK_CASSANDRA_ARCHIVE
      Value: http://dl.bintray.com/spark-packages/maven/datastax/spark-cassandra-connector/2.4.0-s_2.11/spark-cassandra-connector-2.4.0-s_2.11.jar
    Name: env
  - Env:
    - Key: TWITTER_ARCHIVE
      Value: https://repo1.maven.org/maven2/com/twitter/jsr166e/1.1.0/jsr166e-1.1.0.jar
    Name: env
  - CmdLine:
    - cd $SPARK_HOME/jars &&     curl -LO $AWS_ARCHIVE &&     curl -LO $AWS_HADOOP_ARCHIVE
      &&     curl -LO $AZURE_ARCHIVE &&     curl -LO $AZURE_HADOOP_ARCHIVE &&     curl
      -LO $SPARK_CASSANDRA_ARCHIVE &&     curl -LO $TWITTER_ARCHIVE
    Name: run
    PrependShell: true
  - CmdLine:
    - $PIP_INSTALL koalas
    Name: run
    PrependShell: true
  - CmdLine:
    - cp $(ls $SPARK_HOME/python/lib/py4j*) $SPARK_HOME/python/lib/py4j-src.zip
    Name: run
    PrependShell: true
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python/lib/pyspark.zip:$SPARK_HOME/python/lib/py4j-src.zip:$PYTHONPATH
    Name: env
  - Env:
    - Key: ALMOND_VERSION
      Value: 0.6.0
    Name: env
  - CmdLine:
    - curl -Lo coursier https://git.io/coursier-cli &&     chmod +x coursier &&     ./coursier
      bootstrap         -r jitpack         -i user -I user:sh.almond:scala-kernel-api_$SCALA_VERSION:$ALMOND_VERSION         sh.almond:scala-kernel_$SCALA_VERSION:$ALMOND_VERSION         -o
      almond
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/almond-install.sh
    - almond-install.sh
  - CmdLine:
    - chmod +x almond-install.sh &&     ./almond-install.sh &&     rm -rf almond coursier
      almond-install.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - eval $APT_INSTALL         libmysqlclient-dev         libkrb5-dev         libssl-dev         libsasl2-dev
      &&     $PIP_INSTALL "pymssql<3.0" &&     $PIP_INSTALL         apache-airflow[all]
    Name: run
    PrependShell: true
  - Env:
    - Key: AIRFLOW_HOME
      Value: ~/airflow
    Name: env
  - CmdLine:
    - $PIP_INSTALL         dagster         dagster-airflow         dagster-dask         dagster-aws         dagster-bash         dagster-cron         dagster-pandas         dagster-postgres         dagster-pyspark         dagster-spark         dagster-ssh         &&
      $PIP_INSTALL dagit
    Name: run
    PrependShell: true
  - Env:
    - Key: POLYNOTE_VERSION
      Value: 0.2.11
    Name: env
  - Env:
    - Key: POLYNOTE_ARCHIVE
      Value: https://github.com/polynote/polynote/releases/download/$POLYNOTE_VERSION/polynote-dist.tar.gz
    Name: env
  - CmdLine:
    - curl -sL $POLYNOTE_ARCHIVE | tar -zx -C /usr/local/
    Name: run
    PrependShell: true
  - Env:
    - Key: POLYNOTE_HOME
      Value: /usr/local/polynote
    Name: env
  - CmdLine:
    - $PIP_INSTALL     jep jedi virtualenv
    Name: run
    PrependShell: true
  - CmdLine:
    - ldconfig &&     apt-get clean &&     apt-get -y autoremove &&     rm -rf /var/lib/apt/lists/*
      /tmp/* ~/*
    Name: run
    PrependShell: true
  - Env:
    - Key: DEFAULT_USER
      Value: deenv
    Name: env
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/add-user.sh
    - add-user.sh
  - CmdLine:
    - chmod +x add-user.sh && ./add-user.sh $DEFAULT_USER
    Name: run
    PrependShell: true
  - CmdLine:
    - chown -R $DEFAULT_USER:$DEFAULT_USER $SPARK_HOME
    Name: run
    PrependShell: true
  - Env:
    - Key: JUPYTER_LAB_TOKEN
      Value: $DEFAULT_USER
    Name: env
  - Env:
    - Key: TINI_VERSION
      Value: v0.18.0
    Name: env
  - Chown: ""
    Name: add
    SourcesAndDest:
    - https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini
    - /tini
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/docker-entrypoint.sh
    - .
  - CmdLine:
    - chmod +x /tini && chmod +x docker-entrypoint.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - /tini
    - --
    - /docker-entrypoint.sh
    Name: entrypoint
    PrependShell: false
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/run-*
    - /
  - CmdLine:
    - chmod +x /run-*
    Name: run
    PrependShell: true
  - Name: user
    User: $DEFAULT_USER
  - CmdLine:
    - mkdir -p /home/$DEFAULT_USER/data
    Name: run
    PrependShell: true
  - Name: volume
    Volumes:
    - /home/$DEFAULT_USER/data
  - Name: expose
    Ports:
    - "3000"
  - Name: expose
    Ports:
    - "8888"
  - Name: expose
    Ports:
    - "8000"
  - Name: expose
    Ports:
    - "4040"
  - Name: expose
    Ports:
    - "7077"
  - Name: expose
    Ports:
    - "8081"
  - Name: expose
    Ports:
    - "8192"
  From:
    Image: ubuntu:18.04
  Name: ""
  Platform: ""
  SourceCode: FROM ubuntu:18.04
