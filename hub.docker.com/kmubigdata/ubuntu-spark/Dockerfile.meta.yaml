MetaArgs: null
Stages:
- BaseName: kmubigdata/ubuntu-hadoop
  Commands:
  - Maintainer: kimjeongchul
    Name: maintainer
  - Name: user
    User: root
  - CmdLine:
    - apt-get update
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get install -y scala
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get install -y python
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get install -y python3
    Name: run
    PrependShell: true
  - CmdLine:
    - wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-without-hadoop.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xvzf spark-2.4.0-bin-without-hadoop.tgz -C /usr/local
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /usr/local && ln -s ./spark-2.4.0-bin-without-hadoop spark
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -f /spark-2.4.0-bin-without-hadoop.tgz
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_COMMON_HOME
      Value: /usr/local/hadoop
    Name: env
  - Env:
    - Key: HADOOP_HDFS_HOME
      Value: /usr/local/hadoop
    Name: env
  - Env:
    - Key: HADOOP_MAPRED_HOME
      Value: /usr/local/hadoop
    Name: env
  - Env:
    - Key: HADOOP_YARN_HOME
      Value: /usr/local/hadoop
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: /usr/local/hadoop/etc/hadoop
    Name: env
  - Env:
    - Key: YARN_CONF_DIR
      Value: /usr/local/hadoop/etc/hadoop
    Name: env
  - Env:
    - Key: LD_LIBRARY_PATH
      Value: /usr/local/hadoop/lib/native/:$LD_LIBRARY_PATH
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /usr/local/spark
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
    Name: env
  - Chown: ""
    Name: add
    SourcesAndDest:
    - spark-env.sh
    - $SPARK_HOME/conf/spark-env.sh
  - Chown: ""
    Name: add
    SourcesAndDest:
    - spark-defaults.conf
    - $SPARK_HOME/conf/spark-defaults.conf
  - Chown: ""
    Name: add
    SourcesAndDest:
    - run-sparkshell.sh
    - $SPARK_HOME/run-sparkshell.sh
  - CmdLine:
    - cp $HADOOP_HOME/etc/hadoop/workers $SPARK_HOME/conf/slaves
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - bootstrap.sh
    - /etc/bootstrap.sh
  - CmdLine:
    - chown root.root /etc/bootstrap.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - chmod 700 /etc/bootstrap.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - chmod +x /usr/local/spark/run-sparkshell.sh
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "18080"
    - "8080"
  - Name: expose
    Ports:
    - "7077"
  - CmdLine:
    - apt-get install apt-transport-https
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "deb https://dl.bintray.com/sbt/debian /" | sudo tee -a /etc/apt/sources.list.d/sbt.list
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get update
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get -y install sbt
    Name: run
    PrependShell: true
  - CmdLine:
    - /etc/bootstrap.sh
    Name: entrypoint
    PrependShell: false
  From:
    Image: kmubigdata/ubuntu-hadoop
  Name: ""
  Platform: ""
  SourceCode: FROM kmubigdata/ubuntu-hadoop
