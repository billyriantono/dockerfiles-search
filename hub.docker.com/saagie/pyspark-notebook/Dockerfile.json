{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "saagie/scipy-notebook:PRODUCT-514",
      "SourceCode": "FROM saagie/scipy-notebook:PRODUCT-514",
      "Platform": "",
      "From": {
        "Image": "saagie/scipy-notebook:PRODUCT-514"
      },
      "Commands": [
        {
          "Maintainer": "Saagie",
          "Name": "maintainer"
        },
        {
          "Name": "user",
          "User": "root"
        },
        {
          "Env": [
            {
              "Key": "APACHE_SPARK_VERSION",
              "Value": "2.1.0"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "HADOOP_VERSION",
              "Value": "2.7"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "apt-get -y update \u0026\u0026     apt-get install --no-install-recommends -y openjdk-8-jre-headless ca-certificates-java \u0026\u0026     apt-get clean \u0026\u0026     rm -rf /var/lib/apt/lists/*"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "sudo apt-get update \u0026\u0026     sudo apt-get install acl"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /tmp \u0026\u0026         wget -q http://d3kbcqa49mib13.cloudfront.net/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz \u0026\u0026         echo \"3fc94096ae34f9a1a148d37e5ed640a7e5de1812f1f2ecd715d92bbf2901e895cf4b93e6d8ee0d64debb5df7c56d673c0a36e5fc49503ec0f4507eb0edf961a4 *spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\" | sha512sum -c - \u0026\u0026         tar xzf spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz -C /usr/local \u0026\u0026         rm spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr/local \u0026\u0026 ln -s spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get update \u0026\u0026 apt-get install -my wget gnupg"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "sudo apt-get -y install systemd"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-key adv --keyserver keyserver.ubuntu.com --recv E56151BF \u0026\u0026     DISTRO=debian \u0026\u0026     CODENAME=jessie \u0026\u0026     echo \"deb http://repos.mesosphere.io/${DISTRO} ${CODENAME} main\" \u003e /etc/apt/sources.list.d/mesosphere.list \u0026\u0026     apt-get -y update \u0026\u0026     apt-get --no-install-recommends -y install mesos=1.3.1-2.0.1 \u0026\u0026     apt-get clean \u0026\u0026     rm -rf /var/lib/apt/lists/*"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "MESOS_NATIVE_LIBRARY",
              "Value": "/usr/local/lib/libmesos.so"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_OPTS",
              "Value": "--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info"
            }
          ],
          "Name": "env"
        },
        {
          "Name": "user",
          "User": "$NB_USER"
        }
      ]
    }
  ]
}