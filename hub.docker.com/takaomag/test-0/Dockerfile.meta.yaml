MetaArgs: null
Stages:
- BaseName: quay.io/takaomag/netlib-java:release-1.1.2-2018.03.10.05.27
  Commands:
  - Env:
    - Key: X_DOCKER_REPO_NAME
      Value: spark
    - Key: X_SPARK_VERSION
      Value: 2.3.0
    - Key: SPARK_HOME
      Value: /opt/local/spark
    - Key: PYSPARK_DRIVER_PYTHON
      Value: /opt/local/python-3/bin/python3
    - Key: PYSPARK_PYTHON
      Value: /opt/local/python-3/bin/python3
    - Key: SPARK_EXECUTOR_URI
      Value: file:///opt/local/spark/dist/spark-2.3.0-bin-2.9.0.tgz
    - Key: X_HADOOP_VERSION
      Value: 3.0.0
    - Key: LD_LIBRARY_PATH
      Value: /usr/lib/hadoop/lib/native:$LD_LIBRARY_PATH
    - Key: HADOOP_HOME
      Value: /usr/lib/hadoop
    - Key: HADOOP_PREFIX
      Value: /usr/lib/hadoop
    - Key: HADOOP_COMMON_HOME
      Value: /usr/lib/hadoop
    - Key: HADOOP_HDFS_HOME
      Value: /usr/lib/hadoop
    - Key: HADOOP_YARN_HOME
      Value: /usr/lib/hadoop
    - Key: HADOOP_MAPRED_HOME
      Value: /usr/lib/hadoop
    - Key: HADOOP_COMMON_LIB_NATIVE_DIR
      Value: /usr/lib/hadoop/lib/native
    - Key: HADOOP_CONF_DIR
      Value: /etc/hadoop
    - Key: YARN_CONF_DIR
      Value: /etc/hadoop
    - Key: HADOOP_USER_NAME
      Value: hadoop
    - Key: HADOOP_OPTS
      Value: '"-Djava.library.path=/usr/lib/hadoop/lib/native"'
    - Key: HADOOP_LOG_DIR
      Value: /var/log/hadoop
    - Key: HADOOP_PID_DIR
      Value: /run/hadoop
    - Key: HADOOP_DFS_NAMENODE_NAME_DIR
      Value: file:///var/db/hadoop/dfs/name
    - Key: HADOOP_DFS_NAMENODE_CHECKPOINT_DIR
      Value: file:///var/db/hadoop/dfs/namesecondary
    - Key: HADOOP_DFS_DATANODE_DATA_DIR
      Value: file:///var/db/hadoop/dfs/data
    Name: env
  - CmdLine:
    - 'echo "2016-05-06-1" > /dev/null &&     export TERM=dumb &&     export LANG=''en_US.UTF-8''
      &&     source /opt/local/bin/x-set-shell-fonts-env.sh && : &&     echo -e "${FONT_INFO}[INFO]
      Update package database${FONT_DEFAULT}" &&     reflector --latest 100 --verbose
      --sort score --save /etc/pacman.d/mirrorlist &&     sudo -u x-aur-helper yay
      -Syy --noprogressbar &&     echo -e "${FONT_SUCCESS}[SUCCESS] Update package
      database${FONT_DEFAULT}" && : &&     REQUIRED_PACKAGES=("pandoc" "hadoop" "gperftools"
      "google-glog" "leveldb" "protobuf" "picojson-git") && : &&     echo -e "${FONT_INFO}[INFO]
      Install required packages [${REQUIRED_PACKAGES[@]}]${FONT_DEFAULT}" &&     sudo
      -u x-aur-helper yay -S --needed --noconfirm --noprogressbar ${REQUIRED_PACKAGES[@]}
      &&     echo -e "${FONT_SUCCESS}[SUCCESS] Install required packages [${REQUIRED_PACKAGES[@]}]${FONT_DEFAULT}"
      &&     /opt/local/python-3/bin/pip3 install -U pypandoc && : &&     echo -e
      "${FONT_INFO}[INFO] Install hadoop-${X_HADOOP_VERSION}${FONT_DEFAULT}" &&     for
      _d in $(echo ${HADOOP_DFS_NAMENODE_NAME_DIR} | sed -e ''s/,/ /g'');do       mkdir
      -p --mode=0755 ${_d:7} &&       chown hadoop:hadoop ${_d:7};     done &&     for
      _d in $(echo ${HADOOP_DFS_NAMENODE_CHECKPOINT_DIR} | sed -e ''s/,/ /g'');do       mkdir
      -p --mode=0755 ${_d:7} &&       chown hadoop:hadoop ${_d:7};     done &&     for
      _d in $(echo ${HADOOP_DFS_DATANODE_DATA_DIR} | sed -e ''s/,/ /g'');do       mkdir
      -p --mode=0700 ${_d:7} &&       chown hadoop:hadoop ${_d:7};     done &&     mkdir
      -p --mode=0755 ${HADOOP_LOG_DIR} &&     chown hadoop:hadoop ${HADOOP_LOG_DIR}
      &&     mkdir -p --mode=0744 ${HADOOP_PID_DIR} &&     chown hadoop:hadoop ${HADOOP_PID_DIR}
      &&     echo -e "${FONT_SUCCESS}[SUCCESS] Install hadoop-${X_HADOOP_VERSION}${FONT_DEFAULT}"
      && : &&     echo -e "${FONT_INFO}[INFO] Install spark-${X_SPARK_VERSION}${FONT_DEFAULT}"
      &&     archlinux-java set java-8-openjdk &&     ([ -d /opt/local ] || mkdir
      -p /opt/local) &&     cd /var/tmp &&     if [[ "${X_SPARK_CLONE_REPO_CMD}" ]];then      ${X_SPARK_CLONE_REPO_CMD}
      && mv spark spark-${X_SPARK_VERSION};    elif [[ "${X_SPARK_DOWNLOAD_URI}" ]];then      curl
      --silent --location --fail --retry 5 "${X_SPARK_DOWNLOAD_URI}" | tar xz;    else      APACHE_CLOSER_MIRROR=$(curl
      --silent --location --fail --retry 5 --stderr /dev/null "https://www.apache.org/dyn/closer.cgi?as_json=1"
      | jq -r ''.preferred'') &&       curl --silent --location --fail --retry 5 "${APACHE_CLOSER_MIRROR}spark/spark-${X_SPARK_VERSION}/spark-${X_SPARK_VERSION}.tgz"
      | tar xz;    fi &&     cd spark-${X_SPARK_VERSION} &&     if [[ "${X_SPARK_VERSION}"
      == ''2.1.0'' ]];then        rm -f python/pyspark/cloudpickle.py &&         curl
      --silent --location --fail --retry 5 -o python/pyspark/cloudpickle.py "https://raw.githubusercontent.com/HyukjinKwon/spark/6458d4185da9ed9772bb4317a82b26da784a89ee/python/pyspark/cloudpickle.py"
      &&         rm -f python/pyspark/serializers.py &&         curl --silent --location
      --fail --retry 5 -o python/pyspark/serializers.py "https://raw.githubusercontent.com/HyukjinKwon/spark/6458d4185da9ed9772bb4317a82b26da784a89ee/python/pyspark/serializers.py";    fi
      &&     X_HADOOP_VERSION=2.9.0 &&     cp -ap conf/log4j.properties.template conf/org.log4j.properties.template
      &&     sed --in-place -e ''s|log4j\.rootCategory=INFO|log4j\.rootCategory=WARN|g''
      -e ''s|log4j\.logger\.org\.apache\.spark\.repl\.SparkIMain$exprTyper=INFO|log4j\.logger\.org\.apache\.spark\.repl\.SparkIMain$exprTyper=WARN|g''
      -e ''s|log4j\.logger\.org\.apache\.spark\.repl\.SparkILoop$SparkILoopInterpreter=INFO|log4j\.logger\.org\.apache\.spark\.repl\.SparkILoop$SparkILoopInterpreter=WARN|g''
      conf/log4j.properties.template &&     X_WITH_NETLIB=''-Pnetlib-lgpl'' &&     export
      X_INTERNAL_SPARK_VERSION=$(build/mvn help:evaluate -Dexpression=project.version
      2>/dev/null | egrep -v -e ''^\[.+\]'' | tail -n 1) &&     X_INTERNAL_SPARK_VERSION_MAJOR=$(cut
      -d ''.'' -f 1 <<< ${X_INTERNAL_SPARK_VERSION}) &&     [[ -f ./make-distribution.sh
      ]] && MAKE_DIST_PATH=''./make-distribution.sh'' || MAKE_DIST_PATH=''dev/make-distribution.sh''
      &&     export JAVA_HOME=/usr/lib/jvm/java-8-openjdk &&     export MAVEN_OPTS="-Xmx2g
      -XX:ReservedCodeCacheSize=512m" &&     if [[ ${X_INTERNAL_SPARK_VERSION_MAJOR}
      -ge 2 ]];then      ${MAKE_DIST_PATH} --tgz -Pyarn -Phadoop-2.7 -Dhadoop.version=${X_HADOOP_VERSION}
      -Phive -Phive-thriftserver -Pmesos -Pkubernetes ${X_WITH_NETLIB};    else      ${MAKE_DIST_PATH}
      --tgz --skip-java-test --with-tachyon -Pyarn -Phadoop-2.7 -Dhadoop.version=${X_HADOOP_VERSION}
      -Phive -Phive-thriftserver ${X_WITH_NETLIB};    fi &&     cp -ap dist/conf/log4j.properties.template
      dist/conf/log4j.properties &&     mkdir x_mago_dist &&     tar xvzf spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}.tgz
      -C x_mago_dist/. &&     rm spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}.tgz
      &&     cp /usr/share/java/jna.jar x_mago_dist/spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}/jars/.
      &&     cp -ap x_mago_dist/spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}/conf/log4j.properties.template
      x_mago_dist/spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}/conf/log4j.properties
      &&     cd x_mago_dist/spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}/python
      &&     /opt/local/python-3/bin/python3 setup.py sdist &&     /opt/local/python-3/bin/python3
      setup.py bdist_wheel &&     rm -rf build/ .eggs/ pyspark.egg-info/ &&     cd
      ../../.. &&     tar -C x_mago_dist -czf spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION}.tgz
      spark-${X_INTERNAL_SPARK_VERSION}-bin-${X_HADOOP_VERSION} &&     rm -rf x_mago_dist
      &&     cd dist/python &&     /opt/local/python-3/bin/python3 setup.py sdist
      &&     /opt/local/python-3/bin/python3 setup.py bdist_wheel &&     rm -rf build/
      .eggs/ pyspark.egg-info/ &&     cd ../.. &&     porg --log --package="spark-${X_SPARK_VERSION}"
      -- mv dist /opt/local/spark-${X_SPARK_VERSION} &&     porg --log --package="spark-${X_SPARK_VERSION}"
      -+ -- mkdir /opt/local/spark-${X_SPARK_VERSION}/dist &&     porg --log --package="spark-${X_SPARK_VERSION}"
      -+ -- mv spark-${X_INTERNAL_SPARK_VERSION}*.tgz /opt/local/spark-${X_SPARK_VERSION}/dist/.
      &&     cd /opt/local &&     porg --log --package="spark-${X_SPARK_VERSION}"
      -+ -- ln -sf spark-${X_SPARK_VERSION} spark &&     porg --log --package="spark-${X_SPARK_VERSION}"
      -+ -- cp /usr/share/java/jna.jar spark-${X_SPARK_VERSION}/jars/. &&     rm -rf
      /var/tmp/spark-${X_SPARK_VERSION} &&     /opt/local/python-3/bin/pip3 install
      -U /opt/local/spark/python/dist/*.whl &&     archlinux-java set java-9-openjdk
      &&     rm -rf /root/.m2/repository &&     rm -rf /root/.ivy2/cache &&     rm
      -rf /root/.gradle/caches &&     echo -e "${FONT_SUCCESS}[SUCCESS] Install spark-${X_SPARK_VERSION}${FONT_DEFAULT}"
      && : &&     /opt/local/bin/x-archlinux-remove-unnecessary-files.sh &&     rm
      -f /etc/machine-id'
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /opt/local/spark
  From:
    Image: quay.io/takaomag/netlib-java:release-1.1.2-2018.03.10.05.27
  Name: ""
  Platform: ""
  SourceCode: FROM quay.io/takaomag/netlib-java:release-1.1.2-2018.03.10.05.27
