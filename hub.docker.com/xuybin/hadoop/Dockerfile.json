{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "alpine:latest",
      "SourceCode": "FROM alpine:latest",
      "Platform": "",
      "From": {
        "Image": "alpine:latest"
      },
      "Commands": [
        {
          "Name": "volume",
          "Volumes": [
            "/hdfs"
          ]
        },
        {
          "CmdLine": [
            "HADOOP_VER=2.7.5  \u0026\u0026 URL1=\"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VER/hadoop-$HADOOP_VER.tar.gz\"  \u0026\u0026 URL2=\"https://mirrors.aliyun.com/apache/hadoop/common/hadoop-$HADOOP_VER/hadoop-$HADOOP_VER.tar.gz\"  \u0026\u0026 apk --update add --no-cache wget tar openssh bash openjdk8  \u0026\u0026 (wget -t 10 --max-redirect 1 --retry-connrefused -O \"hadoop-$HADOOP_VER.tar.gz\" \"$URL1\" || \t\t wget -t 10 --max-redirect 1 --retry-connrefused -O \"hadoop-$HADOOP_VER.tar.gz\" \"$URL2\")  \u0026\u0026 sed -i -e \"s/bin\\/ash/bin\\/bash/\" /etc/passwd  \u0026\u0026 ssh-keygen -A  \u0026\u0026 ssh-keygen -t rsa -f /root/.ssh/id_rsa -P ''  \u0026\u0026 cat /root/.ssh/id_rsa.pub \u003e\u003e /root/.ssh/authorized_keys  \u0026\u0026 { \t\t echo 'Host *'; \t\t echo '  UserKnownHostsFile /dev/null'; \t\t echo '  StrictHostKeyChecking no'; \t\t echo '  LogLevel quiet'; \t  } \u003e /root/.ssh/config  \u0026\u0026 mkdir -p /hadoop  \u0026\u0026 tar zxf hadoop-$HADOOP_VER.tar.gz -C /hadoop --strip 1  \u0026\u0026 sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/lib/jvm/default-jvm\\nexport HADOOP_PREFIX=/hadoop\\nexport HADOOP_HOME=/hadoop\\nexport HADOOP_CLASSPATH=/hadoop/share/hadoop/tools/lib/*\\n:' /hadoop/etc/hadoop/hadoop-env.sh  \u0026\u0026 sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/hadoop/etc/hadoop\\nexport HADOOP_LOG_DIR=/hdfs/logs\\nexport HADOOP_PID_DIR=/hdfs/pids\\n:' /hadoop/etc/hadoop/hadoop-env.sh  \u0026\u0026 sed -i '/^export YARN_CONF_DIR/ s:.*:export YARN_CONF_DIR=/hadoop/etc/hadoop\\nexport YARN_LOG_DIR=/hdfs/logs\\nexport YARN_PID_DIR=/hdfs/pids\\n:' /hadoop/etc/hadoop/yarn-env.sh  \u0026\u0026 echo -e  '\u003c?xml version=\"1.0\"?\u003e\\n\u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e\\n''\u003cconfiguration\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003edfs.namenode.name.dir\u003c/name\u003e\\n''        \u003cvalue\u003efile:///hdfs/namenode\u003c/value\u003e\\n''    \u003c/property\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003edfs.datanode.data.dir\u003c/name\u003e\\n''        \u003cvalue\u003efile:///hdfs/datanode\u003c/value\u003e\\n''    \u003c/property\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003edfs.replication\u003c/name\u003e\\n''        \u003cvalue\u003e2\u003c/value\u003e\\n''    \u003c/property\u003e\\n''\u003c/configuration\u003e\\n'\u003e/hadoop/etc/hadoop/hdfs-site.xml  \u0026\u0026 echo -e  '\u003c?xml version=\"1.0\"?\u003e\\n\u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e\\n''\u003cconfiguration\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003emapreduce.framework.name\u003c/name\u003e\\n''        \u003cvalue\u003eyarn\u003c/value\u003e\\n''    \u003c/property\u003e\\n''\u003c/configuration\u003e\\n'\u003e/hadoop/etc/hadoop/mapred-site.xml  \u0026\u0026 echo -e  '\u003c?xml version=\"1.0\"?\u003e\\n\u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e\\n''\u003cconfiguration\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003efs.defaultFS\u003c/name\u003e\\n''        \u003cvalue\u003ehdfs://master:9000/\u003c/value\u003e\\n''    \u003c/property\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e\\n''        \u003cvalue\u003e/hdfs/tmp\u003c/value\u003e\\n''    \u003c/property\u003e\\n''\u003c/configuration\u003e\\n'\u003e/hadoop/etc/hadoop/core-site.xml  \u0026\u0026 echo -e  '\u003c?xml version=\"1.0\"?\u003e\\n\u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e\\n''\u003cconfiguration\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e\\n''        \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e\\n''    \u003c/property\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003eyarn.nodemanager.aux-services.mapreduce_shuffle.class\u003c/name\u003e\\n''        \u003cvalue\u003eorg.apache.hadoop.mapred.ShuffleHandler\u003c/value\u003e\\n''    \u003c/property\u003e\\n''    \u003cproperty\u003e\\n''        \u003cname\u003eyarn.resourcemanager.hostname\u003c/name\u003e\\n''        \u003cvalue\u003emaster\u003c/value\u003e\\n''    \u003c/property\u003e\\n''\u003c/configuration\u003e\\n'\u003e/hadoop/etc/hadoop/yarn-site.xml  \u0026\u0026 echo -e '#!/bin/bash\\n''/hadoop/sbin/start-dfs.sh\\n''/hadoop/sbin/start-yarn.sh\\n'\u003e/start-hadoop.sh  \u0026\u0026 chmod -v +x /start-hadoop.sh  \u0026\u0026 echo -e '#!/bin/bash\\n''/hadoop/sbin/stop-yarn.sh\\n''/hadoop/sbin/stop-dfs.sh\\n'\u003e/stop-hadoop.sh  \u0026\u0026 chmod -v +x /stop-hadoop.sh  \u0026\u0026 echo -e '#!/bin/bash\\n''export JAVA_HOME=\"/usr/lib/jvm/default-jvm\"\\n''export PATH=\"$PATH:/usr/lib/jvm/default-jvm/bin:/hadoop/bin:/hadoop/sbin\"\\n'\u003e/etc/profile.d/hadoop.sh  \u0026\u0026 echo -e 'if [ -z ${JAVA_HOME} ]; then\\n''    source /etc/profile\\n''fi\\n'\u003e/root/.bashrc  \u0026\u0026 echo -e '#!/bin/sh\\n''if [ ! -d \"/hdfs/logs\" ]; then\\n''    mkdir -p /hdfs/logs /hdfs/pids /hdfs/tmp\\n''fi\\n''if [ ! -d \"/hdfs/namenode\" ]; then\\n''    mkdir -p /hdfs/namenode /hdfs/datanode\\n''    /hadoop/bin/hdfs namenode -format\\n''fi\\n''if [ -z ${SLAVES} ]; then\\n''    SLAVES=\"slave1,slave2\"\\n''fi\\n''awk \"BEGIN{info=\\\"$SLAVES\\\";tlen=split(info,tA,\\\",\\\");for(k=1;k\u003c=tlen;k++){print tA[k];}}\"\u003e/hadoop/etc/hadoop/slaves\\n''exec /usr/sbin/sshd -D '\u003e/usr/local/bin/entrypoint.sh  \u0026\u0026 chmod -v +x /usr/local/bin/entrypoint.sh  \u0026\u0026 apk del wget tar  \u0026\u0026 rm -rf /hadoop/share/doc /hadoop-$HADOOP_VER.tar.gz  \u0026\u0026 rm -rf /var/cache/apk/* /tmp/*"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "entrypoint.sh"
          ],
          "Name": "entrypoint",
          "PrependShell": false
        }
      ]
    }
  ]
}