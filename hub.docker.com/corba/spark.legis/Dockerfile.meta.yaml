MetaArgs: null
Stages:
- BaseName: debian:jessie
  Commands:
  - CmdLine:
    - echo "deb http://ppa.launchpad.net/webupd8team/java/ubuntu trusty main" > /etc/apt/sources.list.d/webupd8team-java.list      &&     echo
      "deb-src http://ppa.launchpad.net/webupd8team/java/ubuntu trusty main" >> /etc/apt/sources.list.d/webupd8team-java.list
      &&     apt-key adv --keyserver keyserver.ubuntu.com --recv-keys EEA14886 &&     apt-get
      -y update &&     /bin/echo debconf shared/accepted-oracle-license-v1-1 select
      true | /usr/bin/debconf-set-selections &&     DEBIAN_FRONTEND=noninteractive
      apt-get -y install oracle-java8-installer oracle-java8-set-default python curl
    Name: run
    PrependShell: true
  - CmdLine:
    - curl -s http://d3kbcqa49mib13.cloudfront.net/spark-1.6.1-bin-hadoop2.6.tgz |
      tar -xz -C /usr/local/ &&     mv /usr/local/spark-1.6.1-bin-hadoop2.6 /usr/local/spark
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/start-master.sh
    - /start-master.sh
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/start-worker.sh
    - /start-worker.sh
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/spark-shell.sh
    - /spark-shell.sh
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/spark-defaults.conf
    - /spark-defaults.conf
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - job-dependencies/*
    - /job-dependencies/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - jars/spark-cassandra-connector-assembly-1.6.0-M1-s_2.10.jar
    - /spark-cassandra-connector-assembly-1.6.0-M1-s_2.10.jar
  - Env:
    - Key: SPARK_HOME
      Value: /usr/local/spark
    Name: env
  - Env:
    - Key: SPARK_MASTER_OPTS
      Value: '"-Dspark.driver.port=7001 -Dspark.fileserver.port=7002 -Dspark.broadcast.port=7003
        -Dspark.replClassServer.port=7004 -Dspark.blockManager.port=7005 -Dspark.executor.port=7006
        -Dspark.ui.port=4040 -Dspark.broadcast.factory=org.apache.spark.broadcast.HttpBroadcastFactory"'
    Name: env
  - Env:
    - Key: SPARK_WORKER_OPTS
      Value: '"$SPARK_MASTER_OPTS -Dspark.worker.cleanup.enabled=true -Dspark.shuffle.service.enabled=true"'
    Name: env
  - Env:
    - Key: SPARK_MASTER_PORT
      Value: "7077"
    Name: env
  - Env:
    - Key: SPARK_MASTER_WEBUI_PORT
      Value: "8080"
    Name: env
  - Env:
    - Key: SPARK_WORKER_PORT
      Value: "8888"
    Name: env
  - Env:
    - Key: SPARK_WORKER_WEBUI_PORT
      Value: "8081"
    Name: env
  - Env:
    - Key: SPARK_NETWORK_INTERFACE
      Value: '"eth0"'
    Name: env
  - Name: expose
    Ports:
    - "4040"
    - "7001"
    - "7002"
    - "7003"
    - "7004"
    - "7005"
    - "7006"
    - "7077"
    - "8080"
    - "8081"
    - "8888"
  - CmdLine:
    - /start-worker.sh
    Name: cmd
    PrependShell: false
  From:
    Image: debian:jessie
  Name: ""
  Platform: ""
  SourceCode: FROM debian:jessie
