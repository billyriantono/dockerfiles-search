MetaArgs:
- DefaultValue: jupyter/pyspark-notebook
  Key: BASE_CONTAINER
  ProvidedValue: null
  Value: jupyter/pyspark-notebook
Stages:
- BaseName: $BASE_CONTAINER
  Commands:
  - Labels:
    - Key: maintainer
      Value: '"Jupyter Project <jupyter@googlegroups.com>"'
    Name: label
  - Name: user
    User: root
  - CmdLine:
    - apt-get update &&     apt-get install -y vim nano maven openjdk-8-jdk python3-dev
      libsasl2-dev libsasl2-2 libsasl2-modules-gssapi-mit zip
    Name: run
    PrependShell: true
  - Env:
    - Key: R_LIBS_USER
      Value: $SPARK_HOME/R/lib
    Name: env
  - CmdLine:
    - fix-permissions $R_LIBS_USER
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get update &&     apt-get install -y --no-install-recommends     fonts-dejavu     gfortran     gcc
      &&     rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - Name: user
    User: $NB_UID
  - CmdLine:
    - conda install --quiet --yes     'r-base=3.5.1'     'r-irkernel=0.8*'     'r-ggplot2=3.1*'     'r-sparklyr=0.9*'     'r-rcurl=1.95*'
      &&     conda clean --all -f -y &&     fix-permissions $CONDA_DIR &&     fix-permissions
      /home/$NB_USER
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install --no-cache-dir sparkmagic &&     jupyter nbextension enable --py
      --sys-prefix widgetsnbextension
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - Name: workdir
    Path: /opt/conda/lib/python3.7/site-packages
  - CmdLine:
    - jupyter-kernelspec install sparkmagic/kernels/sparkkernel &&     jupyter-kernelspec
      install sparkmagic/kernels/pysparkkernel &&     jupyter-kernelspec install sparkmagic/kernels/sparkrkernel
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /home/$NB_USER/work
  - CmdLine:
    - mkdir /home/$NB_USER/.sparkmagic
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/config.json
    - /home/$NB_USER/.sparkmagic/config.json
  - CmdLine:
    - chown -R jovyan:users /home/$NB_USER/.sparkmagic
    Name: run
    PrependShell: true
  - Name: user
    User: $NB_USER
  - CmdLine:
    - jupyter serverextension enable --py sparkmagic
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - Chown: ""
    Name: add
    SourcesAndDest:
    - krb5.conf
    - /etc/krb5.conf
  - CmdLine:
    - rm -rf /home/$NB_USER/.local &&     fix-permissions $CONDA_DIR &&     fix-permissions
      /home/$NB_USER
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /tmp/spark-2.3.2-bin-without-hadoop.tgz https://archive.apache.org/dist/spark/spark-2.3.2/spark-2.3.2-bin-without-hadoop.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xf /tmp/spark-2.3.2-bin-without-hadoop.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv spark-2.3.2-bin-without-hadoop /opt/
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/spark-2.3.2-bin-without-hadoop /opt/spark
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /tmp/hadoop-3.1.1.tar.gz https://archive.apache.org/dist/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xf /tmp/hadoop-3.1.1.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv hadoop-3.1.1 /opt/
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/hadoop-3.1.1 /opt/hadoop
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/spark/spark-defaults.conf
    - /opt/spark/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/spark/spark-env.sh
    - /opt/spark/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/spark/spark-log4j.properties
    - /opt/spark/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/spark/spark-metrics.properties
    - /opt/spark/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/core-site.xml
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/hadoop-env.sh
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/hdfs-site.xml
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/log4j.properties
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/capacity-scheduler.xml
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/container-executor.cfg
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/resource-types.xml
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/yarn-env.sh
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/yarn-site.xml
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/topology_script.py
    - /opt/hadoop/etc/hadoop/
  - CmdLine:
    - chmod a+rx /opt/hadoop/etc/hadoop/topology_script.py
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/mapred-env.sh
    - /opt/hadoop/etc/hadoop/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hadoop/mapred-site.xml
    - /opt/hadoop/etc/hadoop/
  - CmdLine:
    - pip install --upgrade hiveqlKernel
    Name: run
    PrependShell: true
  - CmdLine:
    - jupyter hiveql install --user
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install calysto_bash
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /tmp/hbase-2.0.2-bin.tar.gz http://archive.apache.org/dist/hbase/2.0.2/hbase-2.0.2-bin.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xf /tmp/hbase-2.0.2-bin.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv hbase-2.0.2 /opt/
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/hbase-2.0.2 /opt/hbase
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hbase/hbase-env.sh
    - /opt/hbase/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hbase/hbase-site.xml
    - /opt/hbase/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hbase/log4j.properties
    - /opt/hbase/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hbase/regionservers
    - /opt/hbase/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/hbase/hbase-site.xml
    - /opt/hadoop/etc/hadoop/
  - CmdLine:
    - cp -r /opt/hbase/lib/hbase-* /opt/hadoop/lib
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /tmp/apache-phoenix-5.0.0-HBase-2.0-bin.tar.gz http://apache.rediris.es/phoenix/apache-phoenix-5.0.0-HBase-2.0/bin/apache-phoenix-5.0.0-HBase-2.0-bin.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xf /tmp/apache-phoenix-5.0.0-HBase-2.0-bin.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv apache-phoenix-5.0.0-HBase-2.0-bin /opt/
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/apache-phoenix-5.0.0-HBase-2.0-bin /opt/phoenix
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/phoenix/bin/sqlline.py /usr/bin/phoenix-sqlline
    Name: run
    PrependShell: true
  - CmdLine:
    - sed -i '1{s/$/2.7/}' /opt/phoenix/bin/sqlline.py
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /tmp/kafka_2.11-2.0.0.tgz https://archive.apache.org/dist/kafka/2.0.0/kafka_2.11-2.0.0.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xf /tmp/kafka_2.11-2.0.0.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv kafka_2.11-2.0.0 /opt/
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/kafka_2.11-2.0.0 /opt/kafka
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/kafka/kafka_client_jaas.conf
    - /opt/kafka/config/kafka_client_jaas.conf
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/kafka/kafka_jaas.conf
    - /opt/kafka/config/kafka_jaas.conf
  - CmdLine:
    - pwd
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /tmp/pig-client.tar.gz https://edi-files-edi.apps.openshift.deustotech.eu/static/notebook/pig-client.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xf /tmp/pig-client.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - mv pig-client /opt/pig-client
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/pig-client /opt/pig
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/pig/log4j.properties
    - /opt/pig/conf/log4j.properties
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/pig/pig-env.sh
    - /opt/pig/conf/pig-env.sh
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/pig/pig.properties
    - /opt/pig/conf/pig.properties
  - CmdLine:
    - wget -O /tmp/tez-client.tar.gz https://edi-files-edi.apps.openshift.deustotech.eu/static/notebook/tez-client.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/tez-client /opt/tez
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/tez/tez-env.sh
    - /opt/tez/conf/tez-env.sh
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/tez/tez-site.xml
    - /opt/tez/conf/tez-site.xml
  - Chown: ""
    Name: add
    SourcesAndDest:
    - oozie-client-4.3.1-client.tar.gz
    - /tmp
  - CmdLine:
    - mv /tmp/oozie-client-4.3.1 /opt/
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/oozie-client-4.3.1 /opt/oozie-client
    Name: run
    PrependShell: true
  - CmdLine:
    - fix-permissions $CONDA_DIR &&     fix-permissions /home/$NB_USER
    Name: run
    PrependShell: true
  - Name: user
    User: $NB_USER
  - Name: workdir
    Path: /home/$NB_USER/work
  - CmdLine:
    - pip install --upgrade hiveqlKernel
    Name: run
    PrependShell: true
  - CmdLine:
    - jupyter hiveql install --user
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: '"/opt/hbase/bin/:/opt/spark/bin:/opt/hadoop/bin:/opt/kafka/bin:/opt/pig/bin:/opt/oozie-client/bin:${PATH}"'
    Name: env
  - Env:
    - Key: HADOOP_HOME
      Value: '"/opt/hadoop"'
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: '"/opt/hadoop/etc/hadoop"'
    Name: env
  - Env:
    - Key: JAVA_HOME
      Value: '"/usr/lib/jvm/java-1.8.0-openjdk-amd64"'
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: '"/opt/spark"'
    Name: env
  - Env:
    - Key: HADOOP_VERSION
      Value: '"3.1.1"'
    Name: env
  - Env:
    - Key: APACHE_SPARK_VERSION
      Value: '"2.3.2"'
    Name: env
  - Env:
    - Key: HDP_VERSION
      Value: '"3.1.0.0-78"'
    Name: env
  - Env:
    - Key: HBASE_HOME
      Value: '"/opt/hbase"'
    Name: env
  - Env:
    - Key: HBASE_CONF_DIR
      Value: '"${HBASE_HOME}/conf"'
    Name: env
  - Env:
    - Key: KAFKA_OPTS
      Value: '"-Djava.security.auth.login.config=/opt/kafka/config/kafka_client_jaas.conf"'
    Name: env
  - Env:
    - Key: TEZ_JARS
      Value: '"/opt/tez"'
    Name: env
  - Env:
    - Key: TEZ_CONF_DIR
      Value: '"/opt/tez/conf"'
    Name: env
  - Env:
    - Key: PIG_CLASSPATH
      Value: '"${HADOOP_HOME}/conf:${TEZ_HOME}/conf"'
    Name: env
  - Env:
    - Key: PIG_HOME
      Value: '"/opt/pig"'
    Name: env
  - Env:
    - Key: HADOOP_CLASSPATH
      Value: '"${HBASE_HOME}/lib/*:${HBASE_HOME}/conf/*:${TEZ_CONF_DIR}:${TEZ_JARS}/*:${TEZ_JARS}/lib/*"'
    Name: env
  - CmdLine:
    - git clone https://github.com/edincubator/stack-examples ~/work/examples
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - CmdLine:
    - rm -rf /tmp/*
    Name: run
    PrependShell: true
  - Name: user
    User: $NB_USER
  - Chown: ""
    Name: add
    SourcesAndDest:
    - configs/.bashrc
    - /home/jovyan/.bashrc
  From:
    Image: $BASE_CONTAINER
  Name: ""
  Platform: ""
  SourceCode: FROM $BASE_CONTAINER
