{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "python:3.5",
      "SourceCode": "FROM python:3.5",
      "Platform": "",
      "From": {
        "Image": "python:3.5"
      },
      "Commands": [
        {
          "Env": [
            {
              "Key": "PYTHONHASHSEED",
              "Value": "0"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONIOENCODING",
              "Value": "UTF-8"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PIP_DISABLE_PIP_VERSION_CHECK",
              "Value": "1"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "HADOOP_VERSION",
              "Value": "2.7.3"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "HADOOP_HOME",
              "Value": "/usr/hadoop-$HADOOP_VERSION"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "HADOOP_CONF_DIR",
              "Value": "$HADOOP_HOME/etc/hadoop"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$HADOOP_HOME/bin"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "curl -sL --retry 3   \"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\"   | gunzip   | tar -x -C /usr/  \u0026\u0026 rm -rf $HADOOP_HOME/share/doc  \u0026\u0026 chown -R root:root $HADOOP_HOME"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_VERSION",
              "Value": "2.4.3"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_PACKAGE",
              "Value": "spark-${SPARK_VERSION}-bin-hadoop2.7"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/spark-${SPARK_VERSION}"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_DIST_CLASSPATH",
              "Value": "\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\""
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:${SPARK_HOME}/bin"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "curl -sL --retry 3   \"http://apache.mirror.cdnetworks.com/spark/spark-${SPARK_VERSION}/$SPARK_PACKAGE.tgz\"   | gunzip   | tar x -C /usr/  \u0026\u0026 mv /usr/$SPARK_PACKAGE $SPARK_HOME  \u0026\u0026 chown -R root:root $SPARK_HOME"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get update --fix-missing \u0026\u0026 apt-get install -y wget bzip2 ca-certificates     libglib2.0-0 libxext6 libsm6 libxrender1     git mercurial subversion"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y openjdk-8-jdk"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "echo 'export PATH=/opt/conda/bin:$PATH' \u003e /etc/profile.d/conda.sh \u0026\u0026     wget --quiet https://repo.anaconda.com/archive/Anaconda2-2019.03-Linux-x86_64.sh -O ~/anaconda.sh \u0026\u0026     /bin/bash ~/anaconda.sh -b -p /opt/conda \u0026\u0026     rm ~/anaconda.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y curl grep sed dpkg \u0026\u0026     TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\"\" | sed 's:^..\\(.*\\).$:\\1:'` \u0026\u0026     curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" \u003e tini.deb \u0026\u0026     dpkg -i tini.deb \u0026\u0026     rm tini.deb \u0026\u0026     apt-get clean"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "/opt/conda/bin:$PATH"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "apt-get update --fix-missing \u0026\u0026 apt-get install -y gfortran libatlas-base-dev gfortran pkg-config             libfreetype6-dev libxft-dev libpng-dev libhdf5-serial-dev g++             make patch lib32ncurses5-dev"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "user",
          "User": "root"
        },
        {
          "CmdLine": [
            "conda install -y gcc"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "conda install -y -c conda-forge cassandra-driver"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "GRAPH_FRAMES_VERSION",
              "Value": "0.7.1-spark2.4.3-s_2.11"
            }
          ],
          "Name": "env"
        },
        {
          "Chown": "",
          "Name": "add",
          "SourcesAndDest": [
            "./graphframes-dist/graphframes-${GRAPH_FRAMES_VERSION}",
            "$SPARK_HOME/graphframes"
          ]
        },
        {
          "CmdLine": [
            "cd $SPARK_HOME/graphframes \u0026\u0026     chmod +x ./build/sbt \u0026\u0026     ./build/sbt \"set test in assembly := {}\" clean assembly \u0026\u0026     mv $SPARK_HOME/graphframes/python/graphframes $SPARK_HOME/python/pyspark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "MONGO_SPARK_CONNECTOR_VERSION",
              "Value": "2.4.0"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "MONGO_SPARK_VERSION",
              "Value": "2.4.3"
            }
          ],
          "Name": "env"
        },
        {
          "Chown": "",
          "Name": "add",
          "SourcesAndDest": [
            "./mongo-spark-connector/mongo-spark-connector_${MONGO_SPARK_VERSION}_${MONGO_SPARK_CONNECTOR_VERSION}",
            "$SPARK_HOME/org.mongodb.spark"
          ]
        },
        {
          "CmdLine": [
            "cd $SPARK_HOME/org.mongodb.spark \u0026\u0026     chmod +x ./sbt \u0026\u0026     ./sbt \"set test in assembly := {}\" clean assembly"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /opt \u0026\u0026   git clone --recursive https://github.com/dmlc/xgboost \u0026\u0026   cd xgboost \u0026\u0026   make -j4"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "/opt/xgboost/python-package"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$SPARK_HOME/python/:$PYTHONPATH"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYSPARK_DRIVER_PYTHON",
              "Value": "jupyter"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYSPARK_DRIVER_PYTHON_OPTS",
              "Value": "lab"
            }
          ],
          "Name": "env"
        },
        {
          "Name": "user",
          "User": "$NB_USER"
        },
        {
          "CmdLine": [
            "pip install spark-sklearn"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PYSPARK_SUBMIT_ARGS",
              "Value": "\"--packages graphframes:graphframes:${GRAPH_FRAMES_VERSION},org.mongodb.spark:mongo-spark-connector_${MONGO_SPARK_VERSION}:${MONGO_SPARK_CONNECTOR_VERSION} pyspark-shell\""
            }
          ],
          "Name": "env"
        },
        {
          "Name": "workdir",
          "Path": "$SPARK_HOME"
        },
        {
          "CmdLine": [
            "bin/spark-class",
            "org.apache.spark.deploy.master.Master"
          ],
          "Name": "cmd",
          "PrependShell": false
        }
      ]
    }
  ]
}