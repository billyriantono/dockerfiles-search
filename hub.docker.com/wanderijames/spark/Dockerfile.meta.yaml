MetaArgs: null
Stages:
- BaseName: alpine:3.9
  Commands:
  - Env:
    - Key: DAEMON_RUN
      Value: "true"
    Name: env
  - Env:
    - Key: SPARK_VERSION
      Value: 2.4.4
    Name: env
  - Env:
    - Key: HADOOP_VERSION
      Value: 2.7.7
    Name: env
  - Env:
    - Key: SPARK_HADOOP_VERSION
      Value: "2.7"
    Name: env
  - Env:
    - Key: SCALA_VERSION
      Value: 2.11.12
    Name: env
  - Env:
    - Key: SCALA_HOME
      Value: /opt/scala
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark
    Name: env
  - Env:
    - Key: PYSPARK_PYTHON
      Value: /usr/bin/python
    Name: env
  - Env:
    - Key: LIVY_VERSION
      Value: 0.6.0
    Name: env
  - CmdLine:
    - apk add     curl     build-base     ca-certificates     gcc     gfortran     bash     python3     python3-dev     jq     wget     openjdk8-jre
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing python and pip ****"     && rm -f /usr/bin/python     &&
      rm -f /usr/bin/pip     && ln -sf python3 /usr/bin/python     && echo "**** Install
      pip ****"     && python3 -m ensurepip     && rm -r /usr/lib/python*/ensurepip     &&
      pip3 install --no-cache --upgrade pip setuptools wheel
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing Scala ***"     && wget --no-verbose "https://downloads.typesafe.com/scala/${SCALA_VERSION}/scala-${SCALA_VERSION}.tgz"     &&
      tar xzf "scala-${SCALA_VERSION}.tgz"     && mkdir "${SCALA_HOME}"     && rm
      "scala-${SCALA_VERSION}/bin/"*.bat     && mv "scala-${SCALA_VERSION}/bin" "scala-${SCALA_VERSION}/lib"
      "${SCALA_HOME}"     && rm -r "scala-${SCALA_VERSION}"     && rm -f "scala-${SCALA_VERSION}.tgz"     &&
      ln -s "${SCALA_HOME}/bin/"* "/usr/bin/"
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing Spark ***"     && wget --no-verbose http://apache.mirror.iphh.net/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}.tgz     &&
      tar -xvzf spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}.tgz     &&
      mv spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION} ${SPARK_HOME}     &&
      rm spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}.tgz     && pip install
      -e ${SPARK_HOME}/python
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing Livy ***"     && wget https://www-eu.apache.org/dist/incubator/livy/${LIVY_VERSION}-incubating/apache-livy-${LIVY_VERSION}-incubating-bin.zip     &&
      unzip apache-livy-${LIVY_VERSION}-incubating-bin.zip     && rm apache-livy-${LIVY_VERSION}-incubating-bin.zip     &&
      mv apache-livy-${LIVY_VERSION}-incubating-bin /opt/livy     && chmod a+x /opt/livy/bin/livy-server
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /opt/livy/logs
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Install Pyspark ML dependencies ***"     && pip install Cython     &&
      pip install numpy     && pip install pandas
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing Postgres psycopg2 and drivers ***"     && apk add         libpq         postgresql-dev     &&
      wget https://jdbc.postgresql.org/download/postgresql-42.2.7.jar     && mv postgresql-42.2.7.jar
      ${SPARK_HOME}/jars/postgresql-42.2.7.jar     && pip install psycopg2-binary
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing redshift drivers ***"     && wget https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/1.2.36.1060/RedshiftJDBC42-no-awssdk-1.2.36.1060.jar     &&
      mv RedshiftJDBC42-no-awssdk-1.2.36.1060.jar ${SPARK_HOME}/jars/RedshiftJDBC42-no-awssdk-1.2.36.1060.jar
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "*** Installing Python dev stuff ***"     && apk add linux-headers zeromq-dev     &&
      pip install         tox         jupyter
    Name: run
    PrependShell: true
  From:
    Image: alpine:3.9
  Name: ""
  Platform: ""
  SourceCode: FROM alpine:3.9
