{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "reecerobinson/jupyter:1.6.0",
      "SourceCode": "FROM reecerobinson/jupyter:1.6.0",
      "Platform": "",
      "From": {
        "Image": "reecerobinson/jupyter:1.6.0"
      },
      "Commands": [
        {
          "Maintainer": "docker@reecerobinson.co.nz",
          "Name": "maintainer"
        },
        {
          "Env": [
            {
              "Key": "APACHE_SPARK_VERSION",
              "Value": "1.6.0"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$SPARK_HOME/bin"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "USE_VAGRANT",
              "Value": "false"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "IS_SNAPSHOT",
              "Value": "false"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "git clone https://github.com/ibm-et/spark-kernel.git"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "echo \"deb http://dl.bintray.com/sbt/debian /\" | tee -a /etc/apt/sources.list.d/sbt.list \u0026\u0026 \tapt-get update \u0026\u0026 \tapt-get install --force-yes -y sbt \u0026\u0026 \tapt-get clean"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "workdir",
          "Path": "/root/spark-kernel"
        },
        {
          "CmdLine": [
            "sed -i s/'USE_VAGRANT?='/''/g /root/spark-kernel/Makefile \t\u0026\u0026 sed -i s/'IS_SNAPSHOT?=true'/''/g /root/spark-kernel/Makefile \t\u0026\u0026 sed -i s/'RUN_PREFIX=$(if $(USE_VAGRANT),vagrant ssh -c \"cd $(VM_WORKDIR) \u0026\u0026 )'/''/g /root/spark-kernel/Makefile \t\u0026\u0026 sed -i s/'RUN_SUFFIX=$(if $(USE_VAGRANT),\")'/''/g /root/spark-kernel/Makefile"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "sbt exit"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "make dist \u0026\u0026 rm -rf /root/.ivy2"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /root/local \u0026\u0026 cd /root/local \u0026\u0026 tar -xzvf /root/spark-kernel/dist/spark-kernel-0.1.5.tar.gz"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "kernels",
            "/root/.ipython/kernels"
          ]
        },
        {
          "CmdLine": [
            "cp $SPARK_HOME/lib/elasticsearch-spark_2.10-2.2.0-rc1.jar /root/local/spark-kernel/lib \u0026\u0026     cp $SPARK_HOME/lib/cassandra-clientutil-2.2.2.jar /root/local/spark-kernel/lib \u0026\u0026     cp $SPARK_HOME/lib/cassandra-driver-core-3.0.0-rc1.jar /root/local/spark-kernel/lib \u0026\u0026     cp $SPARK_HOME/lib/guava-16.0.1.jar /root/local/spark-kernel/lib"
          ],
          "Name": "run",
          "PrependShell": true
        }
      ]
    }
  ]
}