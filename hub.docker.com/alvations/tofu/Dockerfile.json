{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "ubuntu:latest",
      "SourceCode": "FROM ubuntu:latest",
      "Platform": "",
      "From": {
        "Image": "ubuntu:latest"
      },
      "Commands": [
        {
          "Maintainer": "Tofu \u003cto@fu.com\u003e",
          "Name": "maintainer"
        },
        {
          "Labels": [
            {
              "Key": "description",
              "Value": "\"Tofu Tokenization Kit.\""
            }
          ],
          "Name": "label"
        },
        {
          "CmdLine": [
            "apt-get update"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y apt-utils debconf-utils"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get update \u0026\u0026 apt-get -y upgrade"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y sudo nano perl python-dev python3-dev python-pip python3-pip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y curl wget tar dtrx unzip git"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y default-jre default-jdk"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /tokenizers/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "workdir",
          "Path": "/tokenizers/"
        },
        {
          "CmdLine": [
            "wget https://nlp.stanford.edu/software/stanford-segmenter-2016-10-31.zip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "unzip stanford-segmenter-2016-10-31.zip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mv /tokenizers/stanford-segmenter-2016-10-31/data /tokenizers/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mv /tokenizers/data/ /tokenizers/stanfordsegmenterdata/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mv /tokenizers/stanford-segmenter-2016-10-31/segment.sh /tokenizers/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "perl -pi -e 's|\\$BASEDIR\\/data|\\$BASEDIR\\/stanfordsegmenterdata|g' segment.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mv /tokenizers/stanford-segmenter-2016-10-31/stanford-segmenter-3.7.0.jar /tokenizers/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "wget http://nlp.stanford.edu/software/stanford-corenlp-full-2016-10-31.zip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "unzip stanford-corenlp-full-2016-10-31.zip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mv /tokenizers/stanford-corenlp-full-2016-10-31/stanford-corenlp-3.7.0.jar /tokenizers/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "tokenize-zh.sh",
            "/tokenizers/tokenize-zh.sh"
          ]
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "tokenize-en.sh",
            "/tokenizers/tokenize-en.sh"
          ]
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "percsplit.sh",
            "/tokenizers/percsplit.sh"
          ]
        },
        {
          "CmdLine": [
            "chmod +x /tokenizers/percsplit.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "rm stanford-corenlp-full-2016-10-31.zip stanford-segmenter-2016-10-31.zip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "rm -rf /tokenizers/stanford-segmenter-2016-10-31/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "rm -rf /tokenizers/stanford-corenlp-full-2016-10-31/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "wget https://github.com/nltk/nltk_data/raw/gh-pages/packages/corpora/nonbreaking_prefixes.zip"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /share/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "unzip nonbreaking_prefixes.zip -d /share/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "tokenizer.perl",
            "/tokenizers/tokenizer.perl"
          ]
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "clean-corpus-n.perl",
            "/tokenizers/clean-corpus-n.perl"
          ]
        },
        {
          "CmdLine": [
            "chmod +x /tokenizers/tokenizer.perl"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "chmod +x /tokenizers/clean-corpus-n.perl"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install -U docopt"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "preprocess.py",
            "/tokenizers/preprocess.py"
          ]
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "preprocess_util.py",
            "/tokenizers/preprocess_util.py"
          ]
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "paddle2moses.sh",
            "/tokenizers/paddle2moses.sh"
          ]
        },
        {
          "Name": "workdir",
          "Path": "/"
        }
      ]
    }
  ]
}