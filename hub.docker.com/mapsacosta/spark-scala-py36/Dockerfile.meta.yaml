MetaArgs: null
Stages:
- BaseName: centos:7
  Commands:
  - Env:
    - Key: container
      Value: docker
    Name: env
  - Name: user
    User: root
  - CmdLine:
    - yum install -y java-1.8.0-openjdk wget which     && yum clean all && rm -rf
      /var/cache/yum     && rpm -q java-1.8.0-openjdk wget
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - spark-2.4.3-bin-hadoop2.7.tgz
    - /tmp/artifacts/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - sbt-0.13.13.tgz
    - /tmp/artifacts/
  - Env:
    - Key: JBOSS_IMAGE_NAME
      Value: '"radanalyticsio/openshift-spark"'
    - Key: JBOSS_IMAGE_VERSION
      Value: '"2.4-latest"'
    - Key: PATH
      Value: '"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/spark/bin"'
    - Key: SCL_ENABLE_CMD
      Value: '"scl enable rh-python36"'
    - Key: SPARK_HOME
      Value: '"/opt/spark"'
    - Key: SPARK_INSTALL
      Value: '"/opt/spark-distro"'
    - Key: STI_SCRIPTS_PATH
      Value: '"/usr/libexec/s2i"'
    - Key: SCALA_VERSION
      Value: 2.11.8
    - Key: PATH
      Value: $HOME/.local/bin:/opt/sbt/bin:$PATH
    Name: env
  - Labels:
    - Key: io.cekit.version
      Value: '"2.2.7"'
    - Key: maintainer
      Value: '"Maria A. <macosta[at]fnal.gov>"'
    - Key: name
      Value: '"mapsacosta/openshift-spark"'
    - Key: org.concrt.version
      Value: '"2.2.7"'
    - Key: sparkversion
      Value: '"2.4.3"'
    - Key: version
      Value: '"2.4.3-latest"'
    Name: label
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - modules
    - /tmp/scripts
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./root/
    - /
  - Name: user
    User: root
  - CmdLine:
    - bash
    - -x
    - /tmp/scripts/common/install
    Name: run
    PrependShell: false
  - Name: user
    User: root
  - CmdLine:
    - bash
    - -x
    - /tmp/scripts/metrics/install
    Name: run
    PrependShell: false
  - Name: user
    User: root
  - CmdLine:
    - bash
    - -x
    - /tmp/scripts/python36/install
    Name: run
    PrependShell: false
  - Name: user
    User: root
  - CmdLine:
    - bash
    - -x
    - /tmp/scripts/spark/install
    Name: run
    PrependShell: false
  - CmdLine:
    - wget https://archive.apache.org/dist/hadoop/core/hadoop-2.7.2/hadoop-2.7.2.tar.gz
      && tar xvf hadoop-2.7.2.tar.gz  -C /opt/
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - modules/hadoop/*
    - /opt/hadoop-2.7.2/etc/hadoop/
  - Name: user
    User: root
  - CmdLine:
    - bash -x /opt/app-root/check_for_download_sbt /tmp/artifacts/sbt-0.13.13.tgz
      &&     tar -zxf /tmp/artifacts/sbt-0.13.13.tgz -C /opt &&     ln -s /opt/sbt-launcher-packaging-0.13.13
      /opt/sbt &&     mkdir /tmp/.ivy2 /tmp/.sbt
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /
  - Name: user
    User: root
  - Env:
    - Key: ARROW_HOME
      Value: /usr/local
    Name: env
  - Env:
    - Key: PARQUET_HOME
      Value: /usr/local
    Name: env
  - CmdLine:
    - pip3 install --no-cache-dir --upgrade pip
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir setuptools
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir numpy==1.14.5
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir numpy six pytest numpy cython
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir pandas
    Name: run
    PrependShell: true
  - CmdLine:
    - bash
    - -x
    - /tmp/scripts/coffea/install
    Name: run
    PrependShell: false
  - CmdLine:
    - rm -rf /tmp/scripts
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - CmdLine:
    - rm -rf /tmp/artifacts
    Name: run
    PrependShell: true
  - CmdLine:
    - 'yum install -y devtoolset-7 llvm-toolset-7     && yum install -y llvm-toolset-7-clang-analyzer
      llvm-toolset-7-clang-tools-extra # optional'
    Name: run
    PrependShell: true
  - CmdLine:
    - yum -y install python3-devel  &&     pip3 install --no-cache-dir py4j &&     pip3
      install --no-cache-dir scipy  &&     pip3 install --no-cache-dir jinja2 &&     pip3
      install --no-cache-dir cloudpickle &&     pip3 install --no-cache-dir lz4 &&     pip3
      install --no-cache-dir blosc
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir pyarrow==0.10.0
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir numba
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --no-cache-dir coffea
    Name: run
    PrependShell: true
  - Env:
    - Key: PYSPARK_PYTHON
      Value: '"python3.6"'
    Name: env
  - Env:
    - Key: PYSPARK_MAJOR_PYTHON_VERSION
      Value: '"3"'
    Name: env
  - Env:
    - Key: SPARK_WORKER_DIR
      Value: /scratch
    Name: env
  - Env:
    - Key: SPARK_WORKER_PORT
      Value: "8581"
    Name: env
  - Env:
    - Key: SPARK_DIST_CLASSPATH
      Value: '"$(hadoop classpath)"'
    Name: env
  - Env:
    - Key: PATH
      Value: '"$SPARK_HOME/bin:$PATH"'
    Name: env
  - Env:
    - Key: PATH
      Value: '"/opt/hadoop-2.7.3/bin:$PATH"'
    Name: env
  - Env:
    - Key: HADOOP_HOME
      Value: '"/opt/hadoop-2.7.2"'
    Name: env
  - Env:
    - Key: HADOOP_CLASSPATH
      Value: '"$HADOOP_HOME/libexec"'
    Name: env
  - Env:
    - Key: PATH
      Value: '"$PATH:$HADOOP_HOME/bin:$JAVA_PATH/bin:$HADOOP_HOME/sbin"'
    Name: env
  - Env:
    - Key: HADOOP_PREFIX
      Value: '"/opt/hadoop-2.7.2"'
    Name: env
  - Env:
    - Key: HADOOP_MAPRED_HOME
      Value: '"${HADOOP_HOME}"'
    Name: env
  - Env:
    - Key: HADOOP_COMMON_HOME
      Value: '"${HADOOP_HOME}"'
    Name: env
  - Env:
    - Key: HADOOP_HDFS_HOME
      Value: '"${HADOOP_HOME}"'
    Name: env
  - Env:
    - Key: YARN_HOME
      Value: '"${HADOOP_HOME}"'
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: '"${HADOOP_HOME}/etc/hadoop"'
    Name: env
  - Env:
    - Key: HADOOP_COMMON_LIB_NATIVE_DIR
      Value: '"${HADOOP_PREFIX}/lib/native"'
    Name: env
  - Env:
    - Key: HADOOP_OPTS
      Value: '"$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native"'
    Name: env
  - Env:
    - Key: LD_LIBRARY_PATH
      Value: '"$HADOOP_HOME/lib/native/:$LD_LIBRARY_PATH"'
    Name: env
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - modules/hadoop-xrootd/*
    - /opt/hadoop-xrootd/
  - Env:
    - Key: HADOOP_CLASSPATH
      Value: '"/opt/hadoop-xrootd/*:$(hadoop classpath)"'
    Name: env
  - CmdLine:
    - yum -y install xrootd-client xrootd-client-libs xrootd-client-devel python36-xrootd
      && yum clean all
    Name: run
    PrependShell: true
  - CmdLine:
    - yum -y install https://repo.opensciencegrid.org/osg/3.4/osg-3.4-el7-release-latest.rpm                    epel-release                    yum-plugin-priorities
      &&     yum -y install                     osg-wn-client                    redhat-lsb-core                    singularity
      &&     yum clean all &&     rm -rf /var/cache/yum/*
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /tmp
  - CmdLine:
    - /entrypoint
    Name: entrypoint
    PrependShell: false
  - CmdLine:
    - chown -R 1001:0 /opt/app-root &&     chown -R 1001:0 /opt/sbt &&     chmod g+rw
      /opt/sbt/conf &&     chown -R 1001:0 /tmp/.ivy2 &&     chmod g+rw /tmp/.ivy2
      &&     chown -R 1001:0 /tmp/.sbt &&     chmod g+rw /tmp/.sbt
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - Name: volume
    Volumes:
    - /scratch
  - CmdLine:
    - chmod -R 0777 /scratch
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --upgrade coffea
    Name: run
    PrependShell: true
  - CmdLine:
    - /launch.sh
    Name: cmd
    PrependShell: false
  - Name: user
    User: "185"
  From:
    Image: centos:7
  Name: ""
  Platform: ""
  SourceCode: FROM centos:7
