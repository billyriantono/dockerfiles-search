MetaArgs: null
Stages:
- BaseName: phusion/baseimage:latest
  Commands:
  - Maintainer: Thomas Gruender <thomas.gruender@tu-dresden.de>, Brian Rimek <brian.rimek@tu-dresden.de>
    Name: maintainer
  - Labels:
    - Key: version
      Value: '"spark-worker-2.1"'
    Name: label
  - Labels:
    - Key: release
      Value: '"0.1.4"'
    Name: label
  - Key: JAVA_MAJOR_VERSION
    Name: arg
    Value: "7"
  - Key: SPARK_VERSION
    Name: arg
    Value: 2.1.0
  - Key: HADOOP_MAJOR_VERSION
    Name: arg
    Value: "2.7"
  - Key: SPARK_WORKDIR
    Name: arg
    Value: /opt/spark
  - Key: SPARK_ARCHIVE
    Name: arg
    Value: http://www-eu.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_MAJOR_VERSION}.tgz
  - CmdLine:
    - apt-get update &&   apt-get install -y python3 python3-dev python3-pip python3-virtualenv
      &&   apt-get install -y python3-numpy python3-wheel &&   rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - CmdLine:
    - sed -i 's/# \(.*multiverse$\)/\1/g' /etc/apt/sources.list &&   apt-get update
      &&   apt-get -y upgrade &&   apt-get install -y build-essential &&   apt-get
      install -y software-properties-common &&   apt-get install -y byobu curl git
      htop man unzip nano vim wget &&   rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - CmdLine:
    - echo oracle-java${JAVA_MAJOR_VERSION}-installer shared/accepted-oracle-license-v1-1
      select true | debconf-set-selections &&   add-apt-repository -y ppa:webupd8team/java
      &&   apt-get update &&   apt-get install -y oracle-java${JAVA_MAJOR_VERSION}-installer
      &&   rm -rf /var/lib/apt/lists/* &&   rm -rf /var/cache/oracle-jdk${JAVA_MAJOR_VERSION}-installer
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-${JAVA_MAJOR_VERSION}-oracle
    Name: env
  - CmdLine:
    - echo "deb http://cran.rstudio.com/bin/linux/ubuntu xenial/" | tee -a /etc/apt/sources.list
      &&   gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9 &&   gpg -a --export
      E084DAB9 | apt-key add - &&   apt-get update &&   apt-get install -y r-base
      r-base-dev
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install --upgrade pip
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 install tensorflow
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir ${SPARK_WORKDIR}
    Name: run
    PrependShell: true
  - Name: workdir
    Path: ${SPARK_WORKDIR}
  - CmdLine:
    - wget ${SPARK_ARCHIVE} &&   tar -xvzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_MAJOR_VERSION}.tgz
      &&   rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_MAJOR_VERSION}.tgz &&   chown
      -R root:root spark-${SPARK_VERSION}-bin-hadoop${HADOOP_MAJOR_VERSION} &&   ln
      -s spark-${SPARK_VERSION}-bin-hadoop${HADOOP_MAJOR_VERSION} ${SPARK_WORKDIR}/current
      &&   mkdir current/logs &&   touch current/logs/spark-service.log
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_HOME
      Value: ${SPARK_WORKDIR}/current
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$SPARK_HOME/bin
    Name: env
  - CmdLine:
    - mkdir /etc/service/spark-worker
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - files/run.spark-worker
    - /tmp/run.spark-worker
  - CmdLine:
    - tr -d '\015' < /tmp/run.spark-worker > /tmp/run.spark-worker-unix &&   mv /tmp/run.spark-worker-unix
      /etc/service/spark-worker/run &&   chmod +x /etc/service/spark-worker/run
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "8081"
  From:
    Image: phusion/baseimage:latest
  Name: ""
  Platform: ""
  SourceCode: FROM phusion/baseimage:latest
