MetaArgs: null
Stages:
- BaseName: ubuntu:14.04
  Commands:
  - Maintainer: Peter Bryzgalov
    Name: maintainer
  - CmdLine:
    - apt-get update && apt-get install -y --no-install-recommends     wget build-essential
      checkinstall software-properties-common     bzip2     ca-certificates     sudo     locales     libreadline-gplv2-dev
      libncursesw5-dev libssl-dev     libsqlite3-dev tk-dev libgdbm-dev libc6-dev
      libbz2-dev     python-dev python-pip python-numpy python-scipy python-pandas
      gfortran     python-tk     python-setuptools &&     apt-get clean &&     rm
      -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - CmdLine:
    - /usr/bin/python --version
    Name: run
    PrependShell: true
  - CmdLine:
    - sudo pip install nose "ipython[notebook]"
    Name: run
    PrependShell: true
  - CmdLine:
    - echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true
      | debconf-set-selections &&     add-apt-repository -y ppa:webupd8team/java &&     apt-get
      update &&     apt-get install -y oracle-java8-installer &&     rm -rf /var/lib/apt/lists/*
      &&     rm -rf /var/cache/oracle-jdk8-installer
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-8-oracle
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /usr/local/spark
    Name: env
  - CmdLine:
    - mkdir -p $SPARK_HOME
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /spark-distr
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /spark-distr
  - CmdLine:
    - wget http://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz &&     tar
      -xzvf spark-1.6.2-bin-hadoop2.6.tgz -C $SPARK_HOME --strip-components 1 &&     rm
      spark-1.6.2-bin-hadoop2.6.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "export SPARK_HOME=/usr/local/spark"  >> $HOME/.bashrc
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "export PATH=$PATH:$SPARK_HOME/bin"  >> $HOME/.bashrc
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:$SPARK_HOME/bin
    Name: env
  - Env:
    - Key: PYSPARK_DRIVER_PYTHON
      Value: jupyter
    Name: env
  - Env:
    - Key: PYSPARK_DRIVER_PYTHON_OPTS
      Value: '"notebook --no-browser --port=8888 --ip=0.0.0.0"'
    Name: env
  - Name: workdir
    Path: /root
  - Name: expose
    Ports:
    - "19888"
    - "50010"
    - "50020"
    - "50070"
    - "50075"
    - "50090"
    - "6066"
    - "7077"
    - "8020"
    - "8080"
    - "8081"
    - "8888"
  - CmdLine:
    - pyspark --master local[2]
    Name: cmd
    PrependShell: true
  From:
    Image: ubuntu:14.04
  Name: ""
  Platform: ""
  SourceCode: FROM ubuntu:14.04
