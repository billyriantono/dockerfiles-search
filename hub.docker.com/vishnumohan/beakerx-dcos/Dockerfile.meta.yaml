MetaArgs: null
Stages:
- BaseName: debian@sha256:316ebb92ca66bb8ddc79249fb29872bece4be384cb61b5344fac4e84ca4ed2b2
  Commands:
  - Key: BEAKERX_DCOS_VERSION
    Name: arg
    Value: '"0.20.1-1.11.3"'
  - Key: BUILD_DATE
    Name: arg
    Value: null
  - Key: CODENAME
    Name: arg
    Value: '"stretch"'
  - Key: CONDA_DIR
    Name: arg
    Value: '"/opt/conda"'
  - Key: CONDA_ENV_YML
    Name: arg
    Value: '"beakerx-root-conda-base-env.yml"'
  - Key: CONDA_INSTALLER
    Name: arg
    Value: '"Miniconda3-4.5.4-Linux-x86_64.sh"'
  - Key: CONDA_MD5
    Name: arg
    Value: '"a946ea1d0c4a642ddf0c3a26a18bb16d"'
  - Key: CONDA_URL
    Name: arg
    Value: '"https://repo.continuum.io/miniconda"'
  - Key: DCOS_CLI_URL
    Name: arg
    Value: '"https://downloads.dcos.io/binaries/cli/linux/x86-64"'
  - Key: DCOS_CLI_VERSION
    Name: arg
    Value: '"1.11"'
  - Key: DCOS_COMMONS_URL
    Name: arg
    Value: '"https://downloads.mesosphere.com/dcos-commons"'
  - Key: DCOS_COMMONS_VERSION
    Name: arg
    Value: '"0.50.0"'
  - Key: DEBCONF_NONINTERACTIVE_SEEN
    Name: arg
    Value: '"true"'
  - Key: DEBIAN_FRONTEND
    Name: arg
    Value: '"noninteractive"'
  - Key: DEBIAN_REPO
    Name: arg
    Value: '"http://cdn-fastly.deb.debian.org"'
  - Key: DISTRO
    Name: arg
    Value: '"debian"'
  - Key: GPG_KEYSERVER
    Name: arg
    Value: '"hkps://zimmermann.mayfirst.org"'
  - Key: HADOOP_HDFS_HOME
    Name: arg
    Value: '"/opt/hadoop"'
  - Key: HADOOP_MAJOR_VERSION
    Name: arg
    Value: '"2.9"'
  - Key: HADOOP_SHA256
    Name: arg
    Value: '"eed6015a123644d3b4247bac58770e4a8b31340fa62721987430e15a0dd942fc"'
  - Key: HADOOP_URL
    Name: arg
    Value: '"http://www-us.apache.org/dist/hadoop/common"'
  - Key: HADOOP_VERSION
    Name: arg
    Value: '"2.9.1"'
  - Key: HOME
    Name: arg
    Value: '"/home/beakerx"'
  - Key: JAVA_HOME
    Name: arg
    Value: '"/opt/jdk"'
  - Key: JAVA_URL
    Name: arg
    Value: '"https://downloads.mesosphere.com/java"'
  - Key: JAVA_VERSION
    Name: arg
    Value: '"8u172"'
  - Key: LANG
    Name: arg
    Value: '"en_US.UTF-8"'
  - Key: LANGUAGE
    Name: arg
    Value: '"en_US.UTF-8"'
  - Key: LC_ALL
    Name: arg
    Value: '"en_US.UTF-8"'
  - Key: LIBMESOS_BUNDLE_SHA256
    Name: arg
    Value: '"bd4a785393f0477da7f012bf9624aa7dd65aa243c94d38ffe94adaa10de30274"'
  - Key: LIBMESOS_BUNDLE_URL
    Name: arg
    Value: '"https://downloads.mesosphere.com/libmesos-bundle"'
  - Key: LIBMESOS_BUNDLE_VERSION
    Name: arg
    Value: '"1.11.0"'
  - Key: MESOSPHERE_PREFIX
    Name: arg
    Value: '"/opt/mesosphere"'
  - Key: MESOS_JAR_SHA1
    Name: arg
    Value: '"0cef8031567f2ef367e8b6424a94d518e76fb8dc"'
  - Key: MESOS_MAVEN_URL
    Name: arg
    Value: '"https://repo1.maven.org/maven2/org/apache/mesos/mesos"'
  - Key: MESOS_PROTOBUF_JAR_SHA1
    Name: arg
    Value: '"189ef74959049521be8f5a1c3de3921eb0117ffb"'
  - Key: MESOS_VERSION
    Name: arg
    Value: '"1.5.0"'
  - Key: NB_GID
    Name: arg
    Value: '"100"'
  - Key: NB_UID
    Name: arg
    Value: '"1000"'
  - Key: NB_USER
    Name: arg
    Value: '"beakerx"'
  - Key: OPENRESTY_REPO
    Name: arg
    Value: '"http://openresty.org/package"'
  - Key: SPARK_DIST_URL
    Name: arg
    Value: '"https://s3.amazonaws.com/vishnu-mohan/spark"'
  - Key: SPARK_DIST_SHA256
    Name: arg
    Value: '"52e29e83a65688e29da975d1ace7815c6a5b55e76c41d43a28e5e80de2b29843"'
  - Key: SPARK_HOME
    Name: arg
    Value: '"/opt/spark"'
  - Key: SPARK_MAJOR_VERSION
    Name: arg
    Value: '"2.2"'
  - Key: SPARK_VERSION
    Name: arg
    Value: '"2.2.1"'
  - Key: TENSORFLOW_ECO_URL
    Name: arg
    Value: '"https://s3.amazonaws.com/vishnu-mohan/tensorflow"'
  - Key: TENSORFLOW_HADOOP_JAR_SHA256
    Name: arg
    Value: '"cb77cc942a477fb0dbc6b7d17ee1cb0a0a73ba827f288db4c749d5fc0a0c5be3"'
  - Key: TENSORFLOW_SPARK_JAR_SHA256
    Name: arg
    Value: '"303e8d5a8e2e9bad059435d4a86d03a71b3be00d661acba3c5b8f524f20b30fc"'
  - Key: TENSORFLOW_JAR_SHA256
    Name: arg
    Value: '"4b6a9d76ea853db41532275a3608d2d1b5abc1c16609cf8b9ebfffef7c3036fc"'
  - Key: TENSORFLOW_JNI_SHA256
    Name: arg
    Value: '"894d39d8e1d8d1329ea7153f8624657d27619c5db1d9535ab6b66296e3e6ee45"'
  - Key: TENSORFLOW_SERVING_APT_URL
    Name: arg
    Value: '"http://storage.googleapis.com/tensorflow-serving-apt"'
  - Key: TENSORFLOW_SERVING_VERSION
    Name: arg
    Value: '"1.5.0"'
  - Key: TENSORFLOW_URL
    Name: arg
    Value: '"https://storage.googleapis.com/tensorflow"'
  - Key: TENSORFLOW_VARIANT
    Name: arg
    Value: '"cpu"'
  - Key: TENSORFLOW_VERSION
    Name: arg
    Value: '"1.8.0"'
  - Key: TINI_GPG_KEY
    Name: arg
    Value: '"595E85A6B1B4779EA4DAAEC70B588DFF0527A9B7"'
  - Key: TINI_URL
    Name: arg
    Value: '"https://github.com/krallin/tini/releases/download"'
  - Key: TINI_VERSION
    Name: arg
    Value: '"v0.18.0"'
  - Key: VCS_REF
    Name: arg
    Value: null
  - Key: XGBOOST_JAVA_JAR_SHA256
    Name: arg
    Value: '"4a6599ee3f1bd10d984e8b03747d5bc3cb637aeb791474178de2c285857bf69e"'
  - Key: XGBOOST_SPARK_JAR_SHA256
    Name: arg
    Value: '"cd31fb96b26fee197e126215949bc4f5c9a3cafd7ff157ab0037a63777c2935e"'
  - Key: XGBOOST_URL
    Name: arg
    Value: '"https://s3.amazonaws.com/vishnu-mohan/xgboost"'
  - Key: XGBOOST_VERSION
    Name: arg
    Value: '"0.71"'
  - Labels:
    - Key: maintainer
      Value: '"Vishnu Mohan <vishnu@mesosphere.com>"'
    - Key: org.label-schema.build-date
      Value: '"${BUILD_DATE}"'
    - Key: org.label-schema.name
      Value: '"BeakerX"'
    - Key: org.label-schema.description
      Value: '"BeakerX is a collection of kernels and extensions to the Jupyter interactive
        computing environment. It provides JVM support, interactive plots, tables,
        forms, publishing, and more."'
    - Key: org.label-schema.url
      Value: '"http://beakerx.com"'
    - Key: org.label-schema.vcs-ref
      Value: '"${VCS_REF}"'
    - Key: org.label-schema.vcs-url
      Value: '"https://github.com/vishnu2kmohan/beakerx-dcos-docker"'
    - Key: org.label-schema.version
      Value: '"${BEAKERX_DCOS_VERSION}"'
    - Key: org.label-schema.schema-version
      Value: '"1.0"'
    Name: label
  - Env:
    - Key: BOOTSTRAP
      Value: '"${MESOSPHERE_PREFIX}/bin/bootstrap"'
    - Key: CODENAME
      Value: ${CODENAME:-"stretch"}
    - Key: CONDA_DIR
      Value: ${CONDA_DIR:-"/opt/conda"}
    - Key: DEBCONF_NONINTERACTIVE_SEEN
      Value: ${DEBCONF_NONINTERACTIVE_SEEN:-"true"}
    - Key: DEBIAN_FRONTEND
      Value: ${DEBIAN_FRONTEND:-"noninteractive"}
    - Key: DISTRO
      Value: ${DISTRO:-"debian"}
    - Key: GPG_KEYSERVER
      Value: ${GPG_KEYSERVER:-"hkps://zimmermann.mayfirst.org"}
    - Key: HADOOP_HDFS_HOME
      Value: ${HADOOP_HDFS_HOME:-"/opt/hadoop"}
    - Key: HOME
      Value: '"/home/$NB_USER"'
    - Key: JAVA_HOME
      Value: ${JAVA_HOME:-"/opt/jdk"}
    - Key: LANG
      Value: ${LANG:-"en_US.UTF-8"}
    - Key: LANGUAGE
      Value: ${LANGUAGE:-"en_US.UTF-8"}
    - Key: LC_ALL
      Value: ${LC_ALL:-"en_US.UTF-8"}
    - Key: MESOSPHERE_PREFIX
      Value: ${MESOSPHERE_PREFIX:-"/opt/mesosphere"}
    - Key: MESOS_AUTHENTICATEE
      Value: '"com_mesosphere_dcos_ClassicRPCAuthenticatee"'
    - Key: MESOS_HTTP_AUTHENTICATEE
      Value: '"com_mesosphere_dcos_http_Authenticatee"'
    - Key: MESOS_MODULES
      Value: '"{\"libraries\": [{\"file\": \"libdcos_security.so\", \"modules\": [{\"name\":
        \"com_mesosphere_dcos_ClassicRPCAuthenticatee\"}]}]}"'
    - Key: MESOS_NATIVE_LIBRARY
      Value: '"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so"'
    - Key: MESOS_NATIVE_JAVA_LIBRARY
      Value: '"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so"'
    - Key: NB_GID
      Value: ${NB_GID:-"100"}
    - Key: NB_UID
      Value: ${NB_UID:-"1000"}
    - Key: NB_USER
      Value: ${NB_USER:-"beakerx"}
    - Key: NODE_OPTIONS
      Value: '"--max-old-space-size=8192"'
    - Key: PATH
      Value: '"${JAVA_HOME}/bin:${SPARK_HOME}/bin:${HADOOP_HDFS_HOME}/bin:${CONDA_DIR}/bin:${MESOSPHERE_PREFIX}/bin:${PATH}"'
    - Key: SHELL
      Value: '"/bin/bash"'
    - Key: SPARK_HOME
      Value: ${SPARK_HOME:-"/opt/spark"}
    Name: env
  - CmdLine:
    - echo "deb ${DEBIAN_REPO}/${DISTRO} ${CODENAME} main" >> /etc/apt/sources.list     &&
      echo "deb ${DEBIAN_REPO}/${DISTRO}-security ${CODENAME}/updates main" >> /etc/apt/sources.list     &&
      echo "deb ${OPENRESTY_REPO}/${DISTRO} ${CODENAME} openresty" > /etc/apt/sources.list.d/openresty.list     &&
      apt-get update -yq --fix-missing     && apt-get install -yq --no-install-recommends
      apt-utils ca-certificates curl dirmngr gnupg locales     && echo "en_US.UTF-8
      UTF-8" >> /etc/locale.gen     && locale-gen     && curl --retry 3 -fsSL https://openresty.org/package/pubkey.gpg
      -o /tmp/openresty-pubkey.gpg     && apt-key add /tmp/openresty-pubkey.gpg     &&
      rm /tmp/openresty-pubkey.gpg     && apt-get update -yq --fix-missing     &&
      apt-get -yq dist-upgrade     && apt-get install -yq --no-install-recommends        bash-completion        bzip2        dnsutils        ffmpeg        fonts-dejavu        fonts-liberation        git        info        jq        kstart        less        lmodern        luarocks        lua-socket        man        netcat        openresty        openresty-opm        openssh-client        procps        psmisc        rsync        sudo        sssd        unzip        vim        wget     &&
      apt-get clean     && rm -rf /var/lib/apt/lists/*     && opm get zmartzone/lua-resty-openidc     &&
      rm -rf ~/.opm/cache     && chmod ugo+rw /usr/local/openresty/nginx/logs     &&
      chmod ugo+rw /usr/local/openresty/nginx     && addgroup --gid 99 nobody     &&
      usermod -u 99 -g 99 nobody     && echo "nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin"
      >> /etc/passwd     && usermod -a -G users nobody
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - fix-permissions
    - /usr/local/bin/
  - CmdLine:
    - cd /tmp     && apt-key adv --keyserver "${GPG_KEYSERVER}" --recv-keys "${TINI_GPG_KEY}"     &&
      curl --retry 3 -fsSL "${TINI_URL}/${TINI_VERSION}/tini" -o /usr/bin/tini     &&
      curl --retry 3 -fsSL -O "${TINI_URL}/${TINI_VERSION}/tini.asc"     && export
      GNUPGHOME="$(mktemp -d)"     && gpg --keyserver "${GPG_KEYSERVER}" --recv-keys
      "${TINI_GPG_KEY}"     && gpg --batch --verify tini.asc /usr/bin/tini     &&
      rm -rf "${GNUPGHOME}" tini.asc     && chmod +x /usr/bin/tini     && mkdir -p
      "${CONDA_DIR}" "${HADOOP_HDFS_HOME}" "${JAVA_HOME}" "${MESOSPHERE_PREFIX}/bin"
      "${SPARK_HOME}"     && curl --retry 3 -fsSL -O "${LIBMESOS_BUNDLE_URL}/libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz"     &&
      echo "${LIBMESOS_BUNDLE_SHA256}" "libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz"
      | sha256sum -c -     && tar xf "libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz"
      -C "${MESOSPHERE_PREFIX}"     && cd "${MESOSPHERE_PREFIX}/libmesos-bundle/lib"     &&
      curl --retry 3 -fsSL -O "${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}.jar"     &&
      echo "${MESOS_JAR_SHA1} mesos-${MESOS_VERSION}.jar" | sha1sum -c -     && curl
      --retry 3 -fsSL -O "${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}-shaded-protobuf.jar"     &&
      echo "${MESOS_PROTOBUF_JAR_SHA1} mesos-${MESOS_VERSION}-shaded-protobuf.jar"
      | sha1sum -c -     && cd /tmp     && curl --retry 3 -fsSL -O "${DCOS_COMMONS_URL}/artifacts/${DCOS_COMMONS_VERSION}/bootstrap.zip"     &&
      unzip "bootstrap.zip" -d "${MESOSPHERE_PREFIX}/bin/"     && curl --retry 3 -fsSL
      "${DCOS_CLI_URL}/dcos-${DCOS_CLI_VERSION}/dcos" -o ${MESOSPHERE_PREFIX}/bin/dcos     &&
      chmod +x ${MESOSPHERE_PREFIX}/bin/dcos     && curl --retry 3 -fsSL -O "${JAVA_URL}/server-jre-${JAVA_VERSION}-linux-x64.tar.gz"     &&
      tar xf "server-jre-${JAVA_VERSION}-linux-x64.tar.gz" -C "${JAVA_HOME}" --strip-components=1     &&
      curl --retry 3 -fsSL -O "${HADOOP_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz"     &&
      echo "${HADOOP_SHA256}" "hadoop-${HADOOP_VERSION}.tar.gz" | sha256sum -c -     &&
      tar xf "hadoop-${HADOOP_VERSION}.tar.gz" -C "${HADOOP_HDFS_HOME}" --strip-components=1     &&
      rm -rf "${HADOOP_HDFS_HOME}/share/doc"     && curl --retry 3 -fsSL -O "${SPARK_DIST_URL}/spark-${SPARK_VERSION}-bin.tgz"     &&
      echo "${SPARK_DIST_SHA256}" "spark-${SPARK_VERSION}-bin.tgz" | sha256sum -c
      -     && tar xf "spark-${SPARK_VERSION}-bin.tgz" -C "${SPARK_HOME}" --strip-components=1     &&
      cd "${SPARK_HOME}/jars"     && curl --retry 3 -fsSL -O "${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-${XGBOOST_VERSION}.jar"     &&
      echo "${XGBOOST_JAVA_JAR_SHA256}" "xgboost4j-${XGBOOST_VERSION}.jar" | sha256sum
      -c -     && curl --retry 3 -fsSL -O "${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-spark-${XGBOOST_VERSION}.jar"     &&
      echo "${XGBOOST_SPARK_JAR_SHA256}" "xgboost4j-spark-${XGBOOST_VERSION}.jar"
      | sha256sum -c -     && curl --retry 3 -fsSL -O "${TENSORFLOW_URL}/libtensorflow/libtensorflow-${TENSORFLOW_VERSION}.jar"     &&
      echo "${TENSORFLOW_JAR_SHA256}" "libtensorflow-${TENSORFLOW_VERSION}.jar" |
      sha256sum -c -     && curl --retry 3 -fsSL -O "${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/hadoop-${HADOOP_MAJOR_VERSION}/tensorflow-hadoop-${TENSORFLOW_VERSION}.jar"     &&
      echo "${TENSORFLOW_HADOOP_JAR_SHA256}" "tensorflow-hadoop-${TENSORFLOW_VERSION}.jar"
      | sha256sum -c -     && curl --retry 3 -fsSL -O "${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/spark-${SPARK_MAJOR_VERSION}/spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar"     &&
      echo "${TENSORFLOW_SPARK_JAR_SHA256}" "spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar"
      | sha256sum -c -     && cd /tmp     && curl --retry 3 -fsSL -O "${TENSORFLOW_URL}/libtensorflow/libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz"     &&
      echo "${TENSORFLOW_JNI_SHA256}" "libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz"
      | sha256sum -c -     && tar xf "libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz"
      "./libtensorflow_jni.so"     && mv "libtensorflow_jni.so" "/usr/lib"     &&
      rm -rf /tmp/*     && groupadd wheel -g 11     && echo "auth required pam_wheel.so
      use_uid" >> /etc/pam.d/su     && useradd -m -N -u "${NB_UID}" -g "${NB_GID}"
      -s /bin/bash "${NB_USER}"     && usermod -a -G 99,65534 "${NB_USER}"     &&
      chown "${NB_UID}:${NB_GID}" "${CONDA_DIR}"     && chmod g+w /etc/passwd     &&
      fix-permissions "${CONDA_DIR}"     && fix-permissions "${HOME}"
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "deb [arch=amd64] ${TENSORFLOW_SERVING_APT_URL} stable tensorflow-model-server
      tensorflow-model-server-universal" > /etc/apt/sources.list.d/tensorflow-serving.list     &&
      curl --retry 3 -fsSL ${TENSORFLOW_SERVING_APT_URL}/tensorflow-serving.release.pub.gpg
      | apt-key add -     && apt-get update     && TENSORFLOW_SERVING_DEB="$(mktemp)"     &&
      curl --retry 3 -fsSL "${TENSORFLOW_SERVING_APT_URL}/pool/tensorflow-model-server-${TENSORFLOW_SERVING_VERSION}/t/tensorflow-model-server/tensorflow-model-server_${TENSORFLOW_SERVING_VERSION}_all.deb"
      -o "${TENSORFLOW_SERVING_DEB}"    && dpkg -i "${TENSORFLOW_SERVING_DEB}"     &&
      rm -f "${TENSORFLOW_SERVING_DEB}"     && apt-get clean     && rm -rf /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - '"${CONDA_ENV_YML}"'
    - '"${CONDA_DIR}/"'
  - Name: user
    User: $NB_UID
  - CmdLine:
    - cd /tmp     && curl --retry 3 -fsSL -O "${CONDA_URL}/${CONDA_INSTALLER}"     &&
      echo "${CONDA_MD5}  ${CONDA_INSTALLER}" | md5sum -c -     && bash "./${CONDA_INSTALLER}"
      -u -b -p "${CONDA_DIR}"     && ${CONDA_DIR}/bin/conda config --system --prepend
      channels conda-forge     && ${CONDA_DIR}/bin/conda config --system --set auto_update_conda
      false     && ${CONDA_DIR}/bin/conda config --system --set show_channel_urls
      true     && ${CONDA_DIR}/bin/conda update --json --all -yq     && ${CONDA_DIR}/bin/pip
      install --upgrade pip     && ${CONDA_DIR}/bin/conda env update --json -q -f
      "${CONDA_DIR}/${CONDA_ENV_YML}"     && ${CONDA_DIR}/bin/jupyter toree install
      --sys-prefix --interpreters=Scala,PySpark,SparkR,SQL     && ${CONDA_DIR}/bin/jupyter
      labextension install @jupyter-widgets/jupyterlab-manager     && ${CONDA_DIR}/bin/jupyter
      labextension install @jupyterlab/fasta-extension     && ${CONDA_DIR}/bin/jupyter
      labextension install @jupyterlab/geojson-extension     && ${CONDA_DIR}/bin/jupyter
      labextension install @jupyterlab/github     && ${CONDA_DIR}/bin/jupyter labextension
      install @jupyterlab/hub-extension     && ${CONDA_DIR}/bin/jupyter labextension
      install @jupyterlab/latex     && ${CONDA_DIR}/bin/jupyter labextension install
      @jupyterlab/plotly-extension     && ${CONDA_DIR}/bin/jupyter labextension install
      @jupyterlab/vega2-extension     && ${CONDA_DIR}/bin/jupyter labextension install
      @jpmorganchase/perspective-jupyterlab     && ${CONDA_DIR}/bin/jupyter labextension
      install beakerx-jupyterlab@0.20.1      && ${CONDA_DIR}/bin/jupyter labextension
      install bqplot     && ${CONDA_DIR}/bin/jupyter labextension install jupyterlab_bokeh     &&
      ${CONDA_DIR}/bin/jupyter labextension install jupyterlab_voyager     && ${CONDA_DIR}/bin/jupyter
      labextension install jupyterlab-kernelspy     && ${CONDA_DIR}/bin/jupyter labextension
      install jupyterlab-toc     && ${CONDA_DIR}/bin/jupyter labextension install
      knowledgelab     && ${CONDA_DIR}/bin/jupyter labextension install qgrid     &&
      ${CONDA_DIR}/bin/jupyter nbextension install --py --sys-prefix sparkmonitor     &&
      ${CONDA_DIR}/bin/jupyter nbextension enable --py --sys-prefix sparkmonitor     &&
      ${CONDA_DIR}/bin/jupyter serverextension enable --py --sys-prefix sparkmonitor     &&
      ipython profile create     && echo "c.InteractiveShellApp.extensions.append('sparkmonitor.kernelextension')"        >>
      $(ipython profile locate default)/ipython_kernel_config.py     && ${CONDA_DIR}/bin/conda
      remove --force --json -yq openjdk pyqt qt     && ${CONDA_DIR}/bin/npm cache
      clean --force     && rm -rf "${CONDA_DIR}/share/jupyter/lab/staging"  "${HOME}/.npm/_cacache"     &&
      rm -rf "${HOME}/.cache/pip" "${HOME}/.cache/yarn" "${HOME}/.node-gyp"     &&
      ${CONDA_DIR}/bin/conda clean --json -tipsy     && for dir in .conda/envs .jupyter
      .local/share/jupyter/runtime .sparkmagic bin work;        do mkdir -p "${HOME}/${dir}";
      done     && fix-permissions "${CONDA_DIR}"     && fix-permissions "${HOME}"     &&
      rm -rf /tmp/*
    Name: run
    PrependShell: true
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - profile
    - '"${HOME}/.profile"'
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - bash_profile
    - '"${HOME}/.bash_profile"'
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - bashrc
    - '"${HOME}/.bashrc"'
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - dircolors
    - '"${HOME}/.dircolors"'
  - Name: user
    User: root
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - start-notebook.sh
    - /usr/local/bin/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - start-singleuser.sh
    - /usr/local/bin/
  - CmdLine:
    - mv /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0 /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0.bak     &&
      cp "${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libcurl.so.4" /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_DIST_CLASSPATH
      Value: '"${HADOOP_HDFS_HOME}/etc/hadoop:${HADOOP_HDFS_HOME}/share/hadoop/common/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/common/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn:${HADOOP_HDFS_HOME}/share/hadoop/yarn/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/*:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*"'
    - Key: HADOOP_CLASSPATH
      Value: '"${HADOOP_CLASSPATH}:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*"'
    - Key: PYTHONPATH
      Value: '"${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${PYTHONPATH}"'
    - Key: LD_LIBRARY_PATH
      Value: '"/usr/lib/x86_64-linux-gnu:${MESOSPHERE_PREFIX}/libmesos-bundle/lib:${JAVA_HOME}/jre/lib/amd64/server"'
    Name: env
  - Name: workdir
    Path: '"${HOME}"'
  - Name: expose
    Ports:
    - "8080"
  - CmdLine:
    - tini
    - -g
    - --
    Name: entrypoint
    PrependShell: false
  - CmdLine:
    - start-notebook.sh
    Name: cmd
    PrependShell: false
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - krb5.conf.mustache
    - /etc/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - hadoop-env.sh
    - '"${HADOOP_HDFS_HOME}/etc/hadoop/"'
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - hadooprc
    - '"${HOME}/.hadooprc"'
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - conf/
    - '"${SPARK_HOME}/conf/"'
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - jupyter_notebook_config.py
    - /etc/jupyter/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - nginx
    - /usr/local/openresty/nginx/
  - CmdLine:
    - mkdir -p /usr/local/bin/start-notebook.d     && fix-permissions /etc/jupyter/     &&
      chmod -R ugo+rw "${SPARK_HOME}/conf"     && cp "${CONDA_DIR}/share/examples/krb5/krb5.conf"
      /etc     && chmod ugo+rw /etc/krb5.conf     && chmod ugo+rw /usr/local/openresty/nginx/conf/nginx.conf     &&
      chmod ugo+rw /usr/local/openresty/nginx/conf/sites/proxy.conf
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - openidc.lua
    - /usr/local/openresty/site/lualib/resty/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - nginx.conf.mustache
    - /opt/mesosphere/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - proxy.conf.mustache
    - /opt/mesosphere/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - start.sh
    - /usr/local/bin/
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - jupyter_notebook_config.py
    - '"${HOME}/.jupyter/"'
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - beakerx.json
    - '"${HOME}/.jupyter/"'
  - Name: user
    User: '"${NB_UID}"'
  - Chown: 1000:100
    From: ""
    Name: copy
    SourcesAndDest:
    - TFNode.py
    - '"${CONDA_DIR}/lib/python3.6/site-packages/tensorflowonspark/"'
  From:
    Image: debian@sha256:316ebb92ca66bb8ddc79249fb29872bece4be384cb61b5344fac4e84ca4ed2b2
  Name: ""
  Platform: ""
  SourceCode: FROM debian@sha256:316ebb92ca66bb8ddc79249fb29872bece4be384cb61b5344fac4e84ca4ed2b2
