{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "python:2",
      "SourceCode": "FROM python:2",
      "Platform": "",
      "From": {
        "Image": "python:2"
      },
      "Commands": [
        {
          "Maintainer": "Fokko Driesprong \u003cfokkodriesprong@godatadriven.com\u003e",
          "Name": "maintainer"
        },
        {
          "CmdLine": [
            "update-ca-certificates -f   \u0026\u0026 apt-get update   \u0026\u0026 apt-get upgrade -y   \u0026\u0026 apt-get install -y     wget     git     npm     nodejs-legacy     libatlas3-base     libopenblas-base     postgresql-client   \u0026\u0026 apt-get clean   \u0026\u0026 git config --global http.sslverify false"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "GIT_SSL_NO_VERIFY",
              "Value": "false"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "cd /opt/   \u0026\u0026 wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u66-b17/jdk-8u66-linux-x64.tar.gz\"   \u0026\u0026 tar xzf jdk-8u66-linux-x64.tar.gz   \u0026\u0026 rm jdk-8u66-linux-x64.tar.gz   \u0026\u0026 update-alternatives --install /usr/bin/java java /opt/jdk1.8.0_66/bin/java 100   \u0026\u0026 update-alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_66/bin/jar 100   \u0026\u0026 update-alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_66/bin/javac 100"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr/   \u0026\u0026 wget http://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz   \u0026\u0026 tar xzf spark-1.6.3-bin-hadoop2.6.tgz   \u0026\u0026 rm spark-1.6.3-bin-hadoop2.6.tgz   \u0026\u0026 mv spark-1.6.3-bin-hadoop2.6 spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.9-src.zip"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "mkdir -p /usr/spark/work/   \u0026\u0026 chmod -R 777 /usr/spark/work/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_MASTER_PORT",
              "Value": "7077"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "pip install --upgrade pip   \u0026\u0026 pip install pylint coverage --quiet"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "wget -O ./bin/sbt https://raw.githubusercontent.com/paulp/sbt-extras/master/sbt   \u0026\u0026 chmod 0755 ./bin/sbt   \u0026\u0026 ./bin/sbt -v -211 -sbt-create about"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PHANTOM_JS",
              "Value": "phantomjs-1.9.8-linux-x86_64"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "cd /tmp/  \u0026\u0026 wget https://bitbucket.org/ariya/phantomjs/downloads/$PHANTOM_JS.tar.bz2  \u0026\u0026 tar xvjf $PHANTOM_JS.tar.bz2  \u0026\u0026 rm $PHANTOM_JS.tar.bz2  \u0026\u0026 mv $PHANTOM_JS /usr/local/share  \u0026\u0026 ln -sf /usr/local/share/$PHANTOM_JS/bin/phantomjs /usr/local/bin"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install pytest airflow"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "/usr/spark/bin/spark-class org.apache.spark.deploy.master.Master"
          ],
          "Name": "cmd",
          "PrependShell": true
        }
      ]
    }
  ]
}