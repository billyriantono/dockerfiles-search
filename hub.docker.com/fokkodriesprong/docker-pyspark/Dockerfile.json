{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "openjdk:8",
      "SourceCode": "FROM openjdk:8",
      "Platform": "",
      "From": {
        "Image": "openjdk:8"
      },
      "Commands": [
        {
          "Maintainer": "Fokko Driesprong \u003cfokkodriesprong@godatadriven.com\u003e",
          "Name": "maintainer"
        },
        {
          "CmdLine": [
            "update-ca-certificates -f   \u0026\u0026 apt-get update   \u0026\u0026 apt-get upgrade -y   \u0026\u0026 apt-get install -y     software-properties-common     wget     git     libatlas3-base     libopenblas-base     libatlas-base-dev     build-essential   \u0026\u0026 apt-get clean"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr/   \u0026\u0026 wget \"http://ftp.tudelft.nl/apache/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\"   \u0026\u0026 tar xzf spark-2.4.3-bin-hadoop2.7.tgz   \u0026\u0026 rm spark-2.4.3-bin-hadoop2.7.tgz   \u0026\u0026 mv spark-2.4.3-bin-hadoop2.7 spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_MAJOR_VERSION",
              "Value": "2"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$SPARK_HOME/python/:$PYTHONPATH"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "mkdir -p /usr/spark/work/   \u0026\u0026 chmod -R 777 /usr/spark/work/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_MASTER_PORT",
              "Value": "7077"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "CONDA_DIR",
              "Value": "/opt/miniconda"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh \u0026\u0026     chmod a+x miniconda.sh \u0026\u0026     ./miniconda.sh -b -p $CONDA_DIR \u0026\u0026     rm ./miniconda.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "\"$CONDA_DIR/bin/\":$PATH"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "pip install --upgrade pip   \u0026\u0026 pip install pylint coverage pytest black --quiet"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$SPARK_HOME/bin/"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "/usr/spark/bin/spark-class org.apache.spark.deploy.master.Master"
          ],
          "Name": "cmd",
          "PrependShell": true
        }
      ]
    }
  ]
}