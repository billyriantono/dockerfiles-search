{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "python:2",
      "SourceCode": "FROM python:2",
      "Platform": "",
      "From": {
        "Image": "python:2"
      },
      "Commands": [
        {
          "Maintainer": "Fokko Driesprong \u003cfokkodriesprong@godatadriven.com\u003e",
          "Name": "maintainer"
        },
        {
          "CmdLine": [
            "update-ca-certificates -f   \u0026\u0026 apt-get update   \u0026\u0026 apt-get upgrade -y   \u0026\u0026 apt-get install -y     wget     git     libatlas3-base     libopenblas-base   \u0026\u0026 apt-get clean   \u0026\u0026 git config --global http.sslverify false"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "GIT_SSL_NO_VERIFY",
              "Value": "false"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "cd /opt/   \u0026\u0026 wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u144-b01/090f390dda5b47b9b721c7dfaa008135/jdk-8u144-linux-x64.tar.gz\"   \u0026\u0026 tar xzf jdk-8u144-linux-x64.tar.gz   \u0026\u0026 rm jdk-8u144-linux-x64.tar.gz   \u0026\u0026 update-alternatives --install /usr/bin/java java /opt/jdk1.8.0_144/bin/java 100   \u0026\u0026 update-alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_144/bin/jar 100   \u0026\u0026 update-alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_144/bin/javac 100"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr/   \u0026\u0026 wget https://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz   \u0026\u0026 tar xzf spark-2.1.0-bin-hadoop2.7.tgz   \u0026\u0026 rm spark-2.1.0-bin-hadoop2.7.tgz   \u0026\u0026 mv spark-2.1.0-bin-hadoop2.7 spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "mkdir -p /usr/spark/work/   \u0026\u0026 chmod -R 777 /usr/spark/work/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "SPARK_MASTER_PORT",
              "Value": "7077"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "pip install --upgrade pip   \u0026\u0026 pip install --upgrade --quiet pylint pytest coverage numpy setuptools scipy findspark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "wget -O ./bin/sbt https://raw.githubusercontent.com/paulp/sbt-extras/master/sbt   \u0026\u0026 chmod 0755 ./bin/sbt   \u0026\u0026 ./bin/sbt -v -211 -sbt-create about"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "/usr/spark/bin/spark-class org.apache.spark.deploy.master.Master"
          ],
          "Name": "cmd",
          "PrependShell": true
        }
      ]
    }
  ]
}