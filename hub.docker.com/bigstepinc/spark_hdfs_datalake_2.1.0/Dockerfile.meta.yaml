MetaArgs: null
Stages:
- BaseName: mcristinagrosu/bigstep_hdfs_datalake
  Commands:
  - CmdLine:
    - apk add --update alpine-sdk
    Name: run
    PrependShell: true
  - CmdLine:
    - apk add libffi && apk add jq
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /opt && wget http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar xzvf /opt/spark-2.1.0-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - rm  /opt/spark-2.1.0-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark-2.1.0-bin-hadoop2.7
    Name: env
  - Env:
    - Key: R_LIBS_USER
      Value: $SPARK_HOME/R/lib:/opt/conda/envs/ir/lib/R/library:/opt/conda/lib/R/library
    Name: env
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.8.2.1-src.zip
    Name: env
  - CmdLine:
    - mv spark-2.1.0-bin-hadoop2.7 /opt/ && mkdir -p /user && mkdir -p /user/notebooks
      && mkdir -p /user/datasets
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - entrypoint.sh
    - /
  - Chown: ""
    Name: add
    SourcesAndDest:
    - core-site.xml.datalake
    - /opt/spark-2.1.0-bin-hadoop2.7/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - core-site.xml.datalake.integration
    - /opt/spark-2.1.0-bin-hadoop2.7/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - krb5.conf.integration
    - /etc/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - krb5.conf
    - /etc/
  - CmdLine:
    - chmod 777 /entrypoint.sh
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - spark-defaults.conf
    - /opt/spark-2.1.0-bin-hadoop2.7/conf/spark-defaults.conf.template
  - Env:
    - Key: HADOOP_HOME
      Value: /opt/hadoop
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: /opt/hadoop/etc/hadoop
    Name: env
  - Env:
    - Key: CONDA_DIR
      Value: /opt/conda
    Name: env
  - Env:
    - Key: PATH
      Value: $CONDA_DIR/bin:$PATH
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:/$SPARK_HOME/bin/
    Name: env
  - CmdLine:
    - cd /opt &&     wget https://repo.continuum.io/miniconda/Miniconda2-4.2.12-Linux-x86_64.sh
      &&     /bin/bash Miniconda2-4.2.12-Linux-x86_64.sh  -b -p $CONDA_DIR &&      rm
      -rf  Miniconda2-4.2.12-Linux-x86_64.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - export PATH=$PATH:/$CONDA_DIR/bin
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda install --yes     'notebook' &&     $CONDA_DIR/bin/conda
      clean -yt
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/jupyter notebook  --generate-config
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda install --yes nb_conda
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/python -m nb_conda_kernels.install --disable --prefix=$CONDA_DIR
      &&     $CONDA_DIR/bin/conda clean -yt
    Name: run
    PrependShell: true
  - CmdLine:
    - jupyter-nbextension enable nb_conda --py --sys-prefix
    Name: run
    PrependShell: true
  - CmdLine:
    - jupyter-serverextension enable nb_conda --py --sys-prefix
    Name: run
    PrependShell: true
  - CmdLine:
    - jupyter-nbextension enable nbpresent --py --sys-prefix
    Name: run
    PrependShell: true
  - CmdLine:
    - jupyter-serverextension enable nbpresent --py --sys-prefix
    Name: run
    PrependShell: true
  - Env:
    - Key: SBT_VERSION
      Value: 0.13.11
    Name: env
  - Env:
    - Key: SBT_HOME
      Value: /usr/local/sbt
    Name: env
  - Env:
    - Key: PATH
      Value: ${PATH}:${SBT_HOME}/bin
    Name: env
  - CmdLine:
    - curl -sL "http://dl.bintray.com/sbt/native-packages/sbt/$SBT_VERSION/sbt-$SBT_VERSION.tgz"
      | gunzip | tar -x -C /usr/local &&     echo -ne "- with sbt $SBT_VERSION\n"
      >> /root/.built
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /tmp &&     curl -sL "http://dl.bintray.com/sbt/native-packages/sbt/$SBT_VERSION/sbt-$SBT_VERSION.tgz"
      | gunzip | tar -x -C /usr/local &&     echo -ne "- with sbt $SBT_VERSION\n"
      >> /root/.built &&    git clone https://github.com/apache/incubator-toree.git
      &&     cd incubator-toree &&     make dist SHELL=/bin/bash APACHE_SPARK_VERSION=2.1.0
      SCALA_VERSION=2.11 &&     mv /tmp/incubator-toree/dist/toree /opt/toree-kernel
      &&     chmod +x /opt/toree-kernel &&     rm -rf /tmp/incubator-toree
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda install --yes     'ipywidgets'     'pandas'     'matplotlib'     'scipy'     'seaborn'     'scikit-learn'
      &&     $CONDA_DIR/bin/conda clean -yt
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda config --set auto_update_conda False
    Name: run
    PrependShell: true
  - CmdLine:
    - CONDA_VERBOSE=3 $CONDA_DIR/bin/conda create --yes -p /opt/conda/envs/python3
      python=3.5 ipython ipywidgets pandas matplotlib scipy seaborn scikit-learn
    Name: run
    PrependShell: true
  - CmdLine:
    - bash -c '. activate python3 &&     python -m ipykernel.kernelspec --prefix=/opt/conda
      &&     . deactivate'
    Name: run
    PrependShell: true
  - CmdLine:
    - jq --arg v "$CONDA_DIR/envs/python3/bin/python"         '.["env"]["PYSPARK_PYTHON"]=$v'
      /opt/conda/share/jupyter/kernels/python3/kernel.json > /tmp/kernel.json &&      mv
      /tmp/kernel.json /opt/conda/share/jupyter/kernels/python3/kernel.json
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda config --add channels r
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda install --yes -c r r-essentials r-base r-irkernel r-irdisplay
      r-ggplot2 r-repr r-rcurl
    Name: run
    PrependShell: true
  - CmdLine:
    - $CONDA_DIR/bin/conda create --yes  -n ir -c r r-essentials r-base r-irkernel
      r-irdisplay r-ggplot2 r-repr r-rcurl
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir -p /opt/conda/share/jupyter/kernels/scala
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - kernel.json
    - /opt/conda/share/jupyter/kernels/scala/
  - CmdLine:
    - cd /root && wget http://central.maven.org/maven2/com/google/collections/google-collections/1.0/google-collections-1.0.jar
    Name: run
    PrependShell: true
  - CmdLine:
    - mv $CONDA_DIR/envs/python3/lib/libreadline.so.6 /opt/conda/envs/python3/lib/libreadline.so.6.tmp
      &&     ln -s /usr/lib/libreadline.so.6 $CONDA_DIR/envs/python3/lib/libreadline.so.6
    Name: run
    PrependShell: true
  - CmdLine:
    - mv $CONDA_DIR/envs/ir/lib/libreadline.so.6  $CONDA_DIR/envs/ir/lib/libreadline.so.6.tmp
      &&     ln -s /usr/lib/libreadline.so.6 $CONDA_DIR/envs/ir/lib/libreadline.so.6
    Name: run
    PrependShell: true
  - CmdLine:
    - mv $CONDA_DIR/lib/libreadline.so.6 $CONDA_DIR/lib/libreadline.so.6.tmp &&     ln
      -s /usr/lib/libreadline.so.6 $CONDA_DIR/lib/libreadline.so.6
    Name: run
    PrependShell: true
  - CmdLine:
    - mv $CONDA_DIR/pkgs/readline-6.2-2/lib/libreadline.so.6 $CONDA_DIR/pkgs/readline-6.2-2/lib/libreadline.so.6.tmp
      &&     ln -s /usr/lib/libreadline.so.6 $CONDA_DIR/pkgs/readline-6.2-2/lib/libreadline.so.6
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://repo.bigstepcloud.com/bigstep/datalab/DataLab%20Getting%20Started%20in%20Scala.ipynb
      -O /user/notebooks/DataLab\ Getting\ Started\ in\ Scala.ipynb
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://repo.bigstepcloud.com/bigstep/datalab/DataLab%20Getting%20Started%20in%20R.ipynb
      -O /user/notebooks/DataLab\ Getting\ Started\ in\ R.ipynb
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://repo.bigstepcloud.com/bigstep/datalab/DataLab%20Getting%20Started%20in%20Python.ipynb
      -O /user/notebooks/DataLab\ Getting\ Started\ in\ Python.ipynb
    Name: run
    PrependShell: true
  - CmdLine:
    - apk add cairo-dev
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - hive-site.xml
    - /opt/spark-2.1.0-bin-hadoop2.7/conf/
  - CmdLine:
    - wget http://repo.bigstepcloud.com/bigstep/datalab/logo.png -O logo.png
    Name: run
    PrependShell: true
  - CmdLine:
    - cp logo.png $CONDA_DIR/envs/python3/doc/global/template/images/logo.png &&     cp
      logo.png $CONDA_DIR/envs/python3/lib/python3.5/site-packages/notebook/static/base/images/logo.png
      &&     cp logo.png $CONDA_DIR/lib/python2.7/site-packages/notebook/static/base/images/logo.png
      &&     cp logo.png $CONDA_DIR/doc/global/template/images/logo.png &&     rm
      -rf logo.png
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://repo.bigstepcloud.com/bigstep/datalab/hive-schema-1.2.0.postgres.sql
      -O /opt/spark-2.1.0-bin-hadoop2.7/jars/hive-schema-1.2.0.postgres.sql &&     wget
      http://repo.bigstepcloud.com/bigstep/datalab/hive-txn-schema-0.13.0.postgres.sql
      -O /opt/spark-2.1.0-bin-hadoop2.7/jars/hive-txn-schema-0.13.0.postgres.sql &&     wget
      http://repo.bigstepcloud.com/bigstep/datalab/hive-txn-schema-0.14.0.postgres.sql
      -O /opt/spark-2.1.0-bin-hadoop2.7/jars/hive-txn-schema-0.14.0.postgres.sql
    Name: run
    PrependShell: true
  - CmdLine:
    - apk add postgresql-client
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - password.py
    - /opt
  - CmdLine:
    - wget https://github.com/bigstepinc/datalake-client-libraries/releases/download/untagged-f557695f573fa1823db2/datalake-client-libraries-1.5-SNAPSHOT.jar
      -P /opt/spark-2.1.0-bin-hadoop2.7/jars/
    Name: run
    PrependShell: true
  - CmdLine:
    - wget https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar -P /opt/spark-2.1.0-bin-hadoop2.7/jars/
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://central.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-10_2.10/2.1.0/spark-streaming-kafka-0-10_2.10-2.1.0.jar
      -P /opt/spark-2.1.0-bin-hadoop2.7/jars/
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://central.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.10/2.1.0/spark-sql-kafka-0-10_2.10-2.1.0.jar
      -P /opt/spark-2.1.0-bin-hadoop2.7/jars/
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://repo.bigstepcloud.com/bigstep/datalab/toree-assembly-0.2.0.dev1-incubating-SNAPSHOT.jar
      -O /opt/toree-kernel/lib/toree-assembly-0.2.0.dev1-incubating-SNAPSHOT.jar
    Name: run
    PrependShell: true
  - CmdLine:
    - cp /opt/spark-2.1.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.1.0.jar
      /opt/spark-2.1.0-bin-hadoop2.7/jars/spark-examples_2.11-2.1.0.jar
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - spark-daemon.sh
    - /opt/spark-2.1.0-bin-hadoop2.7/sbin/spark-daemon.sh
  - Chown: ""
    Name: add
    SourcesAndDest:
    - log4j.properties
    - /opt/spark-2.1.0-bin-hadoop2.7/conf/log4j.properties
  - Name: expose
    Ports:
    - "10000"
    - "4040"
    - "6066"
    - "7077"
    - "8080"
    - "8081"
    - "88"
    - "8888"
  - CmdLine:
    - /entrypoint.sh
    Name: entrypoint
    PrependShell: false
  From:
    Image: mcristinagrosu/bigstep_hdfs_datalake
  Name: ""
  Platform: ""
  SourceCode: FROM mcristinagrosu/bigstep_hdfs_datalake
