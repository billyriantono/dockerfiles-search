MetaArgs: null
Stages:
- BaseName: ubuntu:16.04
  Commands:
  - Chown: ""
    Name: add
    SourcesAndDest:
    - entrypoint.sh
    - /
  - Env:
    - Key: JAVA_HOME
      Value: /usr/
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:/usr/bin:/usr/lib:/etc/alternatives:/var/lib/dpkg/alternatives
    Name: env
  - CmdLine:
    - apt-get -qq update -y
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get install -y unzip wget curl tar bzip2 software-properties-common git
      gcc make zlib1g-dev openjdk-8-jre libssl-dev
    Name: run
    PrependShell: true
  - CmdLine:
    - echo 'export JAVA_HOME="/usr/bin"' >> ~/.bashrc &&     echo 'export PATH="$PATH:/usr/bin:/usr/lib"'
      >> ~/.bashrc &&     bash ~/.bashrc
    Name: run
    PrependShell: true
  - CmdLine:
    - curl -L -C - -b "oraclelicense=accept-securebackup-cookie" -O http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
      &&    unzip jce_policy-8.zip
    Name: run
    PrependShell: true
  - CmdLine:
    - cp UnlimitedJCEPolicyJDK8/US_export_policy.jar /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security
      && cp UnlimitedJCEPolicyJDK8/local_policy.jar /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -rf UnlimitedJCEPolicyJDK8
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /opt && wget https://www-eu.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz
      &&    tar xzvf /opt/spark-2.4.1-bin-hadoop2.7.tgz &&    rm  /opt/spark-2.4.1-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark-2.4.1-bin-hadoop2.7
    Name: env
  - Env:
    - Key: R_LIBS_USER
      Value: $SPARK_HOME/R/lib:/opt/conda/envs/ir/lib/R/library:/opt/conda/lib/R/library
    Name: env
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:/$SPARK_HOME/bin/
    Name: env
  - CmdLine:
    - wget http://central.maven.org/maven2/com/google/guava/guava/23.0/guava-23.0.jar
      -O $SPARK_HOME/jars/guava-23.0.jar &&       rm $SPARK_HOME/jars/guava-14.0.1.jar
    Name: run
    PrependShell: true
  - Env:
    - Key: SBT_VERSION
      Value: 0.13.11
    Name: env
  - Env:
    - Key: SBT_HOME
      Value: /usr/local/sbt
    Name: env
  - Env:
    - Key: PATH
      Value: ${PATH}:${SBT_HOME}/bin
    Name: env
  - CmdLine:
    - cd /tmp &&     wget "http://repo.bigstepcloud.com/bigstep/datalab/sbt-0.13.11.tgz"
      -O /tmp/sbt-0.13.11.tgz &&     tar -xvf /tmp/sbt-0.13.11.tgz -C /usr/local &&     echo
      -ne "- with sbt $SBT_VERSION\n" >> /root/.built
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /opt &&     wget https://repo.lentiq.com/bigstepdatalake-0.11.1-bin.tar.gz
      &&     tar -xzvf bigstepdatalake-0.11.1-bin.tar.gz &&     rm -rf /opt/bigstepdatalake-0.11.1-bin.tar.gz
      &&     cd /opt/bigstepdatalake-0.11.1/lib/ &&     wget http://repo.uk.bigstepcloud.com/bigstep/bdl/BDL_libs/libhadoop.so
      &&     cp /opt/bigstepdatalake-0.11.1/lib/* $SPARK_HOME/jars/ &&     export
      PATH=/opt/bigstepdatalake-0.11.1/bin:$PATH &&     echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/bigstepdatalake-0.11.1/lib/:$SPARK_HOME/jars/'
      >> ~/.bashrc &&     bash  ~/.bashrc
    Name: run
    PrependShell: true
  - CmdLine:
    - cd $SPARK_HOME/jars/ &&    wget http://repo.bigstepcloud.com/bigstep/datalab/hive-schema-1.2.0.postgres.sql
      &&    wget http://repo.bigstepcloud.com/bigstep/datalab/hive-txn-schema-0.13.0.postgres.sql
      &&    wget http://repo.bigstepcloud.com/bigstep/datalab/hive-txn-schema-0.14.0.postgres.sql
      &&    wget https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar -P $SPARK_HOME/jars/
      &&    add-apt-repository "deb http://apt.postgresql.org/pub/repos/apt/ trusty-pgdg
      main" &&    wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc
      | apt-key add - &&    apt-get install -y postgresql-client
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /opt &&     wget https://www.python.org/ftp/python/3.6.7/Python-3.6.7.tgz
      &&     tar xzf Python-3.6.7.tgz &&     rm -rf Python-3.6.7.tgz &&     cd ./Python-3.6.7/
      &&     ./configure --with-ssl &&     make &&     make test &&     make install
      &&     alias python=python3.6 &&     cd .. &&     rm -rf Python-3.6.7 &&     pip3
      install numpy &&     pip3 install py4j==0.10.7
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - core-site.xml.apiKey
    - $SPARK_HOME/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - spark-defaults.conf
    - $SPARK_HOME/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - hive-site.xml
    - $SPARK_HOME/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - log4j2.xml.default
    - $SPARK_HOME/conf/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - log4j2.xml.audit
    - $SPARK_HOME/conf/
  - CmdLine:
    - chmod 777 /entrypoint.sh
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "10000"
    - "4040"
    - "6066"
    - "7077"
    - "8080"
    - "8081"
    - "88"
    - "8888"
  - CmdLine:
    - /entrypoint.sh
    Name: entrypoint
    PrependShell: false
  From:
    Image: ubuntu:16.04
  Name: ""
  Platform: ""
  SourceCode: FROM ubuntu:16.04
