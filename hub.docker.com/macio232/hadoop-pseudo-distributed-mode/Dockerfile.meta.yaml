MetaArgs: null
Stages:
- BaseName: ubuntu:16.04
  Commands:
  - Name: user
    User: root
  - CmdLine:
    - apt-get update && apt-get -y dist-upgrade && apt-get install -y openssh-server
      wget openjdk-8-jdk vim scala python3 python3-pip && pip3 install py4j
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-8-openjdk-amd64
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$JAVA_HOME/bin
    Name: env
  - CmdLine:
    - "ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa     && cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
      \t&& chmod 0600 ~/.ssh/authorized_keys"
    Name: run
    PrependShell: true
  - CmdLine:
    - useradd -ms /bin/bash hadoop
    Name: run
    PrependShell: true
  - CmdLine:
    - "wget -O /hadoop.tar.gz -q http://ftp.man.poznan.pl/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
      \t&& tar -xzvf hadoop.tar.gz \t&& mv /hadoop-3.1.2 /usr/local/hadoop \t&& rm
      /hadoop.tar.gz"
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /hive-2.3.4.tar.gz -q https://archive.apache.org/dist/hive/hive-2.3.4/apache-hive-2.3.4-bin.tar.gz         &&
      mkdir /home/hadoop/hive-2.3.4         && tar -xzvf hive-2.3.4.tar.gz -C /home/hadoop/hive-2.3.4
      --strip-components=1         && rm /hive-2.3.4.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - wget -O /spark-2.4.3.tgz -q http://ftp.man.poznan.pl/apache/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz         &&
      mkdir /home/hadoop/spark-2.4.3         && tar -xvf /spark-2.4.3.tgz -C /home/hadoop/spark-2.4.3
      --strip-components=1         && rm /spark-2.4.3.tgz
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_HOME
      Value: /usr/local/hadoop
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    Name: env
  - Env:
    - Key: HADOOP_MAPRED_HOME
      Value: $HADOOP_HOME
    Name: env
  - Env:
    - Key: HADOOP_COMMON_HOME
      Value: $HADOOP_HOME
    Name: env
  - Env:
    - Key: HADOOP_HDFS_HOME
      Value: $HADOOP_HOME
    Name: env
  - Env:
    - Key: YARN_HOME
      Value: $HADOOP_HOME
    Name: env
  - Env:
    - Key: HADOOP_COMMON_LIB_NATIVE_DIR
      Value: $HADOOP_HOME/lib/native
    Name: env
  - Env:
    - Key: HADOOP_INSTALL
      Value: $HADOOP_HOME
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /home/hadoop/spark-2.4.3
    Name: env
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python:$PYTHONPATH
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$SPARK_HOME/bin
    Name: env
  - Env:
    - Key: PYSPARK_PYTHON
      Value: python3
    Name: env
  - CmdLine:
    - "mkdir -p $HADOOP_HOME/hdfs/namenode \t&& mkdir -p $HADOOP_HOME/hdfs/datanode"
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - config/
    - /tmp/
  - CmdLine:
    - "mv /tmp/hadoop-env.sh $HADOOP_HOME/etc/hadoop/hadoop-env.sh     && mv /tmp/core-site.xml
      $HADOOP_HOME/etc/hadoop/core-site.xml     && mv /tmp/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml
      \    && mv /tmp/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml.template
      \    && cp $HADOOP_HOME/etc/hadoop/mapred-site.xml.template $HADOOP_HOME/etc/hadoop/mapred-site.xml
      \    && mv /tmp/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml \t&& mv
      /tmp/example.txt /home/hadoop/example.txt \t&& mkdir /home/hadoop/data"
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/hadoop-benchmark.sh
    - $HADOOP_HOME/hadoop-benchmark.sh
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - scripts/hadoop-services.sh
    - $HADOOP_HOME/hadoop-services.sh
  - CmdLine:
    - $HADOOP_HOME/bin/hdfs namenode -format
    Name: run
    PrependShell: true
  - Env:
    - Key: HIVE_HOME
      Value: /home/hadoop/hive-2.3.4
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$HIVE_HOME/bin
    Name: env
  - CmdLine:
    - "mv /tmp/hive-env.sh $HIVE_HOME/conf/hive-env.sh \t&& mv /tmp/hive-site.xml
      $HIVE_HOME/conf/hive-site.xml"
    Name: run
    PrependShell: true
  - CmdLine:
    - cd $HIVE_HOME && rm /home/hadoop/hive-2.3.4/lib/log4j-slf4j-impl-2.6.2.jar &&
      bin/schematool -initSchema -dbType derby
    Name: run
    PrependShell: true
  - CmdLine:
    - /bin/sh $HADOOP_HOME/hadoop-services.sh && /bin/bash
    Name: entrypoint
    PrependShell: true
  - Name: expose
    Ports:
    - "9870"
  - Name: expose
    Ports:
    - "8088"
  - Name: expose
    Ports:
    - "4040"
  From:
    Image: ubuntu:16.04
  Name: ""
  Platform: ""
  SourceCode: FROM ubuntu:16.04
