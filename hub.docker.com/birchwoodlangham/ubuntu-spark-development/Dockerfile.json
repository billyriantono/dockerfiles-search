{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "birchwoodlangham/ubuntu-scala:latest",
      "SourceCode": "FROM birchwoodlangham/ubuntu-scala:latest",
      "Platform": "",
      "From": {
        "Image": "birchwoodlangham/ubuntu-scala:latest"
      },
      "Commands": [
        {
          "Maintainer": "Tan Quach \u003ctan.quach@birchwoodlangham.com\u003e",
          "Name": "maintainer"
        },
        {
          "Env": [
            {
              "Key": "DEBIAN_FRONTEND",
              "Value": "noninteractive"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "ANACONDA_PATH",
              "Value": "/usr/local/anaconda"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$ANACONDA_PATH/bin"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "groupadd -g 1000 spark \u0026\u0026     useradd -u 1000 -g 1000 -m -d /home/spark spark \u0026\u0026     mkdir -p /opt/apps \u0026\u0026     wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh \u0026\u0026     wget http://www.mirrorservice.org/sites/ftp.apache.org/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz \u0026\u0026     tar -C /opt/apps -zxf spark-2.2.1-bin-hadoop2.7.tgz \u0026\u0026     chown -R spark:spark /opt/apps/spark-2.2.1-bin-hadoop2.7 \u0026\u0026     ln -s /opt/apps/spark-2.2.1-bin-hadoop2.7 /usr/local/spark \u0026\u0026     bash Anaconda3-5.1.0-Linux-x86_64.sh -b -p $ANACONDA_PATH \u0026\u0026     rm Anaconda3-5.1.0-Linux-x86_64.sh spark-2.2.1-bin-hadoop2.7.tgz \u0026\u0026     pip install --upgrade pip \u0026\u0026     pip install py4j \u0026\u0026     conda update -n base conda \u0026\u0026     conda install jupyter -y --quiet \u0026\u0026     pip install https://dist.apache.org/repos/dist/dev/incubator/toree/0.2.0-incubating-rc3/toree-pip/toree-0.2.0.tar.gz \u0026\u0026     jupyter toree install"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "user",
          "User": "spark"
        },
        {
          "Name": "workdir",
          "Path": "/home/spark"
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "vimrc_plugins",
            "/home/spark/.vimrc"
          ]
        },
        {
          "CmdLine": [
            "git clone https://github.com/powerline/fonts.git \u0026\u0026     fonts/install.sh \u0026\u0026     rm -rf fonts \u0026\u0026     git clone --depth 1 https://github.com/ryanoasis/nerd-fonts.git fonts \u0026\u0026     cd /home/spark/fonts \u0026\u0026     ./install.sh -q --copy --complete \u0026\u0026     cd /home/spark \u0026\u0026     rm -rf fonts \u0026\u0026     mkdir -p /home/spark/.vim \u0026\u0026     git clone https://github.com/VundleVim/Vundle.vim.git /home/spark/.vim/bundle/Vundle.vim \u0026\u0026     vim +PluginInstall +qall"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "vimrc",
            "/home/spark/.vimrc"
          ]
        },
        {
          "Name": "volume",
          "Volumes": [
            "/home/spark/code",
            "/home/spark/.m2",
            "/home/spark/.ivy2"
          ]
        },
        {
          "Name": "expose",
          "Ports": [
            "7077",
            "8080",
            "8081",
            "8888"
          ]
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$ANACONDA_PATH/bin:$SPARK_HOME/bin"
            },
            {
              "Key": "PYTHONPATH",
              "Value": "$PYTHONPATH:$SPARK_HOME/python"
            },
            {
              "Key": "JAVA_HOME",
              "Value": "/usr/lib/jvm/java-8-oracle"
            },
            {
              "Key": "DERBY_HOME",
              "Value": "/usr/lib/jvm/java-8-oracle/db"
            },
            {
              "Key": "SCALA_HOME",
              "Value": "/usr/share/scala"
            },
            {
              "Key": "SBT_HOME",
              "Value": "/usr/share/sbt-launcher-packaging"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "jupyter",
            "notebook",
            "--notebook-dir=/home/spark/code",
            "--ip='*'",
            "--port=8888",
            "--no-browser"
          ],
          "Name": "cmd",
          "PrependShell": false
        }
      ]
    }
  ]
}