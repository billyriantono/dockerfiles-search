MetaArgs: null
Stages:
- BaseName: jupyter/all-spark-notebook:228ae7a44e0c
  Commands:
  - Maintainer: '"Paolo D''Onorio De Meo <p.donoriodemeo@cineca.it>"'
    Name: maintainer
  - Name: user
    User: root
  - CmdLine:
    - apt-get update && apt-get upgrade -y && apt-get update &&     apt-get install
      -y         wget axel curl         tar sudo openssh-server openssh-client rsync         openjdk-7-jdk
      libyaml-dev         && apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
    Name: run
    PrependShell: true
  - Env:
    - Key: APACHE
      Value: http://www.eu.apache.org
    Name: env
  - Env:
    - Key: HADOOP_VERSION
      Value: hadoop-2.6.5
    Name: env
  - Env:
    - Key: HD
      Value: '"$APACHE/dist/hadoop/common/$HADOOP_VERSION/$HADOOP_VERSION.tar.gz"'
    Name: env
  - Name: workdir
    Path: /tmp
  - CmdLine:
    - axel -a -n 8 $HD     && tar xzvf $HADOOP_VERSION.tar.gz -C /usr/local/     &&
      rm -rf /tmp/*     && cd /usr/local && ln -s ./$HADOOP_VERSION hadoop
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_PREFIX
      Value: /usr/local/hadoop
    Name: env
  - CmdLine:
    - mkdir -p /usr/java     && ln -s /usr/lib/jvm/java-7-openjdk-amd64 /usr/java/default
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/java/default/
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$JAVA_HOME/bin
    Name: env
  - CmdLine:
    - sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/java/default\nexport
      HADOOP_PREFIX=/usr/local/hadoop\nexport HADOOP_HOME=/usr/local/hadoop\n:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh     &&
      sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:'
      $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh     && . $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir $HADOOP_PREFIX/input     && cp $HADOOP_PREFIX/etc/hadoop/*.xml $HADOOP_PREFIX/input
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -f /etc/ssh/ssh_host_dsa_key /etc/ssh/ssh_host_rsa_key /root/.ssh/id_rsa
    Name: run
    PrependShell: true
  - CmdLine:
    - ssh-keygen -q -N "" -t dsa -f /etc/ssh/ssh_host_dsa_key
    Name: run
    PrependShell: true
  - CmdLine:
    - ssh-keygen -q -N "" -t rsa -f /etc/ssh/ssh_host_rsa_key
    Name: run
    PrependShell: true
  - CmdLine:
    - ssh-keygen -q -N "" -t rsa -f /root/.ssh/id_rsa
    Name: run
    PrependShell: true
  - CmdLine:
    - cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - ssh_config
    - /root/.ssh/config
  - CmdLine:
    - chmod 600 /root/.ssh/config && chown root:root /root/.ssh/config
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - core-site.xml.template
    - $HADOOP_PREFIX/etc/hadoop/core-site.xml.template
  - CmdLine:
    - sed s/HOSTNAME/localhost/     /usr/local/hadoop/etc/hadoop/core-site.xml.template     >
      /usr/local/hadoop/etc/hadoop/core-site.xml
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - hdfs-site.xml
    - $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml
  - Chown: ""
    Name: add
    SourcesAndDest:
    - mapred-site.xml
    - $HADOOP_PREFIX/etc/hadoop/mapred-site.xml
  - Chown: ""
    Name: add
    SourcesAndDest:
    - yarn-site.xml
    - $HADOOP_PREFIX/etc/hadoop/yarn-site.xml
  - CmdLine:
    - chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - $HADOOP_PREFIX/bin/hdfs namenode -format
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - bootstrap.sh
    - /etc/bootstrap.sh
  - CmdLine:
    - chown root:root /etc/bootstrap.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - chmod 700 /etc/bootstrap.sh
    Name: run
    PrependShell: true
  - Env:
    - Key: BOOTSTRAP
      Value: /etc/bootstrap.sh
    Name: env
  - CmdLine:
    - rm  /usr/local/hadoop/lib/native/*
    Name: run
    PrependShell: true
  - CmdLine:
    - curl -Ls http://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64-2.6.0.tar|tar
      -x -C /usr/local/hadoop/lib/native/
    Name: run
    PrependShell: true
  - CmdLine:
    - sed  -i "/^[^#]*UsePAM/ s/.*/#&/"  /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "UsePAM no" >> /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "Port 2122" >> /etc/ssh/sshd_config
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: $PATH:$HADOOP_PREFIX/bin
    Name: env
  - CmdLine:
    - service ssh start     && $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh     && $HADOOP_PREFIX/sbin/start-dfs.sh     &&
      hdfs dfs -mkdir -p /user/root     && hdfs dfs -put $HADOOP_PREFIX/etc/hadoop/
      input     && hadoop fs -mkdir -p /tmp     && hadoop fs -chown -R $NB_USER:$NB_USER
      /tmp     && hadoop fs -mkdir -p /user/$NB_USER     && hadoop fs -chown -R $NB_USER:$NB_USER
      /user/$NB_USER
    Name: run
    PrependShell: true
  - CmdLine:
    - chown jovyan /opt
    Name: run
    PrependShell: true
  - Name: user
    User: jovyan
  - CmdLine:
    - pip install --upgrade pip     plumbum jinja2 tweepy version_information     git+https://github.com/Yelp/mrjob
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "Update conda package"     && conda install -y -c damianavila82 rise     &&
      conda install -y -c pydy version_information     && conda clean -y --all
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - boot-all.sh
    - /usr/bin/booter
  - CmdLine:
    - booter
    Name: cmd
    PrependShell: false
  - Chown: ""
    Name: add
    SourcesAndDest:
    - env.sh
    - /tmp/env.sh
  - CmdLine:
    - echo ". /tmp/env.sh" >> /home/$NB_USER/.bashrc
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - Chown: ""
    Name: add
    SourcesAndDest:
    - mrjob.conf
    - /etc/mrjob.conf
  - Name: workdir
    Path: /data
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - jars/*.jar
    - /usr/local/spark/extensions/
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - jars/spark-defaults.conf
    - /usr/local/spark/conf/
  From:
    Image: jupyter/all-spark-notebook:228ae7a44e0c
  Name: ""
  Platform: ""
  SourceCode: FROM jupyter/all-spark-notebook:228ae7a44e0c
