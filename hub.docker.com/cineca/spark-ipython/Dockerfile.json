{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "cineca/hadoop:2.5.2",
      "SourceCode": "FROM cineca/hadoop:2.5.2",
      "Platform": "",
      "From": {
        "Image": "cineca/hadoop:2.5.2"
      },
      "Commands": [
        {
          "Maintainer": "www.hpc.cineca.it",
          "Name": "maintainer"
        },
        {
          "Name": "user",
          "User": "root"
        },
        {
          "CmdLine": [
            "curl -s http://apache.stu.edu.tw/spark/spark-1.4.1/spark-1.4.1-bin-hadoop2.4.tgz | tar -xz -C /usr/local/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr/local     \u0026\u0026 ln -s spark-1.4.1-bin-hadoop2.4 spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /usr/local/spark/yarn-remote-client"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "Name": "add",
          "SourcesAndDest": [
            "yarn-remote-client",
            "/usr/local/spark/yarn-remote-client"
          ]
        },
        {
          "CmdLine": [
            "service ssh start \u0026\u0026 $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh \u0026\u0026 $HADOOP_PREFIX/sbin/start-dfs.sh \u0026\u0026 $HADOOP_PREFIX/bin/hdfs dfsadmin -safemode leave \u0026\u0026 $HADOOP_PREFIX/bin/hdfs dfs -put /usr/local/spark-1.4.1-bin-hadoop2.4/lib /spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "YARN_CONF_DIR",
              "Value": "$HADOOP_PREFIX/etc/hadoop"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_JAR",
              "Value": "hdfs:///spark/spark-assembly-1.4.1-hadoop2.4.0.jar"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python/:$PYTHONPATH"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PYTHONPATH",
              "Value": "$SPARK_HOME/python/lib/py4j-0.8.2.1-src.zip:$PYTHONPATH"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "pip install pip --upgrade"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "apt-get install -y python-tk"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install -U \"ipython[notebook]\""
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install -U nltk"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "pip install pandas"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /notebooks"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "volume",
          "Volumes": [
            "/notebooks"
          ]
        },
        {
          "Name": "workdir",
          "Path": "/notebooks"
        },
        {
          "Name": "expose",
          "Ports": [
            "8888"
          ]
        },
        {
          "Name": "expose",
          "Ports": [
            "8080"
          ]
        },
        {
          "CmdLine": [
            "/etc/bootstrap.sh \u0026\u0026 /usr/local/spark/sbin/start-master.sh \u0026\u0026 IPYTHON_OPTS=\"notebook --no-browser --ip=0.0.0.0 --port 8888\" /usr/local/spark/bin/pyspark"
          ],
          "Name": "cmd",
          "PrependShell": true
        }
      ]
    }
  ]
}