MetaArgs: null
Stages:
- BaseName: ubuntu:16.04
  Commands:
  - CmdLine:
    - apt-get update && apt-get install -y --no-install-recommends   curl wget   python3.5   python3-pip   git   vim   openjdk-8-jdk   net-tools
    Name: run
    PrependShell: true
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-8-openjdk-amd64/
    Name: env
  - Env:
    - Key: HADOOP_VERSION
      Value: 3.2.0
    Name: env
  - Env:
    - Key: HADOOP_URL
      Value: https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz
    Name: env
  - CmdLine:
    - set -x     && curl -fsSL "$HADOOP_URL" -o /tmp/hadoop.tar.gz     && tar -xzf
      /tmp/hadoop.tar.gz -C /opt/     && rm /tmp/hadoop.tar.gz*
    Name: run
    PrependShell: true
  - CmdLine:
    - ln -s /opt/hadoop-$HADOOP_VERSION/etc/hadoop /etc/hadoop
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /opt/hadoop-$HADOOP_VERSION/logs
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /hadoop-data
    Name: run
    PrependShell: true
  - Env:
    - Key: HADOOP_PREFIX
      Value: /opt/hadoop-$HADOOP_VERSION
    Name: env
  - Env:
    - Key: HADOOP_CONF_DIR
      Value: /etc/hadoop
    Name: env
  - Env:
    - Key: MULTIHOMED_NETWORK
      Value: "1"
    Name: env
  - Env:
    - Key: PATH
      Value: $HADOOP_PREFIX/bin/:$PATH
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_javax_jdo_option_ConnectionURL
      Value: jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName
      Value: com.mysql.jdbc.Driver
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName
      Value: root
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword
      Value: root
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_datanucleus_autoCreateSchema
      Value: "false"
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_hive_server2_transport_mode
      Value: binary
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_hive_server2_authentication
      Value: NOSASL
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_hive_server2_enable_doAs
      Value: "false"
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_hive_metastore_schema_verification
      Value: "false"
    Name: env
  - Env:
    - Key: HIVE_SITE_CONF_datanucleus_schema_autoCreateTables
      Value: "true"
    Name: env
  - Env:
    - Key: HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check
      Value: "false"
    Name: env
  - Env:
    - Key: CORE_CONF_fs_defaultFS
      Value: hdfs://localhost:8020
    Name: env
  - Env:
    - Key: CORE_CONF_hadoop_http_staticuser_user
      Value: root
    Name: env
  - Env:
    - Key: CORE_CONF_hadoop_proxyuser_hue_hosts
      Value: '*'
    Name: env
  - Env:
    - Key: CORE_CONF_hadoop_proxyuser_hue_groups
      Value: '*'
    Name: env
  - Env:
    - Key: CORE_CONF_hadoop.proxyuser.root.hosts
      Value: '*'
    Name: env
  - Env:
    - Key: CORE_CONF_hadoop.proxyuser.root.groups
      Value: '*'
    Name: env
  - Env:
    - Key: HDFS_CONF_dfs_webhdfs_enabled
      Value: "true"
    Name: env
  - Env:
    - Key: HDFS_CONF_dfs_permissions_enabled
      Value: "false"
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_log___aggregation___enable
      Value: "true"
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_recovery_enabled
      Value: "true"
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_store_class
      Value: org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_fs_state___store_uri
      Value: /rmstate
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_nodemanager_remote___app___log___dir
      Value: /app-logs
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_log_server_url
      Value: http://historyserver:8188/applicationhistory/logs/
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_timeline___service_enabled
      Value: "true"
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_timeline___service_generic___application___history_enabled
      Value: "true"
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled
      Value: "true"
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_hostname
      Value: resourcemanager
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_timeline___service_hostname
      Value: historyserver
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_address
      Value: resourcemanager:8032
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_scheduler_address
      Value: resourcemanager:8030
    Name: env
  - Env:
    - Key: YARN_CONF_yarn_resourcemanager_resource__tracker_address
      Value: resourcemanager:8031
    Name: env
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - entrypoint.sh
    - /entrypoint.sh
  - CmdLine:
    - chmod a+x /entrypoint.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - wget https://jaist.dl.sourceforge.net/project/jpam/jpam/jpam-1.1/JPam-Linux_amd64-1.1.tgz
      &&     tar zxf JPam-Linux_amd64-1.1.tgz &&     cp JPam-1.1/libjpam.so /opt/hadoop-3.2.0/lib/native
      &&     rm -rf JPam-Linux_amd64-1.1.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - useradd sqlflow && echo 'sqlflow:sqlflow' | chpasswd
    Name: run
    PrependShell: true
  - CmdLine:
    - /entrypoint.sh
    Name: entrypoint
    PrependShell: false
  - CmdLine:
    - mkdir /cmd
    Name: run
    PrependShell: true
  - Health:
      Test:
      - CMD-SHELL
      - curl -f http://localhost:50070/ || exit 1
    Name: healthcheck
  - Env:
    - Key: HDFS_CONF_dfs_namenode_name_dir
      Value: file:///hadoop/dfs/name
    Name: env
  - CmdLine:
    - mkdir -p /hadoop/dfs/name
    Name: run
    PrependShell: true
  - Name: volume
    Volumes:
    - /hadoop/dfs/name
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - cmd/start_namenode.sh
    - /cmd/start_namenode.sh
  - CmdLine:
    - chmod a+x /cmd/start_namenode.sh
    Name: run
    PrependShell: true
  - Health:
      Test:
      - CMD-SHELL
      - curl -f http://localhost:50075/ || exit 1
    Name: healthcheck
  - Env:
    - Key: HDFS_CONF_dfs_datanode_data_dir
      Value: file:///hadoop/dfs/data
    Name: env
  - CmdLine:
    - mkdir -p /hadoop/dfs/data
    Name: run
    PrependShell: true
  - Name: volume
    Volumes:
    - /hadoop/dfs/data
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - cmd/start_datanode.sh
    - /cmd/start_datanode.sh
  - CmdLine:
    - chmod a+x /cmd/start_datanode.sh
    Name: run
    PrependShell: true
  - Health:
      Test:
      - CMD-SHELL
      - curl -f http://localhost:8088/ || exit 1
    Name: healthcheck
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - cmd/start_resourcemanager.sh
    - /cmd/start_resourcemanager.sh
  - CmdLine:
    - chmod a+x /cmd/start_resourcemanager.sh
    Name: run
    PrependShell: true
  - Health:
      Test:
      - CMD-SHELL
      - curl -f http://localhost:8042/ || exit 1
    Name: healthcheck
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - cmd/start_nodemanager.sh
    - /cmd/start_nodemanager.sh
  - CmdLine:
    - chmod a+x /cmd/start_nodemanager.sh
    Name: run
    PrependShell: true
  - Key: HIVE_VERSION
    Name: arg
    Value: null
  - Env:
    - Key: HIVE_VERSION
      Value: ${HIVE_VERSION:-2.3.2}
    Name: env
  - Env:
    - Key: HIVE_HOME
      Value: /opt/hive
    Name: env
  - Env:
    - Key: PATH
      Value: $HIVE_HOME/bin:$PATH
    Name: env
  - Env:
    - Key: HADOOP_HOME
      Value: /opt/hadoop-$HADOOP_VERSION
    Name: env
  - CmdLine:
    - apt-get install -y wget procps
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /opt
  - CmdLine:
    - wget --quiet http://archive.apache.org/dist/hive/hive-$HIVE_VERSION/apache-hive-$HIVE_VERSION-bin.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - "tar -xzf apache-hive-$HIVE_VERSION-bin.tar.gz && \tmv apache-hive-$HIVE_VERSION-bin
      hive && \trm apache-hive-$HIVE_VERSION-bin.tar.gz && \tapt-get clean && \trm
      -rf /var/lib/apt/lists/*"
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - conf/
    - $HIVE_HOME/conf
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - cmd/start_hiveserver2.sh
    - /cmd/start_hiveserver2.sh
  - CmdLine:
    - chmod +x /cmd/start_hiveserver2.sh
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - cmd/start_all.sh
    - /cmd/start_all.sh
  - CmdLine:
    - chmod +x /cmd/start_all.sh
    Name: run
    PrependShell: true
  - CmdLine:
    - /bin/bash
    - -c
    - debconf-set-selections <<< 'mysql-server mysql-server/root_password password
      root'
    Name: run
    PrependShell: false
  - CmdLine:
    - /bin/bash
    - -c
    - debconf-set-selections <<< 'mysql-server mysql-server/root_password_again password
      root'
    Name: run
    PrependShell: false
  - CmdLine:
    - apt-get update && apt-get install -y --no-install-recommends mysql-server
    Name: run
    PrependShell: true
  - Name: volume
    Volumes:
    - /var/lib/mysql
  - Name: workdir
    Path: /tmp
  - CmdLine:
    - wget --quiet https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.47.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -xzf mysql-connector-java-5.1.47.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - cp mysql-connector-java-5.1.47/mysql-connector-java-5.1.47.jar /opt/hive/lib/
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -rf /tmp/mysql-connector-java-5.1.47.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - rm -rf /tmp/mysql-connector-java-5.1.47
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /dataset
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - dataset/popularize_churn.sql
    - /dataset/popularize_churn.sql
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - dataset/popularize_iris.sql
    - /dataset/popularize_iris.sql
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - dataset/create_model_db.sql
    - /dataset/create_model_db.sql
  - CmdLine:
    - wget --quiet https://dl.google.com/go/go1.11.5.linux-amd64.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - tar -C /usr/local -xzf go1.11.5.linux-amd64.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - rm go1.11.5.linux-amd64.tar.gz
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get install -y --no-install-recommends build-essential
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: $PATH:/usr/local/go/bin
    Name: env
  - CmdLine:
    - mkdir -p /go/bin
    Name: run
    PrependShell: true
  - Env:
    - Key: GOPATH
      Value: /go
    Name: env
  - Env:
    - Key: PATH
      Value: $PATH:$GOPATH/bin
    Name: env
  - Key: CONDA_OS
    Name: arg
    Value: Linux
  - CmdLine:
    - cd / && curl -sL https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
      -o mconda-install.sh &&     bash -x mconda-install.sh -b -p miniconda &&     rm
      mconda-install.sh
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: '"/miniconda/bin:$PATH"'
    Name: env
  - CmdLine:
    - ls /miniconda/bin && /miniconda/bin/conda create -y -q -n sqlflow-dev python=3.6
      &&     echo ". /miniconda/etc/profile.d/conda.sh" >> ~/.bashrc &&     echo "source
      activate sqlflow-dev" >> ~/.bashrc &&     bash -c "source activate sqlflow-dev
      && python -m pip install     tensorflow==2.0.0-alpha0     mysql-connector-python     impyla     jupyter"
    Name: run
    PrependShell: true
  - CmdLine:
    - wget --quiet https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protoc-3.6.1-linux-x86_64.zip
      && apt-get install -y unzip && unzip -qq protoc-3.6.1-linux-x86_64.zip -d /usr/local
      && rm protoc-3.6.1-linux-x86_64.zip && go get github.com/golang/protobuf/protoc-gen-go
      && mv /go/bin/protoc-gen-go /usr/local/bin/
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "go get -t sqlflow.org/gohive && go test -v sqlflow.org/gohive" > /build_and_test.bash
    Name: run
    PrependShell: true
  - CmdLine:
    - chmod +x /build_and_test.bash
    Name: run
    PrependShell: true
  From:
    Image: ubuntu:16.04
  Name: ""
  Platform: ""
  SourceCode: FROM ubuntu:16.04
