{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "sequenceiq/hadoop-docker:2.5.1",
      "SourceCode": "FROM sequenceiq/hadoop-docker:2.5.1",
      "Platform": "",
      "From": {
        "Image": "sequenceiq/hadoop-docker:2.5.1"
      },
      "Commands": [
        {
          "Maintainer": "Yanif Ahmad \u003cyanif@jhu.edu\u003e",
          "Name": "maintainer"
        },
        {
          "CmdLine": [
            "curl -s http://d3kbcqa49mib13.cloudfront.net/spark-1.1.0-bin-hadoop2.4.tgz | tar -xz -C /usr/local/"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "cd /usr/local \u0026\u0026 ln -s spark-1.1.0-bin-hadoop2.4 spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir /usr/local/spark/yarn-remote-client"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "Name": "add",
          "SourcesAndDest": [
            "yarn-remote-client",
            "/usr/local/spark/yarn-remote-client"
          ]
        },
        {
          "CmdLine": [
            "$BOOTSTRAP \u0026\u0026 $HADOOP_PREFIX/bin/hadoop dfsadmin -safemode leave \u0026\u0026 $HADOOP_PREFIX/bin/hdfs dfs -put /usr/local/spark-1.1.0-bin-hadoop2.4/lib /spark"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Env": [
            {
              "Key": "YARN_CONF_DIR",
              "Value": "$HADOOP_PREFIX/etc/hadoop"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_JAR",
              "Value": "hdfs:///spark/spark-assembly-1.1.0-hadoop2.4.0.jar"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:/opt/anaconda/bin"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "yum update -y \u0026\u0026 yum install -y wget bzip2 screen"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "echo 'export PATH=/opt/anaconda/bin:$PATH' \u003e /etc/profile.d/conda.sh"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "( echo \"=======================\" ) \u0026\u0026     ( echo \"Installing Python      \" ) \u0026\u0026     ( echo \"=======================\" ) \u0026\u0026     wget --quiet http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh \u0026\u0026     /bin/bash /Miniconda-latest-Linux-x86_64.sh -b -p /opt/anaconda \u0026\u0026     rm Miniconda-latest-Linux-x86_64.sh \u0026\u0026     test -f /opt/anaconda/bin/conda \u0026\u0026     conda install --yes pip \u0026\u0026     conda install --yes numpy \u0026\u0026     conda install --yes scipy \u0026\u0026     conda install --yes matplotlib \u0026\u0026     conda install --yes ipython \u0026\u0026     conda install --yes scikit-learn \u0026\u0026     conda install --yes scikit-image \u0026\u0026     conda install --yes pandas \u0026\u0026     conda install --yes requests \u0026\u0026     conda install --yes h5py \u0026\u0026     pip install astroML"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "/etc/bootstrap.sh",
            "-d"
          ],
          "Name": "cmd",
          "PrependShell": false
        }
      ]
    }
  ]
}