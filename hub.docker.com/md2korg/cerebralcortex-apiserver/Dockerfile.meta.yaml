MetaArgs: null
Stages:
- BaseName: tiangolo/uwsgi-nginx-flask:python3.6
  Commands:
  - Labels:
    - Key: maintainer
      Value: '"Timothy Hnat <twhnat@memphis.edu>"'
    Name: label
  - Labels:
    - Key: org.md2k.apiserver.version
      Value: '''3.1.0'''
    Name: label
  - Labels:
    - Key: description
      Value: '"Cerebral Cortex REST API Server"'
    Name: label
  - Env:
    - Key: APACHE_SPARK_VERSION
      Value: 2.4.4
    Name: env
  - Env:
    - Key: HADOOP_VERSION
      Value: "2.7"
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /usr/local/spark
    Name: env
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip
    Name: env
  - Env:
    - Key: JAVA_HOME
      Value: /usr/lib/jvm/java-8-openjdk-amd64
    Name: env
  - Env:
    - Key: PATH
      Value: $JAVA_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH
    Name: env
  - Env:
    - Key: PYSPARK_PYTHON
      Value: python3
    Name: env
  - Env:
    - Key: HADOOP_HOME
      Value: /opt/hadoop
    Name: env
  - Health:
      Interval: 60000000000
      StartPeriod: 30000000000
      Test:
      - CMD-SHELL
      - curl -f http://localhost/api/v3/docs/ || exit 1
      Timeout: 3000000000
    Name: healthcheck
  - CmdLine:
    - apt-get update   && apt-get install -yqq libsnappy-dev wget git python3-pip  openjdk-8-jre
      python3-setuptools libyaml-dev libev-dev liblapack-dev   && pip3 install --upgrade
      --force-reinstall pip==9.0.3   && pip3 install cython py4j
    Name: run
    PrependShell: true
  - CmdLine:
    - wget http://apache.mirrors.tds.net/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz
      &&   tar -xzf hadoop-3.1.3.tar.gz &&   mv hadoop-3.1.3 $HADOOP_HOME &&   echo
      "export JAVA_HOME=$JAVA_HOME" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh &&   echo
      "PATH=$PATH:$HADOOP_HOME/bin" >> ~/.bashrc
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /tmp &&         wget -q http://apache.cs.utah.edu/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
      &&         tar xzf spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
      -C /usr/local &&         rm spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /usr/local && ln -s spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}
      spark
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - requirements.txt
    - /app/requirements.txt
  - Name: workdir
    Path: /app
  - CmdLine:
    - pip install -r requirements.txt
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - ./app
    - /app
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - nginx/nginx.conf
    - /etc/nginx/
  - CmdLine:
    - mkdir -p /data /cc_config_file /cc_bucket
    Name: run
    PrependShell: true
  - Name: volume
    Volumes:
    - /data
    - /cc_bucket
  From:
    Image: tiangolo/uwsgi-nginx-flask:python3.6
  Name: ""
  Platform: ""
  SourceCode: FROM tiangolo/uwsgi-nginx-flask:python3.6
