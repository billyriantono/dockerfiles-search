{
  "MetaArgs": null,
  "Stages": [
    {
      "Name": "",
      "BaseName": "ikuai/hadoop",
      "SourceCode": "FROM ikuai/hadoop",
      "Platform": "",
      "From": {
        "Image": "ikuai/hadoop"
      },
      "Commands": [
        {
          "Maintainer": "Dylan \u003cbbcheng@ikuai8.com\u003e",
          "Name": "maintainer"
        },
        {
          "Env": [
            {
              "Key": "SPARK_VERSION",
              "Value": "2.2.1"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "SPARK_HOME",
              "Value": "/usr/local/spark-$SPARK_VERSION"
            }
          ],
          "Name": "env"
        },
        {
          "CmdLine": [
            "apt-get update \t\u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -yq --no-install-recommends python python3 \t\u0026\u0026 apt-get autoremove -y \t\u0026\u0026 apt-get clean \t\u0026\u0026 rm -rf /var/lib/apt/lists/*"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "mkdir -p \"${SPARK_HOME}\" \t\u0026\u0026 export ARCHIVE=spark-$SPARK_VERSION-bin-without-hadoop.tgz \t\u0026\u0026 export DOWNLOAD_PATH=apache/spark/spark-$SPARK_VERSION/$ARCHIVE \t\u0026\u0026 curl -sSL http://download.nextag.com/$DOWNLOAD_PATH | tar -xz -C $SPARK_HOME --strip-components 1 \t\u0026\u0026 rm -rf $ARCHIVE"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "spark-env.sh",
            "$SPARK_HOME/conf/spark-env.sh"
          ]
        },
        {
          "Env": [
            {
              "Key": "PATH",
              "Value": "$PATH:$SPARK_HOME/bin"
            }
          ],
          "Name": "env"
        },
        {
          "Env": [
            {
              "Key": "LD_LIBRARY_PATH",
              "Value": "$HADOOP_HOME/lib/native/:$LD_LIBRARY_PATH"
            }
          ],
          "Name": "env"
        },
        {
          "Chown": "",
          "From": "",
          "Name": "copy",
          "SourcesAndDest": [
            "start-spark",
            "/opt/util/bin/start-spark"
          ]
        },
        {
          "CmdLine": [
            "chmod +x /opt/util/bin/start-spark \t\u0026\u0026 echo \"export SPARK_HOME=$SPARK_HOME\" \u003e\u003e /etc/bash.bashrc \t\u0026\u0026 echo 'export PATH=$PATH:$SPARK_HOME/bin'\u003e\u003e /etc/bash.bashrc"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "CmdLine": [
            "echo '#!/usr/bin/env bash' \u003e /usr/bin/master \t\u0026\u0026 echo 'start-spark master' \u003e\u003e /usr/bin/master \t\u0026\u0026 chmod +x /usr/bin/master \t\u0026\u0026 echo '#!/usr/bin/env bash' \u003e /usr/bin/worker \t\u0026\u0026 echo 'start-spark worker $1' \u003e\u003e /usr/bin/worker \t\u0026\u0026 chmod +x /usr/bin/worker"
          ],
          "Name": "run",
          "PrependShell": true
        },
        {
          "Name": "expose",
          "Ports": [
            "6066",
            "7077",
            "8080",
            "8081"
          ]
        },
        {
          "CmdLine": [
            "/usr/sbin/sshd",
            "-D"
          ],
          "Name": "cmd",
          "PrependShell": false
        }
      ]
    }
  ]
}