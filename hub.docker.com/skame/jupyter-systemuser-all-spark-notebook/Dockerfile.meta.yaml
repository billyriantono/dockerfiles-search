MetaArgs: null
Stages:
- BaseName: jupyter/all-spark-notebook
  Commands:
  - Name: user
    User: root
  - CmdLine:
    - apt-get update && apt-get upgrade -y && apt-get install -y         supervisor
    Name: run
    PrependShell: true
  - CmdLine:
    - conda update --all
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install libpng freetype numpy pip scipy
    Name: run
    PrependShell: true
  - CmdLine:
    - "conda install ipykernel jupyter matplotlib conda-build && \tpython -m ipykernel.kernelspec"
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install tensorflow chainer
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install swig
    Name: run
    PrependShell: true
  - CmdLine:
    - "apt-get install -y --no-install-recommends \tmecab libmecab-dev mecab-ipadic-utf8"
    Name: run
    PrependShell: true
  - CmdLine:
    - apt-get install -y gcc-multilib g++-multilib
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install mecab-python3
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install gensim
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install git+git://github.com/google/skflow.git
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install pyquery
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install pymysql
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install psycopg2
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install ipython-sql
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install pyhive
    Name: run
    PrependShell: true
  - CmdLine:
    - conda install plotly dash dash-renderer dash-html-components dash-core-components
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install cufflinks
    Name: run
    PrependShell: true
  - Env:
    - Key: APACHE_SPARK_VERSION
      Value: 2.4.4
    Name: env
  - CmdLine:
    - cd /tmp &&         wget -q http://ftp.jaist.ac.jp/pub/apache/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop2.7.tgz
      &&         tar xzf spark-${APACHE_SPARK_VERSION}-bin-hadoop2.7.tgz -C /usr/local
      &&         rm spark-${APACHE_SPARK_VERSION}-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - cd /usr/local && rm -f spark && ln -s spark-${APACHE_SPARK_VERSION}-bin-hadoop2.7
      spark
    Name: run
    PrependShell: true
  - Env:
    - Key: PYTHONPATH
      Value: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip
    Name: env
  - Env:
    - Key: PYSPARK_PYTHON
      Value: /opt/conda/bin/python
    Name: env
  - CmdLine:
    - pip install sparkmagic && jupyter nbextension enable --py --sys-prefix widgetsnbextension
    Name: run
    PrependShell: true
  - CmdLine:
    - "cd /opt/conda/lib/python3.7/site-packages && \tjupyter-kernelspec install sparkmagic/kernels/pysparkkernel
      &&         jupyter-kernelspec install sparkmagic/kernels/sparkkernel &&         jupyter-kernelspec
      install sparkmagic/kernels/sparkrkernel"
    Name: run
    PrependShell: true
  - CmdLine:
    - mkdir /opt/sparkmagic
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - config.json
    - /opt/sparkmagic/config.json
  - Env:
    - Key: SPARKMAGIC_CONF_DIR
      Value: /opt/sparkmagic
    Name: env
  - Env:
    - Key: SPARKMAGIC_CONF_FILE
      Value: config.json
    Name: env
  - CmdLine:
    - conda install zc.lockfile
    Name: run
    PrependShell: true
  - CmdLine:
    - pip install linecache2 && pip install argparse
    Name: run
    PrependShell: true
  - CmdLine:
    - 'apt-get -y autoremove && apt-get clean # && rm -rf /var/lib/apt/lists/*'
    Name: run
    PrependShell: true
  - CmdLine:
    - sed -ri 's!/usr/local!/opt/conda/bin:/usr/local!' /etc/sudoers
    Name: run
    PrependShell: true
  From:
    Image: jupyter/all-spark-notebook
  Name: ""
  Platform: ""
  SourceCode: FROM jupyter/all-spark-notebook
