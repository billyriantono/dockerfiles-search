MetaArgs: null
Stages:
- BaseName: java:8-alpine
  Commands:
  - Maintainer: He Bai <bai.he@outlook.com>
    Name: maintainer
  - Name: workdir
    Path: /root
  - Env:
    - Key: HADOOP_VERSION
      Value: 2.5.2
    Name: env
  - Env:
    - Key: HIVE_VERSION
      Value: 1.2.1
    Name: env
  - Env:
    - Key: MYSQL_JDBC_VERSION
      Value: 5.1.38
    Name: env
  - Env:
    - Key: PG_JDBC_VERSION
      Value: 9.4.1208
    Name: env
  - Env:
    - Key: SPARK_VERSION
      Value: 1.6.1-bin-hadoop2.4
    Name: env
  - Env:
    - Key: STRATIO_VERSION
      Value: 0.11.1
    Name: env
  - Env:
    - Key: SCALA_VERSION
      Value: "2.10"
    Name: env
  - Env:
    - Key: CASBAH_VERSION
      Value: 3.1.1
    Name: env
  - Env:
    - Key: MONGO_HADOOP_VERSION
      Value: 1.5.2
    Name: env
  - Env:
    - Key: MONGO_DRIVER_VERSION
      Value: 3.2.2
    Name: env
  - Env:
    - Key: LANG
      Value: C.UTF-8
    Name: env
  - Env:
    - Key: GPG_KEY
      Value: 97FC712E4C024BBEA48A61ED3A5CA953F73C700D
    Name: env
  - Env:
    - Key: PYTHON_VERSION
      Value: 3.5.1
    Name: env
  - Env:
    - Key: PYTHON_PIP_VERSION
      Value: 8.1.2
    Name: env
  - Env:
    - Key: HADOOP_DIR
      Value: hadoop-${HADOOP_VERSION}
    Name: env
  - Env:
    - Key: HIVE_DIR
      Value: apache-hive-${HIVE_VERSION}-bin
    Name: env
  - Env:
    - Key: SPARK_DIR
      Value: spark-${SPARK_VERSION}
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /root/${SPARK_DIR}
    Name: env
  - Env:
    - Key: EXT_LIB_DIR
      Value: extlibs
    Name: env
  - Env:
    - Key: NOTEBOOK_DIR
      Value: notebook
    Name: env
  - CmdLine:
    - mkdir ${EXT_LIB_DIR}
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/mysql/mysql-connector-java/${MYSQL_JDBC_VERSION}/mysql-connector-java-${MYSQL_JDBC_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - https://jdbc.postgresql.org/download/postgresql-${PG_JDBC_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/org/mongodb/casbah-commons_${SCALA_VERSION}/${CASBAH_VERSION}/casbah-commons_${SCALA_VERSION}-${CASBAH_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/org/mongodb/casbah-core_${SCALA_VERSION}/${CASBAH_VERSION}/casbah-core_${SCALA_VERSION}-${CASBAH_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/org/mongodb/casbah-query_${SCALA_VERSION}/${CASBAH_VERSION}/casbah-query_${SCALA_VERSION}-${CASBAH_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/com/stratio/datasource/spark-mongodb_${SCALA_VERSION}/${STRATIO_VERSION}/spark-mongodb_${SCALA_VERSION}-${STRATIO_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/org/mongodb/mongo-hadoop/mongo-hadoop-core/${MONGO_HADOOP_VERSION}/mongo-hadoop-core-${MONGO_HADOOP_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://repo1.maven.org/maven2/org/mongodb/mongo-java-driver/${MONGO_DRIVER_VERSION}/mongo-java-driver-${MONGO_DRIVER_VERSION}.jar
    - /root/${EXT_LIB_DIR}
  - Chown: ""
    Name: add
    SourcesAndDest:
    - requirements.txt
    - /root/requirements.txt
  - CmdLine:
    - set -ex     && apk add --no-cache --virtual .fetch-deps curl gnupg     && curl
      -fSL "https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz"
      -o python.tar.xz     && curl -fSL "https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc"
      -o python.tar.xz.asc     && export GNUPGHOME="$(mktemp -d)"     && gpg --keyserver
      ha.pool.sks-keyservers.net --recv-keys "$GPG_KEY"     && gpg --batch --verify
      python.tar.xz.asc python.tar.xz     && rm -r "$GNUPGHOME" python.tar.xz.asc     &&
      mkdir -p /usr/src     && tar -xJC /usr/src -f python.tar.xz     && mv "/usr/src/Python-$PYTHON_VERSION"
      /usr/src/python     && rm python.tar.xz     && apk del .fetch-deps         &&
      apk add --no-cache --virtual .build-deps          bzip2-dev         g++         libc-dev         linux-headers         make         ncurses-dev         openssl-dev         pax-utils         readline-dev         sqlite-dev         xz-dev         zlib-dev         postgresql-dev     &&
      cd /usr/src/python     && ./configure --enable-shared --enable-unicode=ucs4     &&
      make -j$(getconf _NPROCESSORS_ONLN)     && make install     && pip3 install
      --no-cache-dir --upgrade --ignore-installed pip==$PYTHON_PIP_VERSION     &&
      ln -s /usr/include/locale.h /usr/include/xlocale.h     && pip3 install -r /root/requirements.txt     &&
      pip3 install jupyter     && find /usr/local -depth         \(             \(
      -type d -a -name test -o -name tests \)             -o             \( -type
      f -a -name '*.pyc' -o -name '*.pyo' \)         \) -exec rm -rf '{}' +     &&
      runDeps="$(         scanelf --needed --nobanner --recursive /usr/local             |
      awk '{ gsub(/,/, "\nso:", $2); print "so:" $2 }'             | sort -u             |
      xargs -r apk info --installed             | sort -u     )"     && apk add --virtual
      .python-rundeps $runDeps     && apk del .build-deps     && rm -rf /usr/src/python
      ~/.cache
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://www-us.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz
    - /root
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://www-us.apache.org/dist/hive/hive-${HIVE_VERSION}/apache-hive-${HIVE_VERSION}-bin.tar.gz
    - /root
  - Chown: ""
    Name: add
    SourcesAndDest:
    - http://d3kbcqa49mib13.cloudfront.net/spark-${SPARK_VERSION}.tgz
    - /root
  - CmdLine:
    - cd /root && tar xvzf hadoop-${HADOOP_VERSION}.tar.gz     && tar xvzf apache-hive-${HIVE_VERSION}-bin.tar.gz     &&
      tar xvzf spark-${SPARK_VERSION}.tgz     && rm hadoop-${HADOOP_VERSION}.tar.gz
      apache-hive-${HIVE_VERSION}-bin.tar.gz spark-${SPARK_VERSION}.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - cp /root/${EXT_LIB_DIR}/mysql-connector-java-${MYSQL_JDBC_VERSION}.jar ${HIVE_DIR}/lib/mysql-connector-java-${MYSQL_JDBC_VERSION}-bin.jar
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - hive-site.xml
    - /root/${HIVE_DIR}/conf/hive-site.xml
  - Chown: ""
    Name: add
    SourcesAndDest:
    - hive-site.xml
    - /root/${SPARK_DIR}/conf/hive-site.xml
  - CmdLine:
    - mkdir -p /root/${NOTEBOOK_DIR}
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - start-hive-metastore.sh
    - /root/start-hive-metastore.sh
  - CmdLine:
    - chmod +x /root/start-hive-metastore.sh
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - start-sparksql-thrift.sh
    - /root/start-sparksql-thrift.sh
  - CmdLine:
    - chmod +x /root/start-sparksql-thrift.sh
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - start-jupyter-notebook.sh
    - /root/start-jupyter-notebook.sh
  - CmdLine:
    - chmod +x /root/start-jupyter-notebook.sh
    Name: run
    PrependShell: true
  From:
    Image: java:8-alpine
  Name: ""
  Platform: ""
  SourceCode: FROM java:8-alpine
