MetaArgs: null
Stages:
- BaseName: rpy2/jupyter:latest
  Commands:
  - Maintainer: Laurent Gautier <lgautier@gmail.com>
    Name: maintainer
  - Key: CRAN_MIRROR
    Name: arg
    Value: https://cran.revolutionanalytics.com/
  - Key: CRAN_MIRROR_TAG
    Name: arg
    Value: -cran35
  - Name: user
    User: root
  - Key: LLVM_VERSION
    Name: arg
    Value: "6.0"
  - CmdLine:
    - "echo 'deb http://apt.llvm.org/'\"$(lsb_release -c -s)\"'/ llvm-toolchain-'\"$(lsb_release
      -c -s)\"'-6.0 main' >> /etc/apt/sources.list &&   wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key|sudo
      apt-key add - &&   apt-get update -qq &&   apt-get install -y                      clang-\"${LLVM_VERSION}\"
      \t\t     lldb-\"${LLVM_VERSION}\"                      ed                      git
      \t\t     libcairo-dev \t\t     libcurl4-openssl-dev \t\t     libssl-dev \t\t
      \    libedit-dev \t\t     scala \t\t     wget &&   rm -rf /var/lib/apt/lists/*"
    Name: run
    PrependShell: true
  - Key: SPARK_VERSION
    Name: arg
    Value: 2.4.0
  - CmdLine:
    - wget --progress=bar http://mirrors.ocf.berkeley.edu/apache/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz
      &&   tar -xzf spark-${SPARK_VERSION}-bin-hadoop2.7.tgz &&   mv spark-${SPARK_VERSION}-bin-hadoop2.7
      /opt/ &&   rm spark-${SPARK_VERSION}-bin-hadoop2.7.tgz
    Name: run
    PrependShell: true
  - Key: LLVMLITE_VERSION
    Name: arg
    Value: 0.24.0
  - CmdLine:
    - pip3 --no-cache-dir install wheel --upgrade &&   pip3 --no-cache-dir install
      sqlalchemy &&   rm -rf /root/.cache &&   wget https://github.com/numba/llvmlite/archive/v${LLVMLITE_VERSION}.zip
      &&   unzip v${LLVMLITE_VERSION}.zip &&   cd llvmlite-${LLVMLITE_VERSION} &&   LLVM_CONFIG=`which
      llvm-config-"${LLVM_VERSION}"` python3 setup.py install &&   cd .. && rm -rf
      llvmlite-${LLVMLITE_VERSION} && rm v${LLVMLITE_VERSION}.zip &&   pip3 --no-cache
      install numba &&   pip3 --no-cache install findspark &&   pip3 --no-cache install
      jupyter_dashboards &&   jupyter dashboards quick-setup --sys-prefix &&   rm
      -rf /root/.cache
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "bigrquery\n        glmnet\n        gridExtra\n        maps\n        mapproj\n        plotly\n        RPostgreSQL\n        party\n        partykit\n        svglite"
      > rpacks.txt &&   R -e 'install.packages(sub("(.+)\\\\n","\\1", scan("rpacks.txt",
      "character")), repos="'"${CRAN_MIRROR}"'")' &&   rm rpacks.txt
    Name: run
    PrependShell: true
  - Env:
    - Key: NB_USER
      Value: jupyteruser
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark-${SPARK_VERSION}-bin-hadoop2.7
    Name: env
  - Name: user
    User: $NB_USER
  - CmdLine:
    - mkdir -p /home/$NB_USER/work
    Name: run
    PrependShell: true
  - Name: workdir
    Path: /home/$NB_USER/work
  From:
    Image: rpy2/jupyter:latest
  Name: ""
  Platform: ""
  SourceCode: FROM rpy2/jupyter:latest
