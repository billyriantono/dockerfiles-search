MetaArgs: null
Stages:
- BaseName: ubuntu:16.04
  Commands:
  - Maintainer: Laurent Gautier <lgautier@gmail.com>
    Name: maintainer
  - CmdLine:
    - "apt-get update -qq &&   apt-get install -y                      ed                      git
      \t\t     llvm-3.7-tools \t\t     libcairo-dev \t\t     libedit-dev                      lsb-release
      \t\t     python3 \t\t     python3-pip \t\t     r-base \t\t     r-base-dev \t\t
      \    llvm-3.7 \t\t     scala \t\t     wget &&  rm -rf /var/lib/apt/lists/*"
    Name: run
    PrependShell: true
  - CmdLine:
    - wget --progress=bar http://mirrors.ocf.berkeley.edu/apache/spark/spark-1.6.1/spark-1.6.1-bin-hadoop2.6.tgz
      &&   tar -xzf spark-1.6.1-bin-hadoop2.6.tgz &&   mv spark-1.6.1-bin-hadoop2.6
      /opt/ &&   rm spark-1.6.1-bin-hadoop2.6.tgz
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 --no-cache-dir install pip --upgrade &&   pip3 --no-cache-dir install setuptools
      --upgrade &&   pip3 --no-cache-dir install wheel --upgrade &&   pip3 --no-cache-dir
      install numpy pandas sphinx jinja2 jupyter notebook &&   pip3 --no-cache-dir
      install bokeh &&   pip3 --no-cache-dir install sqlalchemy &&   rm -rf /root/.cache
      &&   wget https://github.com/numba/llvmlite/archive/v0.10.0.zip &&   unzip v0.10.0.zip
      &&   cd llvmlite-0.10.0 &&   LLVM_CONFIG=`which llvm-config-3.7` python3 setup.py
      install &&   cd .. && rm -rf llvmite-0.10.0 && rm v0.10.0.zip &&   pip3 --no-cache
      install numba &&   pip3 --no-cache install findspark &&   rm -rf /root/.cache
    Name: run
    PrependShell: true
  - CmdLine:
    - echo "broom\n        dplyr\n        hexbin\n        glmnet\n        ggplot2\n        gridExtra\n        lme4\n        plotly\n        RSQLite\n        svglite\n        tidyr"
      > rpacks.txt &&   R -e 'install.packages(sub("(.+)\\\\n","\\1", scan("rpacks.txt",
      "character")), repos="http://cran.cnr.Berkeley.edu")' &&   rm rpacks.txt
    Name: run
    PrependShell: true
  - CmdLine:
    - pip3 --no-cache-dir install         https://bitbucket.org/rpy2/rpy2/get/RELEASE_2_8_0.tar.gz
      &&   rm -rf /root/.cache
    Name: run
    PrependShell: true
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - finefoods_to_sqlite.py
    - /opt/data/finefoods_to_sqlite.py
  - CmdLine:
    - cd /opt/data &&   wget -q --show-progress --progress=bar:force        http://snap.stanford.edu/data/finefoods.txt.gz
      &&   python3 finefoods_to_sqlite.py &&   rm finefoods.txt.gz
    Name: run
    PrependShell: true
  - Env:
    - Key: SHELL
      Value: /bin/bash
    Name: env
  - Env:
    - Key: NB_USER
      Value: jupyteruser
    Name: env
  - Env:
    - Key: NB_UID
      Value: "1000"
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark-1.6.1-bin-hadoop2.6
    Name: env
  - CmdLine:
    - useradd -m -s /bin/bash -N -u $NB_UID $NB_USER
    Name: run
    PrependShell: true
  - Name: user
    User: $NB_USER
  - CmdLine:
    - mkdir /home/$NB_USER/work &&     mkdir /home/$NB_USER/.jupyter &&     mkdir
      /home/$NB_USER/.local &&     echo "cacert=/etc/ssl/certs/ca-certificates.crt"
      > /home/$NB_USER/.curlrc &&     echo "c.NotebookApp.ip = '*'" >> /home/$NB_USER/.jupyter/jupyter_notebook_config.py
    Name: run
    PrependShell: true
  - Name: user
    User: root
  - Name: workdir
    Path: /home/$NB_USER/work
  - Name: expose
    Ports:
    - "8888"
  - Name: user
    User: $NB_USER
  - Chown: ""
    From: ""
    Name: copy
    SourcesAndDest:
    - pragmatic_polyglot.ipynb
    - /home/$NB_USER/work
  - CmdLine:
    - jupyter notebook --no-browser
    Name: cmd
    PrependShell: true
  From:
    Image: ubuntu:16.04
  Name: ""
  Platform: ""
  SourceCode: FROM ubuntu:16.04
