MetaArgs: null
Stages:
- BaseName: radanalyticsio/openshift-spark:latest
  Commands:
  - Name: user
    User: root
  - Env:
    - Key: LANGUAGE
      Value: en_US.UTF-8
    Name: env
  - Env:
    - Key: LANG
      Value: en_US.UTF-8
    Name: env
  - Env:
    - Key: LC_ALL
      Value: en_US.UTF-8
    Name: env
  - Env:
    - Key: PYTHONIOENCODING
      Value: UTF-8
    Name: env
  - Env:
    - Key: CONDA_DIR
      Value: /opt/conda
    Name: env
  - Env:
    - Key: NB_USER
      Value: nbuser
    Name: env
  - Env:
    - Key: NB_UID
      Value: "1011"
    Name: env
  - Env:
    - Key: NB_PYTHON_VER
      Value: "3.6"
    Name: env
  - Env:
    - Key: MINICONDA_VERSION
      Value: Miniconda3-latest-Linux-x86_64.sh
    Name: env
  - CmdLine:
    - "yum install -y curl wget java-headless bzip2 gnupg2 sqlite3     && yum clean
      all -y     && cd /tmp     && wget -q https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
      \    && bash Miniconda3-latest-Linux-x86_64.sh -b -p $CONDA_DIR     && rm Miniconda3-latest-Linux-x86_64.sh
      \    && export PATH=/opt/conda/bin:$PATH     && yum install -y gcc gcc-c++ glibc-devel
      \    && /opt/conda/bin/conda install --quiet --yes python=$NB_PYTHON_VER 'nomkl'
      \t\t\t    'ipywidgets=5.2*' \t\t\t    'matplotlib' \t\t\t    'scipy' \t\t\t
      \   'seaborn' \t\t\t    'cloudpickle' \t\t\t    statsmodels \t\t\t    pandas
      \t\t\t    'dill' \t\t\t    notebook \t\t\t    jupyter           py4j     &&
      pip install pystan     && pip install widgetsnbextension fbprophet     && yum
      erase -y gcc gcc-c++ glibc-devel     && yum clean all -y     && rm -rf /root/.npm
      \    && rm -rf /root/.cache     && rm -rf /root/.config     && rm -rf /root/.local
      \    && rm -rf /root/tmp     && useradd -m -s /bin/bash -N -u $NB_UID $NB_USER
      \    && usermod -g root $NB_USER     && chown -R $NB_USER $CONDA_DIR     &&
      conda remove --quiet --yes --force --feature mkl ; conda clean -tipsy"
    Name: run
    PrependShell: true
  - Env:
    - Key: PATH
      Value: /opt/conda/bin:$PATH
    Name: env
  - Env:
    - Key: SPARK_HOME
      Value: /opt/spark
    Name: env
  - CmdLine:
    - mkdir /notebooks && chown $NB_UID:root /notebooks && chmod 1777 /notebooks
    Name: run
    PrependShell: true
  - Name: expose
    Ports:
    - "8888"
  - CmdLine:
    - mkdir -p -m 700 /home/$NB_USER/.jupyter/ &&     echo "c.NotebookApp.ip = '*'"
      >> /home/$NB_USER/.jupyter/jupyter_notebook_config.py &&     echo "c.NotebookApp.open_browser
      = False" >> /home/$NB_USER/.jupyter/jupyter_notebook_config.py &&     echo "c.NotebookApp.notebook_dir
      = '/notebooks'" >> /home/$NB_USER/.jupyter/jupyter_notebook_config.py &&     chown
      -R $NB_UID:root /home/$NB_USER &&     chmod g+rwX,o+rX -R /home/$NB_USER
    Name: run
    PrependShell: true
  - Labels:
    - Key: io.k8s.description
      Value: '"PySpark Jupyter Notebook."'
    - Key: io.k8s.display-name
      Value: '"PySpark Jupyter Notebook."'
    - Key: io.openshift.expose-services
      Value: '"8888:http"'
    Name: label
  - Env:
    - Key: TINI_VERSION
      Value: v0.9.0
    Name: env
  - Chown: ""
    Name: add
    SourcesAndDest:
    - https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini
    - /tini
  - Chown: ""
    Name: add
    SourcesAndDest:
    - https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini.asc
    - /tini.asc
  - CmdLine:
    - gpg --keyserver ha.pool.sks-keyservers.net --recv-keys 0527A9B7 && gpg --verify
      /tini.asc
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - start.sh
    - /start.sh
  - CmdLine:
    - export PYTHONPATH=$SPARK_HOME/python:$(echo $SPARK_HOME/python/lib/py4j-*-src.zip)
    Name: run
    PrependShell: true
  - CmdLine:
    - chmod +x /tini /start.sh
    Name: run
    PrependShell: true
  - Env:
    - Key: HOME
      Value: /home/$NB_USER
    Name: env
  - Name: user
    User: $NB_UID
  - Name: workdir
    Path: /notebooks
  - Chown: ""
    Name: add
    SourcesAndDest:
    - app.py
    - /notebooks/
  - Chown: ""
    Name: add
    SourcesAndDest:
    - test-app2.ipynb
    - /notebooks/
  - Name: user
    User: root
  - CmdLine:
    - mkdir /datavol1
    Name: run
    PrependShell: true
  - CmdLine:
    - /tini
    - --
    Name: entrypoint
    PrependShell: false
  - Name: user
    User: root
  - CmdLine:
    - /entrypoint
    - /start.sh
    Name: cmd
    PrependShell: false
  From:
    Image: radanalyticsio/openshift-spark:latest
  Name: ""
  Platform: ""
  SourceCode: FROM radanalyticsio/openshift-spark:latest
