MetaArgs: null
Stages:
- BaseName: openjdk:11.0.2-jre
  Commands:
  - Key: HADOOP_VERSION
    Name: arg
    Value: '"3.1.2"'
  - Key: HADOOP_BASE
    Name: arg
    Value: '"/opt"'
  - Key: HADOOP_FULLNAME
    Name: arg
    Value: '"hadoop-${HADOOP_VERSION}"'
  - Key: HADOOP_DOWNLOAD_URL
    Name: arg
    Value: '"https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=hadoop/common/${HADOOP_FULLNAME}/${HADOOP_FULLNAME}.tar.gz"'
  - Key: HADOOP_UID
    Name: arg
    Value: "1000"
  - Key: HADOOP_GID
    Name: arg
    Value: "1000"
  - Key: ACTIVATION_JAR_DOWNLOAD_URL
    Name: arg
    Value: '"http://central.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar"'
  - Env:
    - Key: HADOOP_HOME
      Value: '"/opt/hadoop"'
    - Key: HADOOP_PID_DIR
      Value: '"/var/run/hadoop"'
    - Key: HADOOP_LOG_DIR
      Value: '"/var/log/hadoop"'
    - Key: HADOOP_USER
      Value: '"hadoop"'
    - Key: HADOOP_CONF_DIR
      Value: '"/etc/hadoop"'
    - Key: HADOOP_DATA_DIR
      Value: '"/var/lib/hadoop"'
    - Key: HADOOP_CONF_TEMP_DIR
      Value: '"/config_template"'
    Name: env
  - Env:
    - Key: HADOOP_NAMENODE_URI
      Value: '"hdfs://localhost"'
    Name: env
  - Env:
    - Key: JAVA_HEAPSIZE
      Value: '"1g"'
    - Key: JAVA_GC_OPTS
      Value: '"-XX:+UseG1GC"'
    - Key: JAVA_GC_LOG_OPTS
      Value: '""'
    Name: env
  - Env:
    - Key: SCRIPTS_DIR
      Value: '"/scripts"'
    - Key: USER_ADDITION_SCRIPTS_DIR
      Value: '"/user_addition_scripts"'
    - Key: ROOT_ADDITION_SCRIPTS_DIR
      Value: '"/root_addition_scripts"'
    Name: env
  - Env:
    - Key: PATH
      Value: '"${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin"'
    Name: env
  - Key: SU_EXEC_VERSION
    Name: arg
    Value: "0.2"
  - Key: SU_EXEC_URL
    Name: arg
    Value: '"https://github.com/ncopa/su-exec/archive/v${SU_EXEC_VERSION}.tar.gz"'
  - CmdLine:
    - apt-get update && apt-get -y install gcc make  && curl -sL "${SU_EXEC_URL}"
      | tar -C /tmp -zx  && make -C "/tmp/su-exec-${SU_EXEC_VERSION}"  && cp "/tmp/su-exec-${SU_EXEC_VERSION}/su-exec"
      /usr/bin  && rm -fr "/tmp/su-exec-${SU_EXEC_VERSION}"  && groupadd -g "${HADOOP_GID}"
      -r "${HADOOP_USER}"  && useradd -g "${HADOOP_USER}" -u "${HADOOP_UID}" -d "${HADOOP_HOME}"
      -M -r -s "/bin/bash" "${HADOOP_USER}"  && mkdir -p "${HADOOP_BASE}"  && curl
      -L "${HADOOP_DOWNLOAD_URL}" | tar -C "${HADOOP_BASE}" --no-same-owner -xzf -  &&
      ln -snf "${HADOOP_BASE}/${HADOOP_FULLNAME}" "${HADOOP_HOME}"  && rm -fr "${HADOOP_HOME}/include"
      "${HADOOP_HOME}/lib/native/examples"     "${HADOOP_HOME}/share/doc"  && find
      "${HADOOP_HOME}/share/hadoop" -name sources -type d -prune -exec rm -fr {} \;  &&
      find "${HADOOP_HOME}/share/hadoop" -name templates -type d -prune -exec rm -fr
      {} \;  && find "${HADOOP_HOME}/share/hadoop" -name jdiff -type d -prune -exec
      rm -fr {} \;  && find "${HADOOP_HOME}/share/hadoop" -name test -type d -prune
      -exec rm -fr {} \;  && find "${HADOOP_HOME}/share/hadoop" -name "lib-examples"
      -type d -prune -exec rm -fr {} \;  && find "${HADOOP_HOME}/share/hadoop" -name
      "*-tests.jar" -type f -exec rm -f {} \;  && curl -L -o "${HADOOP_HOME}/share/hadoop/common/lib/activation-1.1.1.jar"
      "${ACTIVATION_JAR_DOWNLOAD_URL}"  && mv "${HADOOP_HOME}/etc" /hadoop_etc_orig  &&
      mkdir -p "${HADOOP_CONF_TEMP_DIR}" "${SCRIPTS_DIR}"  && mkdir -p "${HADOOP_PID_DIR}"
      "${HADOOP_DATA_DIR}" "${HADOOP_CONF_DIR}" "${HADOOP_LOG_DIR}"  && chown -R "${HADOOP_USER}:${HADOOP_USER}"
      "${HADOOP_PID_DIR}" "${HADOOP_DATA_DIR}" "${HADOOP_LOG_DIR}"  && mkdir -p /scripts
      "${USER_ADDITION_SCRIPTS_DIR}" "${ROOT_ADDITION_SCRIPTS_DIR}"  && apt-get -y
      autoremove --purge gcc make curl  && apt-get -y clean  && rm -fr /var/lib/apt/lists/*
    Name: run
    PrependShell: true
  - Chown: ""
    Name: add
    SourcesAndDest:
    - docker-entrypoint.sh
    - '"${SCRIPTS_DIR}"'
  - Chown: ""
    Name: add
    SourcesAndDest:
    - core-site.xml.tmpl
    - '"${HADOOP_CONF_TEMP_DIR}"'
  - Name: volume
    Volumes:
    - '"${HADOOP_DATA_DIR}"'
    - '"${HADOOP_LOG_DIR}"'
    - '"${HADOOP_CONF_DIR}"'
  - Name: workdir
    Path: '"${HADOOP_HOME}"'
  - CmdLine:
    - /scripts/docker-entrypoint.sh
    Name: entrypoint
    PrependShell: false
  From:
    Image: openjdk:11.0.2-jre
  Name: ""
  Platform: ""
  SourceCode: FROM openjdk:11.0.2-jre
